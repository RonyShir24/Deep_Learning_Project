{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWeR5mD6ErlR",
    "outputId": "83c9e4ba-9a8b-402c-ad1d-32a0d4025fc7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pretty_midi\n",
      "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from pretty_midi) (1.26.3)\n",
      "Collecting mido>=1.1.16 (from pretty_midi)\n",
      "  Obtaining dependency information for mido>=1.1.16 from https://files.pythonhosted.org/packages/39/2c/df005c4b310dde2c834431032139bf2c3924f81798013feb052d1afd543b/mido-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading mido-1.3.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: six in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from pretty_midi) (1.16.0)\n",
      "Requirement already satisfied: packaging~=23.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from mido>=1.1.16->pretty_midi) (23.1)\n",
      "Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
      "  Building wheel for pretty_midi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592288 sha256=c245d145df76ba4d1bc308e943d53fb02f6135bee01f3960a941d0bbea1b4ce0\n",
      "  Stored in directory: /sise/home/ronyshi/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n",
      "Successfully built pretty_midi\n",
      "Installing collected packages: mido, pretty_midi\n",
      "Successfully installed mido-1.3.2 pretty_midi-0.2.10\n"
     ]
    }
   ],
   "source": [
    "! pip install pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YVSQ6CgP0NOc",
    "outputId": "16722d7d-6183-48dc-919b-af609517502e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /storage/modules/packages/anaconda/lib/python3.11/site-packages (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m8ivy-px0NOc",
    "outputId": "bbe7fa4b-b27e-42a7-9a9d-003ef1ca5e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /storage/modules/packages/anaconda/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from nltk) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHgUn7MSC6Z4"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /storage/modules/packages/anaconda/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from gensim) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Collecting FuzzyTM>=0.4.0 (from gensim)\n",
      "  Obtaining dependency information for FuzzyTM>=0.4.0 from https://files.pythonhosted.org/packages/2d/30/074bac7a25866a2807c1005c7852c0139ac22ba837871fc01f16df29b9dc/FuzzyTM-2.0.9-py3-none-any.whl.metadata\n",
      "  Downloading FuzzyTM-2.0.9-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: pandas in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (2.1.4)\n",
      "Collecting pyfume (from FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for pyfume from https://files.pythonhosted.org/packages/ed/ea/a3b120e251145dcdb10777f2bc5f18b1496fd999d705a178c1b0ad947ce1/pyFUME-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading pyFUME-0.3.4-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Collecting scipy>=1.7.0 (from gensim)\n",
      "  Obtaining dependency information for scipy>=1.7.0 from https://files.pythonhosted.org/packages/21/cd/fe2d4af234b80dc08c911ce63fdaee5badcdde3e9bcd9a68884580652ef0/scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m670.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.18.5 (from gensim)\n",
      "  Obtaining dependency information for numpy>=1.18.5 from https://files.pythonhosted.org/packages/22/97/dfb1a31bb46686f09e68ea6ac5c63fdee0d22d7b23b8f3f7ea07712869ef/numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting simpful==2.12.0 (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for simpful==2.12.0 from https://files.pythonhosted.org/packages/9d/0e/aebc2fb0b0f481994179b2ee2b8e6bbf0894d971594688c018375e7076ea/simpful-2.12.0-py3-none-any.whl.metadata\n",
      "  Downloading simpful-2.12.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fst-pso==1.8.1 (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas (from FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/56/73/3351beeb807dca69fcc3c4966bcccc51552bd01549a9b13c04ab00a43f21/pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting miniful (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Downloading FuzzyTM-2.0.9-py3-none-any.whl (31 kB)\n",
      "Downloading pyFUME-0.3.4-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading simpful-2.12.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20430 sha256=89aab41149bcf3ca6fdfc2f24349989a00ea1e89f037c990137576cb5d719244\n",
      "  Stored in directory: /sise/home/ronyshi/.cache/pip/wheels/69/f5/e5/18ad53fe1ed6b2af9fad05ec052e4acbac8e92441df44bad2e\n",
      "  Building wheel for miniful (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3513 sha256=194420060c4e0a80b5f7416f373853a1827cfcc9a2f94f1d7430c14e1730e10f\n",
      "  Stored in directory: /sise/home/ronyshi/.cache/pip/wheels/9d/ff/2f/afe4cd56f47de147407705626517d68bea0f3b74eb1fb168e6\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: numpy, scipy, pandas, simpful, miniful, fst-pso, pyfume, FuzzyTM\n",
      "Successfully installed FuzzyTM-2.0.9 fst-pso-1.8.1 miniful-0.0.6 numpy-1.24.4 pandas-1.5.3 pyfume-0.3.4 scipy-1.10.1 simpful-2.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/ronyshi/.local/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/ronyshi/.local/lib/python3.11/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ronyshi/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorboard tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in /sise/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /sise/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /sise/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /sise/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /sise/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.66.1)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    }
   ],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Levenshtein==0.25.1 in /sise/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages (from python-Levenshtein) (0.25.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /sise/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages (from Levenshtein==0.25.1->python-Levenshtein) (3.9.1)\n",
      "Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.25.1\n"
     ]
    }
   ],
   "source": [
    "! pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "BxBPOa0eDG-U",
    "outputId": "ca567982-4e23-4007-af59-04e519258a52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kirmayer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import gensim.downloader as api\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import Levenshtein\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBLsp6wRDJb6"
   },
   "source": [
    "## PreProcess - First Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UI5sH8u98HqE"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_midi_data(directory_path):\n",
    "    '''\n",
    "    Extract melody features from MIDI files in the given directory.\n",
    "\n",
    "    Parameters:\n",
    "    - directory_path (str): Path to the directory containing MIDI files.\n",
    "\n",
    "    Returns:\n",
    "    - features_dict (dict): A dictionary containing extracted features for each song.\n",
    "    - num_of_melody_features (int): Number of melody features extracted for each song.\n",
    "    '''\n",
    "    files = [file for file in os.listdir(directory_path) if isfile(join(directory_path, file))]\n",
    "    features_dict = {}\n",
    "    num_of_melody_features = 12\n",
    "    for filename in tqdm(files, desc=\"Extracting features\"):\n",
    "        try:\n",
    "            singer_name, song_name = filename.replace('.mid', '').split(\"_-_\")\n",
    "            singer_name = \" \".join(singer_name.split(\"_\")).lower()\n",
    "            song_name = \" \".join(song_name.split(\"_\")).lower()\n",
    "        except ValueError:\n",
    "            print(f\"Skipping file {filename}: cannot parse singer and song name\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            midi_data = pretty_midi.PrettyMIDI(join(directory_path, filename))\n",
    "            melody_features= np.zeros(12)\n",
    "            tempo_changes, tempi = midi_data.get_tempo_changes()\n",
    "            chroma = midi_data.get_chroma()\n",
    "            song_velocity = np.sum(chroma)\n",
    "            song_semitones = [np.sum(semitone) / song_velocity for semitone in chroma] if song_velocity else np.zeros(chroma.shape[0])\n",
    "\n",
    "            melody_features = np.array([\n",
    "                len(tempo_changes),\n",
    "                np.mean(tempi),\n",
    "                np.var(tempi),\n",
    "                np.max(tempi),\n",
    "                np.min(tempi),\n",
    "                np.median(tempi),\n",
    "                len(song_semitones),\n",
    "                np.mean(song_semitones),\n",
    "                np.var(song_semitones),\n",
    "                np.max(song_semitones),\n",
    "                np.min(song_semitones),\n",
    "                np.median(song_semitones),\n",
    "            ])\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            melody_features = np.zeros(num_of_melody_features)\n",
    "\n",
    "        features_dict[(singer_name, song_name)] = melody_features\n",
    "        #features_dict[(singer_name, song_name)] = all_features\n",
    "\n",
    "\n",
    "    print(f\"Extracted melody features for {len(features_dict)} songs.\")\n",
    "    return features_dict, num_of_melody_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6fpUY_1N0NOf"
   },
   "outputs": [],
   "source": [
    "def normalize_features(features_dict):\n",
    "    \"\"\"\n",
    "    Normalize the features with MinMaxScaler in the given features dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - features_dict (dict): A dictionary containing the features.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_features_dict (dict): A dictionary containing the normalized features.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_matrix = np.array(list(features_dict.values()))\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_matrix = scaler.fit_transform(feature_matrix)\n",
    "    normalized_features_dict = {song: features for song, features in zip(features_dict.keys(), normalized_matrix)}\n",
    "    return normalized_features_dict\n",
    "\n",
    "\n",
    "def get_features(singer_name, song_name, normalized_features_dictionary):\n",
    "    \"\"\"\n",
    "    Get the normalized features for a given singer and song name.\n",
    "\n",
    "    Parameters:\n",
    "    - singer_name (str): The name of the singer.\n",
    "    - song_name (str): The name of the song.\n",
    "    - normalized_features_dictionary (dict): A dictionary containing the normalized features.\n",
    "\n",
    "    Returns:\n",
    "    - features (array-like): The normalized features for the given singer and song name, or \"Features not found\" if not found.\n",
    "    \"\"\"\n",
    "    key = (singer_name.lower().strip(), song_name.lower().strip())\n",
    "    return normalized_features_dictionary.get(key, \"Features not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "s4Sh30H00NOf",
    "outputId": "73e74170-3310-4fd4-d467-8efe9cfc3c2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|▏         | 8/625 [00:02<02:36,  3.94it/s]/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n",
      "Extracting features:   3%|▎         | 17/625 [00:03<01:50,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Aaron_Neville_-_Tell_It_Like_It_Is.mid: data byte must be in range 0..127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|█▉        | 124/625 [00:24<01:03,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Beastie_Boys_-_Girls.mid: Could not decode key with 1 flats and mode 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 170/625 [00:33<00:53,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Billy_Joel_-_Movin'_Out.mid: data byte must be in range 0..127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 175/625 [00:33<01:02,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Billy_Joel_-_Pressure.mid: data byte must be in range 0..127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 244/625 [00:49<01:05,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Brian_McKnight_-_On_The_Down_Low.mid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 364/625 [01:17<00:33,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dan_Fogelberg_-_Leader_of_the_Band.mid: Could not decode key with 4 flats and mode 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|█████▉    | 369/625 [01:18<00:37,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing David_Bowie_-_Lazarus.mid: Could not decode key with 16 sharps and mode 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▌   | 407/625 [01:25<00:49,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file Ed_Sheeran_-_Thinking_Out_Loud_-_Violin.mid: cannot parse singer and song name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 441/625 [01:35<01:05,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file Eric_Clapton_-_wonderful_tonight_-_live_extnd_version_@jiji@.mid: cannot parse singer and song name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 625/625 [02:19<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted melody features for 623 songs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_dictionary, num_of_features = get_midi_data('midi_files')\n",
    "normalized_features_dictionary= normalize_features(features_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "r0hZCToe0NOg"
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_tokenize(row, END_OF_LINE_TOKEN=\"<EOL>\", END_OF_FILE_TOKEN=\"<EOF>\"):\n",
    "    '''\n",
    "    Clean and tokenize the given row of lyrics.\n",
    "\n",
    "    Parameters:\n",
    "    - row (str): The row of lyrics to be cleaned and tokenized.\n",
    "    - END_OF_LINE_TOKEN (str): The token to represent the end of a line.\n",
    "    - END_OF_FILE_TOKEN (str): The token to represent the end of a file.\n",
    "\n",
    "    Returns:\n",
    "    - final_tokens (list): The cleaned and tokenized list of words.\n",
    "    '''\n",
    "\n",
    "    # Remove content inside square brackets []\n",
    "    row = re.sub(r'\\[.*?\\]', '', row)\n",
    "\n",
    "    # Remove content inside parentheses () with x+d, verse, or repeat\n",
    "    row = re.sub(r'\\(.*?x\\d+.*?\\)', '', row, flags=re.IGNORECASE)\n",
    "    row = re.sub(r'\\((.*?verse.*?|.*?repeat.*?)\\)', '', row, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace '&' with END_OF_LINE_TOKEN\n",
    "    row = row.replace(\"&\", f\" {END_OF_LINE_TOKEN} \")\n",
    "\n",
    "    # Split the row into tokens\n",
    "    tokens = row.split()\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    punctuation_table = str.maketrans('', '', string.punctuation)\n",
    "    processed_tokens = [\n",
    "        word if word == END_OF_LINE_TOKEN else word.translate(punctuation_table)\n",
    "        for word in tokens\n",
    "    ]\n",
    "    final_tokens = [\n",
    "        word if word == END_OF_LINE_TOKEN else word.lower()\n",
    "        for word in processed_tokens\n",
    "        if word.isalpha() or word.isdigit() or word == END_OF_LINE_TOKEN\n",
    "    ]\n",
    "\n",
    "    # Append END_OF_FILE_TOKEN at the end\n",
    "    final_tokens.append(END_OF_FILE_TOKEN)\n",
    "\n",
    "    return final_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "apZJg2wF0NOg"
   },
   "outputs": [],
   "source": [
    "def get_dataset_df(features_dictionary, csv_file_path):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - features_dictionary (dict): A dictionary containing the normalized features.\n",
    "    - csv_file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - dataset_df (DataFrame): The dataset dataframe.\n",
    "    '''\n",
    "    dataset_df = pd.read_csv(csv_file_path, header=None, usecols=[0, 1, 2])\n",
    "    dataset_df.rename(columns={0: 'Singer', 1: 'SongName', 2: 'Lyrics'}, inplace=True)\n",
    "\n",
    "    dataset_df['Lyrics'] = dataset_df['Lyrics'].apply(clean_and_tokenize)\n",
    "    dataset_df['Features'] = dataset_df.apply(lambda row: get_features(row['Singer'], row['SongName'], features_dictionary), axis=1)\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "FkRwVwO80NOg",
    "outputId": "6390f84c-20d2-4e73-f55f-5f8256935c0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>SongName</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elton john</td>\n",
       "      <td>candle in the wind</td>\n",
       "      <td>[goodbye, norma, jean, &lt;EOL&gt;, though, i, never...</td>\n",
       "      <td>[0.01639344262295082, 0.46552152588646606, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gerry rafferty</td>\n",
       "      <td>baker street</td>\n",
       "      <td>[winding, your, way, down, on, baker, street, ...</td>\n",
       "      <td>[0.00273224043715847, 0.5208333333333334, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gerry rafferty</td>\n",
       "      <td>right down the line</td>\n",
       "      <td>[you, know, i, need, your, love, &lt;EOL&gt;, youve,...</td>\n",
       "      <td>[0.00273224043715847, 0.55000055000055, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 unlimited</td>\n",
       "      <td>tribal dance</td>\n",
       "      <td>[come, on, check, it, out, yall, &lt;EOL&gt;, come, ...</td>\n",
       "      <td>[0.00273224043715847, 0.541667208333875, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 unlimited</td>\n",
       "      <td>let the beat control your body</td>\n",
       "      <td>[let, the, beat, control, your, body, &lt;EOL&gt;, l...</td>\n",
       "      <td>[0.00273224043715847, 0.58333391666725, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>don henley</td>\n",
       "      <td>dirty laundry</td>\n",
       "      <td>[i, make, my, living, off, the, evening, news,...</td>\n",
       "      <td>[0.00273224043715847, 0.47916678645836325, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>don henley</td>\n",
       "      <td>new york minute</td>\n",
       "      <td>[harry, got, up, &lt;EOL&gt;, dressed, all, in, blac...</td>\n",
       "      <td>[0.04644808743169399, 0.20539215405637992, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bob dylan</td>\n",
       "      <td>subterranean homesick blues</td>\n",
       "      <td>[johnnys, in, the, basement, &lt;EOL&gt;, mixing, up...</td>\n",
       "      <td>[0.00273224043715847, 0.7083336875001771, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>goldfinger</td>\n",
       "      <td>mable</td>\n",
       "      <td>[i, met, her, sunday, that, was, yesterday, &lt;E...</td>\n",
       "      <td>[0.00819672131147541, 0.6569444307639656, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>dr dre</td>\n",
       "      <td>forgot about dre</td>\n",
       "      <td>[yall, know, me, still, the, same, og, but, i,...</td>\n",
       "      <td>[0.00273224043715847, 0.5541676734046067, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Singer                        SongName  \\\n",
       "0        elton john              candle in the wind   \n",
       "1    gerry rafferty                    baker street   \n",
       "2    gerry rafferty             right down the line   \n",
       "3       2 unlimited                    tribal dance   \n",
       "4       2 unlimited  let the beat control your body   \n",
       "..              ...                             ...   \n",
       "595      don henley                   dirty laundry   \n",
       "596      don henley                 new york minute   \n",
       "597       bob dylan     subterranean homesick blues   \n",
       "598      goldfinger                           mable   \n",
       "599          dr dre                forgot about dre   \n",
       "\n",
       "                                                Lyrics  \\\n",
       "0    [goodbye, norma, jean, <EOL>, though, i, never...   \n",
       "1    [winding, your, way, down, on, baker, street, ...   \n",
       "2    [you, know, i, need, your, love, <EOL>, youve,...   \n",
       "3    [come, on, check, it, out, yall, <EOL>, come, ...   \n",
       "4    [let, the, beat, control, your, body, <EOL>, l...   \n",
       "..                                                 ...   \n",
       "595  [i, make, my, living, off, the, evening, news,...   \n",
       "596  [harry, got, up, <EOL>, dressed, all, in, blac...   \n",
       "597  [johnnys, in, the, basement, <EOL>, mixing, up...   \n",
       "598  [i, met, her, sunday, that, was, yesterday, <E...   \n",
       "599  [yall, know, me, still, the, same, og, but, i,...   \n",
       "\n",
       "                                              Features  \n",
       "0    [0.01639344262295082, 0.46552152588646606, 0.0...  \n",
       "1    [0.00273224043715847, 0.5208333333333334, 0.0,...  \n",
       "2    [0.00273224043715847, 0.55000055000055, 0.0, 0...  \n",
       "3    [0.00273224043715847, 0.541667208333875, 0.0, ...  \n",
       "4    [0.00273224043715847, 0.58333391666725, 0.0, 0...  \n",
       "..                                                 ...  \n",
       "595  [0.00273224043715847, 0.47916678645836325, 0.0...  \n",
       "596  [0.04644808743169399, 0.20539215405637992, 0.0...  \n",
       "597  [0.00273224043715847, 0.7083336875001771, 0.0,...  \n",
       "598  [0.00819672131147541, 0.6569444307639656, 0.03...  \n",
       "599  [0.00273224043715847, 0.5541676734046067, 0.0,...  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataset_df(normalized_features_dictionary, 'lyrics_train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PNyUssed0NOg"
   },
   "outputs": [],
   "source": [
    "def get_lyrics_vocabulary(lyrics_list):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - lyrics_list (list): A list containing the lyrics.\n",
    "\n",
    "    Returns:\n",
    "    - vocabulary (set): A set containing the vocabulary of the lyrics.\n",
    "    '''\n",
    "    return set(word for lyrics in lyrics_list for word in lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "CvnZeYas0NOg"
   },
   "outputs": [],
   "source": [
    "def save_vocabulary_data(train_df, test_df, wv_model_path='word2vec.model'):\n",
    "    '''\n",
    "    Save the vocabulary data to a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - train_df (DataFrame): The training dataset.\n",
    "    - test_df (DataFrame): The testing dataset.\n",
    "    - wv_model_path (str): The path to the word2vec model.\n",
    "\n",
    "    '''\n",
    "\n",
    "    wv = word2vec_model\n",
    "\n",
    "    combined_vocab = get_lyrics_vocabulary(train_df['Lyrics']) | get_lyrics_vocabulary(test_df['Lyrics'])\n",
    "\n",
    "    embeddings_dict = {word: wv[word] for word in combined_vocab if word in wv}\n",
    "\n",
    "    missing_stopwords = [word for word in stopwords.words('english') if word not in embeddings_dict]\n",
    "    embeddings_dict.update({stopword: np.random.uniform(low=-1.0, high=1.0, size=(300,)) for stopword in missing_stopwords})\n",
    "\n",
    "    with open('embeddings.pickle', 'wb') as f:\n",
    "        pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "sadkCRUD0NOh"
   },
   "outputs": [],
   "source": [
    "def get_vocabulary_data():\n",
    "    '''\n",
    "\n",
    "    Load the vocabulary data from a pickle file.\n",
    "\n",
    "    Returns:\n",
    "    - embeddings_dict (dict): A dictionary containing the word embeddings.\n",
    "    - words (list): A list of words in the vocabulary.\n",
    "    - word_indices (dict): A dictionary mapping words to their indices.\n",
    "    - embeddings (list): A list of word embeddings.\n",
    "    - embedding_matrix (ndarray): A matrix of word embeddings.\n",
    "    - vocab_size (int): The size of the vocabulary.\n",
    "    - embedding_dim (int): The dimension of the word embeddings.\n",
    "    '''\n",
    "\n",
    "    with open('embeddings.pickle', 'rb') as f:\n",
    "        embeddings_dict = pickle.load(f)\n",
    "\n",
    "    #embeddings_dict[\"unk\"] = np.zeros((300,))\n",
    "\n",
    "    words = list(embeddings_dict.keys())\n",
    "    word_indices = {word: index for index, word in enumerate(words)}\n",
    "\n",
    "    embeddings = list(embeddings_dict.values())\n",
    "    embedding_matrix = np.vstack(embeddings)\n",
    "\n",
    "    vocab_size = len(words)\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "    print(\"Vocabulary size:\", vocab_size)\n",
    "    print(\"Embedding dimensions:\", embedding_dim)\n",
    "\n",
    "    return embeddings_dict, words, word_indices, embeddings, embedding_matrix, vocab_size, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "VniSwQ730NOh",
    "outputId": "5e43dca3-f4a1-4a68-b9bd-39130a9efbf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6805\n",
      "Embedding dimensions: 300\n"
     ]
    }
   ],
   "source": [
    "train_df = get_dataset_df(normalized_features_dictionary, 'lyrics_train_set.csv')\n",
    "test_df = get_dataset_df(normalized_features_dictionary, 'lyrics_test_set.csv')\n",
    "\n",
    "save_vocabulary_data(train_df, test_df)\n",
    "\n",
    "embeddings_dict, words, word_indices, embeddings, embedding_matrix, vocab_size, embedding_dim = get_vocabulary_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "6dLbHTce0NOh"
   },
   "outputs": [],
   "source": [
    "def from_w2i_to_i2w(word_indices):\n",
    "    \"\"\"\n",
    "    Convert word indices to word dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - word_indices (dict): A dictionary mapping words to their indices.\n",
    "\n",
    "    Returns:\n",
    "    - indices_word (dict): A dictionary mapping indices to their corresponding words.\n",
    "    \"\"\"\n",
    "    indices_word = {v: k for k, v in word_indices.items()}\n",
    "    return indices_word\n",
    "\n",
    "indices_word = from_w2i_to_i2w(word_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lox-W57E0NOi"
   },
   "source": [
    "## PreProcess - Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midi_data_second(directory_path):\n",
    "    \"\"\"\n",
    "    Extract melody and instrument features from MIDI files in the given directory.\n",
    "\n",
    "    Parameters:\n",
    "    - directory_path (str): Path to the directory containing MIDI files.\n",
    "\n",
    "    Returns:\n",
    "    - features_dict_2 (dict): A dictionary containing extracted features for each song.\n",
    "    - num_of_melody_features_2 (int): Number of melody and instrument features extracted for each song.\n",
    "    \"\"\"\n",
    "    files = [file for file in os.listdir(directory_path) if isfile(join(directory_path, file))]\n",
    "    features_dict_2 = {}\n",
    "    num_of_melody_features_2 = 9\n",
    "    for filename in tqdm(files, desc=\"Extracting features\"):\n",
    "        try:\n",
    "            singer_name, song_name = filename.replace('.mid', '').split(\"_-_\")\n",
    "            singer_name = \" \".join(singer_name.split(\"_\")).lower()\n",
    "            song_name = \" \".join(song_name.split(\"_\")).lower()\n",
    "        except ValueError:\n",
    "            print(f\"Skipping file {filename}: cannot parse singer and song name\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            midi_data = pretty_midi.PrettyMIDI(join(directory_path, filename))\n",
    "            \n",
    "            # Instrument features\n",
    "            instruments = midi_data.instruments\n",
    "            num_instruments = len(instruments)\n",
    "            instrument_ranges = [max(note.pitch for note in instrument.notes) - min(note.pitch for note in instrument.notes) if instrument.notes else 0 for instrument in instruments]\n",
    "            instrument_durations = [np.mean([note.end - note.start for note in instrument.notes]) if instrument.notes else 0 for instrument in instruments]\n",
    "            \n",
    "            # Music features\n",
    "            notes = [note for instrument in instruments for note in instrument.notes]\n",
    "            pitches = [note.pitch for note in notes]\n",
    "            durations = [note.end - note.start for note in notes]\n",
    "            velocities = [note.velocity for note in notes]\n",
    "            \n",
    "            melody_features_2 = np.array([\n",
    "                num_instruments,\n",
    "                np.mean(instrument_ranges) if instrument_ranges else 0,\n",
    "                np.mean(instrument_durations) if instrument_durations else 0,\n",
    "                len(notes),\n",
    "                np.mean(durations) if durations else 0,\n",
    "                (max(pitches) - min(pitches)) if pitches else 0,\n",
    "                np.mean(velocities) if velocities else 0,\n",
    "                midi_data.get_end_time(),\n",
    "                midi_data.estimate_tempo(),\n",
    "            ])\n",
    "            #print(len(melody_features_2))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            melody_features_2 = np.zeros(num_of_melody_features_2)\n",
    "\n",
    "        features_dict_2[(singer_name, song_name)] = melody_features_2\n",
    "        #features_dict[(singer_name, song_name)] = all_features\n",
    "\n",
    "\n",
    "    print(f\"Extracted melody features for {len(features_dict_2)} songs.\")\n",
    "    return features_dict_2, num_of_melody_features_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features_second(features_dict_2):\n",
    "    \"\"\"\n",
    "    Normalize the features with MinMaxScaler in the given features dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - features_dict (dict): A dictionary containing the features.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_features_dict (dict): A dictionary containing the normalized features.\n",
    "    \"\"\"\n",
    "    feature_matrix = np.array(list(features_dict_2.values()))\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_matrix = scaler.fit_transform(feature_matrix)\n",
    "    normalized_features_dict = {song: features for song, features in zip(features_dict_2.keys(), normalized_matrix)}\n",
    "    return normalized_features_dict\n",
    "\n",
    "\n",
    "def get_features_second(singer_name, song_name, normalized_features_dictionary_2):\n",
    "    \"\"\"\n",
    "    Get the normalized features for a given singer and song name.\n",
    "\n",
    "    Parameters:\n",
    "    - singer_name (str): The name of the singer.\n",
    "    - song_name (str): The name of the song.\n",
    "    - normalized_features_dictionary (dict): A dictionary containing the normalized features.\n",
    "\n",
    "    Returns:\n",
    "    - features (array-like): The normalized features for the given singer and song name, or \"Features not found\" if not found.\n",
    "    \"\"\"\n",
    "    key = (singer_name.lower().strip(), song_name.lower().strip())\n",
    "    return normalized_features_dictionary_2.get(key, \"Features not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|          | 7/625 [00:00<01:09,  8.89it/s]/home/kirmayer/.conda/envs/my_env/lib/python3.10/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n",
      "Extracting features:   3%|▎         | 19/625 [00:01<00:48, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Aaron_Neville_-_Tell_It_Like_It_Is.mid: data byte must be in range 0..127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 125/625 [00:13<00:40, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Beastie_Boys_-_Girls.mid: Could not decode key with 1 flats and mode 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 170/625 [00:18<00:35, 12.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Billy_Joel_-_Movin'_Out.mid: data byte must be in range 0..127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 172/625 [00:18<00:32, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Billy_Joel_-_Pressure.mid: data byte must be in range 0..127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 244/625 [00:26<00:27, 13.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Brian_McKnight_-_On_The_Down_Low.mid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 361/625 [00:38<00:25, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dan_Fogelberg_-_Leader_of_the_Band.mid: Could not decode key with 4 flats and mode 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|█████▉    | 370/625 [00:39<00:19, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing David_Bowie_-_Lazarus.mid: Could not decode key with 16 sharps and mode 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▌   | 408/625 [00:43<00:28,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file Ed_Sheeran_-_Thinking_Out_Loud_-_Violin.mid: cannot parse singer and song name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 444/625 [00:46<00:13, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file Eric_Clapton_-_wonderful_tonight_-_live_extnd_version_@jiji@.mid: cannot parse singer and song name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 625/625 [01:06<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted melody features for 623 songs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_dictionary_second, num_of_features_second = get_midi_data_second('midi_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features_dictionary_second= normalize_features_second(features_dictionary_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_tokenize_second(row, END_OF_LINE_TOKEN=\"<EOL>\", END_OF_FILE_TOKEN=\"<EOF>\"):\n",
    "    '''\n",
    "    Clean and tokenize the given row of lyrics.\n",
    "\n",
    "    Parameters:\n",
    "    - row (str): The row of lyrics to be cleaned and tokenized.\n",
    "    - END_OF_LINE_TOKEN (str): The token to represent the end of a line.\n",
    "    - END_OF_FILE_TOKEN (str): The token to represent the end of a file.\n",
    "\n",
    "    Returns:\n",
    "    - final_tokens (list): The cleaned and tokenized list of words.\n",
    "    '''\n",
    "\n",
    "    # Remove content inside square brackets []\n",
    "    row = re.sub(r'\\[.*?\\]', '', row)\n",
    "\n",
    "    # Remove content inside parentheses () with x+d, verse, or repeat\n",
    "    row = re.sub(r'\\(.*?x\\d+.*?\\)', '', row, flags=re.IGNORECASE)\n",
    "    row = re.sub(r'\\((.*?verse.*?|.*?repeat.*?)\\)', '', row, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace '&' with END_OF_LINE_TOKEN\n",
    "    row = row.replace(\"&\", f\" {END_OF_LINE_TOKEN} \")\n",
    "\n",
    "    # Split the row into tokens\n",
    "    tokens = row.split()\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    punctuation_table = str.maketrans('', '', string.punctuation)\n",
    "    processed_tokens = [\n",
    "        word if word == END_OF_LINE_TOKEN else word.translate(punctuation_table)\n",
    "        for word in tokens\n",
    "    ]\n",
    "    final_tokens = [\n",
    "        word if word == END_OF_LINE_TOKEN else word.lower()\n",
    "        for word in processed_tokens\n",
    "        if word.isalpha() or word.isdigit() or word == END_OF_LINE_TOKEN\n",
    "    ]\n",
    "\n",
    "    # Append END_OF_FILE_TOKEN at the end\n",
    "    final_tokens.append(END_OF_FILE_TOKEN)\n",
    "\n",
    "    return final_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_df_second(features_dictionary_2, csv_file_path):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - features_dictionary (dict): A dictionary containing the normalized features.\n",
    "    - csv_file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - dataset_df (DataFrame): The dataset dataframe.\n",
    "    '''\n",
    "    dataset_df = pd.read_csv(csv_file_path, header=None, usecols=[0, 1, 2])\n",
    "    dataset_df.rename(columns={0: 'Singer', 1: 'SongName', 2: 'Lyrics'}, inplace=True)\n",
    "\n",
    "    dataset_df['Lyrics'] = dataset_df['Lyrics'].apply(clean_and_tokenize_second)\n",
    "    dataset_df['Features'] = dataset_df.apply(lambda row: get_features_second(row['Singer'], row['SongName'], features_dictionary_2), axis=1)\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>SongName</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elton john</td>\n",
       "      <td>candle in the wind</td>\n",
       "      <td>[goodbye, norma, jean, &lt;EOL&gt;, though, i, never...</td>\n",
       "      <td>[0.29032258064516125, 0.2849002849002849, 0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gerry rafferty</td>\n",
       "      <td>baker street</td>\n",
       "      <td>[winding, your, way, down, on, baker, street, ...</td>\n",
       "      <td>[0.29032258064516125, 0.2863247863247863, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gerry rafferty</td>\n",
       "      <td>right down the line</td>\n",
       "      <td>[you, know, i, need, your, love, &lt;EOL&gt;, youve,...</td>\n",
       "      <td>[0.3225806451612903, 0.29358974358974355, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 unlimited</td>\n",
       "      <td>tribal dance</td>\n",
       "      <td>[come, on, check, it, out, yall, &lt;EOL&gt;, come, ...</td>\n",
       "      <td>[0.3548387096774194, 0.17482517482517482, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 unlimited</td>\n",
       "      <td>let the beat control your body</td>\n",
       "      <td>[let, the, beat, control, your, body, &lt;EOL&gt;, l...</td>\n",
       "      <td>[0.3548387096774194, 0.29137529137529133, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>don henley</td>\n",
       "      <td>dirty laundry</td>\n",
       "      <td>[i, make, my, living, off, the, evening, news,...</td>\n",
       "      <td>[0.16129032258064516, 0.22564102564102564, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>don henley</td>\n",
       "      <td>new york minute</td>\n",
       "      <td>[harry, got, up, &lt;EOL&gt;, dressed, all, in, blac...</td>\n",
       "      <td>[0.6774193548387096, 0.3144078144078144, 0.186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bob dylan</td>\n",
       "      <td>subterranean homesick blues</td>\n",
       "      <td>[johnnys, in, the, basement, &lt;EOL&gt;, mixing, up...</td>\n",
       "      <td>[0.29032258064516125, 0.22934472934472935, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>goldfinger</td>\n",
       "      <td>mable</td>\n",
       "      <td>[i, met, her, sunday, that, was, yesterday, &lt;E...</td>\n",
       "      <td>[0.22580645161290322, 0.27289377289377287, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>dr dre</td>\n",
       "      <td>forgot about dre</td>\n",
       "      <td>[yall, know, me, still, the, same, og, but, i,...</td>\n",
       "      <td>[0.25806451612903225, 0.15224358974358973, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Singer                        SongName  \\\n",
       "0        elton john              candle in the wind   \n",
       "1    gerry rafferty                    baker street   \n",
       "2    gerry rafferty             right down the line   \n",
       "3       2 unlimited                    tribal dance   \n",
       "4       2 unlimited  let the beat control your body   \n",
       "..              ...                             ...   \n",
       "595      don henley                   dirty laundry   \n",
       "596      don henley                 new york minute   \n",
       "597       bob dylan     subterranean homesick blues   \n",
       "598      goldfinger                           mable   \n",
       "599          dr dre                forgot about dre   \n",
       "\n",
       "                                                Lyrics  \\\n",
       "0    [goodbye, norma, jean, <EOL>, though, i, never...   \n",
       "1    [winding, your, way, down, on, baker, street, ...   \n",
       "2    [you, know, i, need, your, love, <EOL>, youve,...   \n",
       "3    [come, on, check, it, out, yall, <EOL>, come, ...   \n",
       "4    [let, the, beat, control, your, body, <EOL>, l...   \n",
       "..                                                 ...   \n",
       "595  [i, make, my, living, off, the, evening, news,...   \n",
       "596  [harry, got, up, <EOL>, dressed, all, in, blac...   \n",
       "597  [johnnys, in, the, basement, <EOL>, mixing, up...   \n",
       "598  [i, met, her, sunday, that, was, yesterday, <E...   \n",
       "599  [yall, know, me, still, the, same, og, but, i,...   \n",
       "\n",
       "                                              Features  \n",
       "0    [0.29032258064516125, 0.2849002849002849, 0.20...  \n",
       "1    [0.29032258064516125, 0.2863247863247863, 0.05...  \n",
       "2    [0.3225806451612903, 0.29358974358974355, 0.13...  \n",
       "3    [0.3548387096774194, 0.17482517482517482, 0.11...  \n",
       "4    [0.3548387096774194, 0.29137529137529133, 0.07...  \n",
       "..                                                 ...  \n",
       "595  [0.16129032258064516, 0.22564102564102564, 0.0...  \n",
       "596  [0.6774193548387096, 0.3144078144078144, 0.186...  \n",
       "597  [0.29032258064516125, 0.22934472934472935, 0.0...  \n",
       "598  [0.22580645161290322, 0.27289377289377287, 0.0...  \n",
       "599  [0.25806451612903225, 0.15224358974358973, 0.0...  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataset_df_second(normalized_features_dictionary_second, 'lyrics_train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29032258 0.28490028 0.20359285 0.19754749 0.45547235 0.47058824\n",
      " 0.7661793  0.38073131 0.84439485]\n"
     ]
    }
   ],
   "source": [
    "print(get_dataset_df_second(normalized_features_dictionary_second, 'lyrics_train_set.csv')[\"Features\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics_vocabulary_second(lyrics_list):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - lyrics_list (list): A list containing the lyrics.\n",
    "\n",
    "    Returns:\n",
    "    - vocabulary (set): A set containing the vocabulary of the lyrics.\n",
    "    '''\n",
    "    return set(word for lyrics in lyrics_list for word in lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocabulary_data_second(train_df, test_df, wv_model_path='word2vec.model'):\n",
    "    '''\n",
    "    Save the vocabulary data to a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - train_df (DataFrame): The training dataset.\n",
    "    - test_df (DataFrame): The testing dataset.\n",
    "    - wv_model_path (str): The path to the word2vec model.\n",
    "    '''\n",
    "    wv = word2vec_model\n",
    "\n",
    "    combined_vocab = get_lyrics_vocabulary_second(train_df['Lyrics']) | get_lyrics_vocabulary_second(test_df['Lyrics'])\n",
    "\n",
    "    embeddings_dict = {word: wv[word] for word in combined_vocab if word in wv}\n",
    "\n",
    "    missing_stopwords = [word for word in stopwords.words('english') if word not in embeddings_dict]\n",
    "    embeddings_dict.update({stopword: np.random.uniform(low=-1.0, high=1.0, size=(300,)) for stopword in missing_stopwords})\n",
    "\n",
    "    with open('embeddings_second.pickle', 'wb') as f:\n",
    "        pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_data_second():\n",
    "    '''\n",
    "    Load the vocabulary data from a pickle file.\n",
    "\n",
    "    Returns:\n",
    "    - embeddings_dict (dict): A dictionary containing the word embeddings.\n",
    "    - words (list): A list of words in the vocabulary.\n",
    "    - word_indices (dict): A dictionary mapping words to their indices.\n",
    "    - embeddings (list): A list of word embeddings.\n",
    "    - embedding_matrix (ndarray): A matrix of word embeddings.\n",
    "    - vocab_size (int): The size of the vocabulary.\n",
    "    - embedding_dim (int): The dimension of the word embeddings.\n",
    "    '''\n",
    "    with open('embeddings_second.pickle', 'rb') as f:\n",
    "        embeddings_dict = pickle.load(f)\n",
    "\n",
    "    #embeddings_dict[\"unk\"] = np.zeros((300,))\n",
    "\n",
    "    words = list(embeddings_dict.keys())\n",
    "    word_indices = {word: index for index, word in enumerate(words)}\n",
    "\n",
    "    embeddings = list(embeddings_dict.values())\n",
    "    embedding_matrix = np.vstack(embeddings)\n",
    "\n",
    "    vocab_size = len(words)\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "    print(\"Vocabulary size:\", vocab_size)\n",
    "    print(\"Embedding dimensions:\", embedding_dim)\n",
    "\n",
    "    return embeddings_dict, words, word_indices, embeddings, embedding_matrix, vocab_size, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6805\n",
      "Embedding dimensions: 300\n"
     ]
    }
   ],
   "source": [
    "train_df_second = get_dataset_df_second(normalized_features_dictionary_second, 'lyrics_train_set.csv')\n",
    "test_df_second = get_dataset_df_second(normalized_features_dictionary_second, 'lyrics_test_set.csv')\n",
    "\n",
    "save_vocabulary_data_second(train_df_second, test_df_second)\n",
    "\n",
    "embeddings_dict_second, words_second, word_indices_second, embeddings_second, embedding_matrix_second, vocab_size_second, embedding_dim_second = get_vocabulary_data_second()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_w2i_to_i2w_second(word_indices_second):\n",
    "    \"\"\"\n",
    "    Convert word indices to word dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - word_indices (dict): A dictionary mapping words to their indices.\n",
    "\n",
    "    Returns:\n",
    "    - indices_word (dict): A dictionary mapping indices to their corresponding words.\n",
    "    \"\"\"\n",
    "    indices_word = {v: k for k, v in word_indices_second.items()}\n",
    "    return indices_word\n",
    "\n",
    "indices_word_second = from_w2i_to_i2w_second(word_indices_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps On The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe_to_numeric(df):\n",
    "    '''\n",
    "    Convert the dataframe to a numeric dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The dataframe to be converted.\n",
    "\n",
    "    Returns:\n",
    "    - df_numeric (DataFrame): The numeric dataframe.\n",
    "    '''\n",
    "    df_numeric = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df_numeric = df_numeric.fillna(0)\n",
    "    return df_numeric\n",
    "\n",
    "\n",
    "def prepare_training_data(df, word_indices, sequence_size=10):\n",
    "    '''\n",
    "    Prepare the training data.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The dataframe to be converted.\n",
    "    - word_indices (dict): A dictionary mapping words to their indices.\n",
    "    - sequence_size (int): The size of the input sequence.\n",
    "\n",
    "    Returns:\n",
    "    - X (DataFrame): The input dataframe.\n",
    "    '''\n",
    "\n",
    "    def split_input_target(sequence, features):\n",
    "        '''\n",
    "        Split the input sequence and features into input rows.\n",
    "\n",
    "        Parameters:\n",
    "        - sequence (list): The input sequence.\n",
    "        - features (array): The features.\n",
    "\n",
    "        Returns:\n",
    "        - input_rows (list): The input rows.\n",
    "        '''\n",
    "\n",
    "        input_rows = []\n",
    "        input_seq = [word_indices.get('unk', 0)] * sequence_size\n",
    "        for i in range(1, len(sequence)):\n",
    "            input_seq.append(sequence[i-1])\n",
    "            input_seq = input_seq[1:]\n",
    "            input_rows.append(np.append(input_seq, features))\n",
    "        return input_rows\n",
    "\n",
    "    X_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        lyrics_indices = [word_indices.get(word, word_indices.get('unk', 0)) for word in row['Lyrics']]\n",
    "        features = row['Features']\n",
    "        input_rows = split_input_target(lyrics_indices, features)\n",
    "        X_list.extend(input_rows)\n",
    "\n",
    "    X = pd.DataFrame(X_list)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset for sequence data.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe_sequence (pd.DataFrame): A pandas DataFrame containing sequence data.\n",
    "\n",
    "    Attributes:\n",
    "    - data (torch.Tensor): Tensor representation of the sequence data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe_sequence):\n",
    "        self.data = torch.tensor(dataframe_sequence.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - int: Number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the sample at the given index.\n",
    "\n",
    "        Parameters:\n",
    "        - idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: The sample at the specified index.\n",
    "        \"\"\"\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class MelodyFeaturesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset for melody features.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe_melody (pd.DataFrame): A pandas DataFrame containing melody feature data.\n",
    "\n",
    "    Attributes:\n",
    "    - data (torch.Tensor): Tensor representation of the melody feature data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe_melody):\n",
    "        self.data = torch.tensor(dataframe_melody.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - int: Number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the sample at the given index.\n",
    "\n",
    "        Parameters:\n",
    "        - idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: The sample at the specified index.\n",
    "        \"\"\"\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lox-W57E0NOi"
   },
   "source": [
    "# Move to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "tqGp4-Pt0NOi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3242,  0.0425, -0.0615,  ..., -0.1289, -0.0021,  0.1289],\n",
       "        [-0.1426,  0.1641, -0.1709,  ..., -0.1689, -0.0703,  0.2471],\n",
       "        [ 0.3359,  0.1631, -0.0452,  ..., -0.0854,  0.2441, -0.0280],\n",
       "        ...,\n",
       "        [-0.9011, -0.5590, -0.2796,  ..., -0.1294,  0.7510,  0.2752],\n",
       "        [-0.1828,  0.1387,  0.6018,  ..., -0.7934, -0.8282,  0.8052],\n",
       "        [ 0.4023,  0.1453, -0.8555,  ...,  0.6176,  0.5266,  0.5414]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor = torch.tensor(embedding_matrix)\n",
    "embedding_matrix_cuda = torch_tensor.cuda()\n",
    "embedding_matrix_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3242,  0.0425, -0.0615,  ..., -0.1289, -0.0021,  0.1289],\n",
       "        [-0.1426,  0.1641, -0.1709,  ..., -0.1689, -0.0703,  0.2471],\n",
       "        [ 0.3359,  0.1631, -0.0452,  ..., -0.0854,  0.2441, -0.0280],\n",
       "        ...,\n",
       "        [ 0.8986,  0.9480,  0.6543,  ...,  0.3838, -0.4488, -0.5414],\n",
       "        [-0.4256, -0.7522,  0.3777,  ...,  0.1347, -0.1928, -0.7852],\n",
       "        [-0.6574,  0.6713,  0.2547,  ..., -0.6875,  0.3018,  0.7365]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor_second = torch.tensor(embedding_matrix_second)\n",
    "embedding_matrix_cuda_second = torch_tensor_second.cuda()\n",
    "embedding_matrix_cuda_second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4X78DNM0NOi"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "nWfMr0tz0NOi"
   },
   "outputs": [],
   "source": [
    "class LyricsGeneratorModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A class representing a lyrics generator model.\n",
    "\n",
    "    Parameters:\n",
    "    - num_of_melody_features : The number of melody features.\n",
    "    - vocab_size : The size of the vocabulary.\n",
    "    - embedding_dim : The dimension of the word embeddings.\n",
    "    - embedding_matrix : The pre-trained word embedding matrix.\n",
    "    - hidden_size : The size of the hidden state in the LSTM layer.\n",
    "    - dropout_rate : The dropout rate.\n",
    "\n",
    "    Attributes:\n",
    "    - word_embedding : The word embedding matrix.\n",
    "    - lstm : The LSTM layer.\n",
    "    - fc : The fully connected layer.\n",
    "    - hidden_size : The size of the hidden state in the LSTM layer.\n",
    "    - dropout : The dropout layer.\n",
    "\n",
    "    Methods:\n",
    "    - forward(word_input, melody_input, hidden=None, return_h=False, seq_len=10): Forward pass of the model.\n",
    "    - init_hidden(batch_size): Initialize the hidden state of the LSTM layer.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_of_melody_features, vocab_size, embedding_dim, embedding_matrix, hidden_size=256, dropout_rate=0.0):\n",
    "        super(LyricsGeneratorModel, self).__init__()\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device = device\n",
    "        self.word_embedding = embedding_matrix\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim + num_of_melody_features, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=vocab_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, word_input, melody_input, hidden=None, return_h=False, seq_len=10):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Parameters:\n",
    "        - word_input: The input for the word sequence.\n",
    "        - melody_input : The input for the melody features.\n",
    "        - hidden: The hidden state of the LSTM layer.\n",
    "        - return_h : Whether to return the hidden state.\n",
    "        - seq_len : The length of the input sequence.\n",
    "\n",
    "        Returns:\n",
    "        - logits (torch.Tensor): The output logits.\n",
    "        - hidden (tuple): The hidden state of the LSTM layer.\n",
    "\n",
    "        \"\"\"\n",
    "        word_embedded = self.word_embedding[word_input]\n",
    "        actual_seq_len = word_embedded.size(1)\n",
    "        melody_input = melody_input.unsqueeze(1).repeat(1, actual_seq_len, 1)\n",
    "        combined_input = torch.cat((word_embedded, melody_input), dim=-1).float()\n",
    "\n",
    "        if hidden is not None:\n",
    "            hidden = (hidden[0].to(combined_input.device), hidden[1].to(combined_input.device))\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(combined_input.size(0))\n",
    "\n",
    "        lstm_output, hidden = self.lstm(combined_input, hidden)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "        logits = self.fc(lstm_output)\n",
    "\n",
    "        if return_h:\n",
    "            return logits, hidden\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state of the LSTM layer.\n",
    "\n",
    "        Parameters:\n",
    "        - batch_size : The batch size.\n",
    "\n",
    "        Returns:\n",
    "        - hidden : The initialized hidden state.\n",
    "\n",
    "        \"\"\"\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=self.device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size, device=self.device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "rdBUfknz0NOi"
   },
   "outputs": [],
   "source": [
    "def train_model(model,df,word_indices_array, sequence_length=10,batch_size=32, epochs=25, lr=1e-3, weight_decay=1e-5, patience=10):\n",
    "\n",
    "    \"\"\"\n",
    "    Train the specified model using the provided data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to be trained.\n",
    "    - df: The dataframe containing the training data.\n",
    "    - sequence_length: The length of the input sequence.\n",
    "    - batch_size: The batch size for training.\n",
    "    - epochs: The number of epochs to train for.\n",
    "    - lr: The learning rate for the optimizer.\n",
    "    - weight_decay: The weight decay for the optimizer.\n",
    "    - patience: The number of epochs to wait for improvement in validation loss before early stopping.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    preperd_df = prepare_training_data(df, word_indices_array , sequence_length)\n",
    "\n",
    "    column_names = preperd_df.columns.tolist()\n",
    "\n",
    "    sequence_columns = column_names[0:sequence_length]\n",
    "    melody_features_columns = column_names[sequence_length:]\n",
    "\n",
    "    sequence_df = preperd_df[sequence_columns]\n",
    "    melody_features_df = preperd_df[melody_features_columns]\n",
    "\n",
    "\n",
    "    sequence_df_numeric = convert_dataframe_to_numeric(sequence_df)\n",
    "    melody_features_df_numeric = convert_dataframe_to_numeric(melody_features_df)\n",
    "\n",
    "\n",
    "    sequence_dataset = SequenceDataset(sequence_df_numeric)\n",
    "    melody_features_dataset = MelodyFeaturesDataset(melody_features_df_numeric)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    dataset_size = len(sequence_dataset)\n",
    "    val_split = int(np.floor(0.15 * dataset_size))\n",
    "    train_split = dataset_size - val_split\n",
    "\n",
    "    train_sequence_dataset, val_sequence_dataset = random_split(sequence_dataset, [train_split, val_split])\n",
    "    train_melody_features_dataset, val_melody_features_dataset = random_split(melody_features_dataset, [train_split, val_split])\n",
    "\n",
    "    train_sequence_loader = DataLoader(train_sequence_dataset, batch_size=batch_size, shuffle=True)\n",
    "    train_melody_features_loader = DataLoader(train_melody_features_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_sequence_loader = DataLoader(val_sequence_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_melody_features_loader = DataLoader(val_melody_features_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on {device}\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    directory_name = f\"model_d_{dropout}_sq_{sequence_length}_bs_{batch_size}_hs_{hidden_size}_lr_{lr}\"\n",
    "    writer = SummaryWriter(log_dir=f'{directory_name}')\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        combined_train_loader = zip(train_sequence_loader, train_melody_features_loader)\n",
    "\n",
    "        for batch, melody_batch in tqdm(combined_train_loader, total=len(train_sequence_loader),\n",
    "                                        desc=f\"Epoch {epoch + 1} - Training\", unit=\"batch\"):\n",
    "\n",
    "            x = batch[:, :-1].long().to(device)\n",
    "            y = batch[:, 1:].long().to(device)\n",
    "            melody_input_batch = melody_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x, melody_input_batch).to(device)\n",
    "            loss = criterion(outputs.transpose(1, 2), y)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        combined_val_loader = zip(val_sequence_loader, val_melody_features_loader)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch, melody_batch in tqdm(combined_val_loader, total=len(val_sequence_loader),\n",
    "                                            desc=f\"Epoch {epoch + 1} - Validation\", unit=\"batch\"):\n",
    "                x_val = batch[:, :-1].long().to(device)\n",
    "                y_val = batch[:, 1:].long().to(device)\n",
    "                melody_input_batch_val = melody_batch.to(device)\n",
    "\n",
    "                outputs_val = model(x_val, melody_input_batch_val).to(device)\n",
    "                loss_val = criterion(outputs_val.transpose(1, 2), y_val)\n",
    "\n",
    "                val_running_loss += loss_val.item()\n",
    "\n",
    "        train_avg_loss = train_running_loss / len(train_sequence_loader)\n",
    "        val_avg_loss = val_running_loss / len(val_sequence_loader)\n",
    "\n",
    "        writer.add_scalar('Loss/train', train_avg_loss, epoch)\n",
    "        writer.add_scalar('Loss/validation', val_avg_loss, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} completed, Training Loss: {train_avg_loss}, Validation Loss: {val_avg_loss}\")\n",
    "\n",
    "        if val_avg_loss < best_val_loss:\n",
    "            best_val_loss = val_avg_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Validation loss hasn't improved for {patience} epochs. Stopping early.\")\n",
    "                break\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcBXEV9A0NOj"
   },
   "source": [
    "# Prepare Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "PmKBao6b0NOj",
    "outputId": "02150b7f-96a1-4a9a-bdfb-4b4f5c64e21f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2639, 899, 5635, 6339, 1017, 899, 3399, 6443, 0, 1076, 3822, 6497, 6590, 1372, 5075, 0, 1076, 3822, 5247, 0, 1076, 3822, 6497, 4089, 6146, 0, 5735, 1964, 5662, 2824, 0, 5882, 931, 553, 855, 6479, 634, 0, 1964, 5546, 192, 5022, 6765, 3540, 6443, 0, 1964, 4376, 3822, 5318, 3822, 3605, 367, 0, 3822, 1885, 225, 1017, 0, 1076, 3822, 6497, 4089, 6146, 0, 5735, 1964, 5662, 2824, 0, 3623, 5882, 931, 553, 855, 6479, 634, 0, 5193, 6590, 1503, 2731, 6110, 517, 4089, 4375, 0, 6762, 4437, 4968, 2250, 3250, 0, 6763, 2025, 3822, 4843, 6763, 4612, 4089, 5679, 0, 1964, 336, 1915, 6765, 4829, 931, 1336, 0, 0], array([0.00273224, 0.36666676, 0.        , 0.28852421, 0.36666676,\n",
      "       0.36666676, 1.        , 1.        , 0.10592051, 0.24096955,\n",
      "       0.00523077, 0.69189946])]\n"
     ]
    }
   ],
   "source": [
    "def lyrics_to_indices(lyrics, word_indices):\n",
    "    '''Conver lyrics to indices using the word_indices dictionary.'''\n",
    "    return [word_indices.get(word, word_indices.get('unk', 0)) for word in lyrics]\n",
    "\n",
    "\n",
    "preperd_test = [[lyrics_to_indices(row['Lyrics'], word_indices), row['Features']] for _, row in test_df.iterrows()]\n",
    "\n",
    "print(preperd_test[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2639, 899, 5635, 6339, 1017, 899, 3399, 6443, 0, 1076, 3822, 6497, 6590, 1372, 5075, 0, 1076, 3822, 5247, 0, 1076, 3822, 6497, 4089, 6146, 0, 5735, 1964, 5662, 2824, 0, 5882, 931, 553, 855, 6479, 634, 0, 1964, 5546, 192, 5022, 6765, 3540, 6443, 0, 1964, 4376, 3822, 5318, 3822, 3605, 367, 0, 3822, 1885, 225, 1017, 0, 1076, 3822, 6497, 4089, 6146, 0, 5735, 1964, 5662, 2824, 0, 3623, 5882, 931, 553, 855, 6479, 634, 0, 5193, 6590, 1503, 2731, 6110, 517, 4089, 4375, 0, 6762, 4437, 4968, 2250, 3250, 0, 6763, 2025, 3822, 4843, 6763, 4612, 4089, 5679, 0, 1964, 336, 1915, 6765, 4829, 931, 1336, 0, 0], array([0.32258065, 0.13076923, 0.11686103, 0.10060111, 0.39328317,\n",
      "       0.49019608, 0.79420665, 0.26967225, 0.67029533])]\n"
     ]
    }
   ],
   "source": [
    "def lyrics_to_indices_second(lyrics, word_indices_second):\n",
    "    '''Conver lyrics to indices using the word_indices dictionary.'''\n",
    "    return [word_indices_second.get(word, word_indices_second.get('unk', 0)) for word in lyrics]\n",
    "\n",
    "\n",
    "#list of list of list -> [[lyrics_indices, features], ...]\n",
    "preperd_test_second = [[lyrics_to_indices_second(row['Lyrics'], word_indices_second), row['Features']] for _, row in test_df_second.iterrows()]\n",
    "\n",
    "print(preperd_test_second[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZhu3_040NOj"
   },
   "source": [
    "# Generate New Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258.07166666666666\n"
     ]
    }
   ],
   "source": [
    "#calculate the average length of training songs\n",
    "def calculate_length_without_special_tokens(tokens):\n",
    "    '''Function to calculate the length without <EOL> and <EOS>'''\n",
    "    return len([token for token in tokens if token not in ('<EOL>', '<EOS>')])\n",
    "\n",
    "lengths = train_df['Lyrics'].apply(calculate_length_without_special_tokens)\n",
    "average_length = lengths.mean()\n",
    "print(average_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "7UUcgWRd0NOj"
   },
   "outputs": [],
   "source": [
    "def generate_lyrics_from_indices(model, lyrics_indices, song_features, indices_word_array, num_words=100):\n",
    "    \"\"\"\n",
    "    Generate lyrics for a single song using the specified model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to be used for generating lyrics.\n",
    "    - lyrics_indices: The lyrics of the song as a list of indices.\n",
    "    - song_features: The features of the song as a list.\n",
    "    - indices_word: The dictionary mapping indices to words.\n",
    "    - num_words: The number of words to generate.\n",
    "\n",
    "    Returns:\n",
    "    - generated_lyrics: The generated lyrics.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generated_lyrics = []\n",
    "\n",
    "    \n",
    "\n",
    "    # Convert lyrics_indices to a tensor\n",
    "    sequence = torch.tensor(lyrics_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # Safely convert song_features to float and create a tensor\n",
    "    try:\n",
    "        melody_features = torch.tensor([float(item) for item in song_features], dtype=torch.float).unsqueeze(0).to(device)\n",
    "    except ValueError as e:\n",
    "        print(\"Error converting song_features to float:\", e)\n",
    "        raise\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(sequence.size(0))\n",
    "\n",
    "        # Start with the first word\n",
    "        first_word = sequence[0, 0].item()\n",
    "        generated_lyrics.append(indices_word_array[first_word])\n",
    "        input_word = torch.tensor([[first_word]], dtype=torch.long, device=device)\n",
    "\n",
    "        # Generate new words\n",
    "        for _ in range(num_words):\n",
    "            output, hidden = model(input_word, melody_features, hidden, return_h=True, seq_len=2)\n",
    "            output = output.squeeze(0)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=-1)\n",
    "            word_idx = torch.multinomial(probabilities, num_samples=1).item()\n",
    "            generated_lyrics.append(indices_word_array[word_idx])\n",
    "            input_word = torch.tensor([[word_idx]], dtype=torch.long, device=device)\n",
    "            if indices_word_array[word_idx] == \"<EOF>\":\n",
    "                break\n",
    "\n",
    "    return \" \".join(generated_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics_from_indices_single_word(model, start_word, song_features, word_indices_array ,indices_word_array, num_words=100):\n",
    "    \"\"\"\n",
    "    Generate lyrics for a single song using the specified model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to be used for generating lyrics.\n",
    "    - lyrics_indices: The lyrics of the song as a list of indices.\n",
    "    - song_features: The features of the song as a list.\n",
    "    - indices_word: The dictionary mapping indices to words.\n",
    "    - num_words: The number of words to generate.\n",
    "\n",
    "    Returns:\n",
    "    - generated_lyrics: The generated lyrics.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generated_lyrics = []\n",
    "\n",
    "\n",
    "\n",
    "    # Convert start_word to its index\n",
    "    try:\n",
    "        start_word_idx = word_indices_array[start_word]\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: '{start_word}' not found in word_indices_array.\")\n",
    "        raise\n",
    "\n",
    "\n",
    "    # Safely convert song_features to float and create a tensor\n",
    "    try:\n",
    "        melody_features = torch.tensor([float(item) for item in song_features], dtype=torch.float).unsqueeze(0).to(device)\n",
    "    except ValueError as e:\n",
    "        print(\"Error converting song_features to float:\", e)\n",
    "        raise\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        hidden = model.init_hidden(1)\n",
    "\n",
    "        generated_lyrics.append(start_word)\n",
    "        input_word = torch.tensor([[start_word_idx]], dtype=torch.long, device=device)\n",
    "\n",
    "        # Generate new words\n",
    "        for _ in range(num_words):\n",
    "            output, hidden = model(input_word, melody_features, hidden, return_h=True, seq_len=2)\n",
    "            output = output.squeeze(0)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=-1)\n",
    "            word_idx = torch.multinomial(probabilities, num_samples=1).item()\n",
    "            generated_lyrics.append(indices_word_array[word_idx])\n",
    "            input_word = torch.tensor([[word_idx]], dtype=torch.long, device=device)\n",
    "            if indices_word_array[word_idx] == \"<EOF>\":\n",
    "                break\n",
    "\n",
    "    return \" \".join(generated_lyrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxgEmD4_0NOj"
   },
   "source": [
    "# Eveluation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "YrC2HNKX0NOk"
   },
   "outputs": [],
   "source": [
    "from gensim.similarities import WmdSimilarity\n",
    "\n",
    "\n",
    "class SongEvaluation:\n",
    "    \"\"\"\n",
    "    A class for evaluating the similarity between original and generated song lyrics.\n",
    "\n",
    "    Parameters:\n",
    "    - original_lyrics : The original lyrics of the song.\n",
    "    - generated_lyrics : The generated lyrics of the song.\n",
    "\n",
    "    Methods:\n",
    "    - jaccard_similarity(): Calculate the Jaccard similarity between the original and generated lyrics.\n",
    "    - cosine_similarity(): Calculate the cosine similarity between the original and generated lyrics.\n",
    "    - bleu_score(): Calculate the BLEU score between the original and generated lyrics.\n",
    "    - evaluate(): Evaluate the similarity between the original and generated lyrics using multiple metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, original_lyrics, generated_lyrics,indices_word_array  ):\n",
    "        self.original_lyrics = original_lyrics\n",
    "        self.generated_lyrics = generated_lyrics\n",
    "\n",
    "        self.original_lyrics = [indices_word_array[token] for token in original_lyrics]\n",
    "        self.original_lyrics = ' '.join(self.original_lyrics)\n",
    "\n",
    "        self.vectorizer = TfidfVectorizer().fit([self.original_lyrics, self.generated_lyrics])\n",
    "\n",
    "\n",
    "    def jaccard_similarity(self):\n",
    "        \"\"\"\n",
    "        Calculate the Jaccard similarity between the original and generated lyrics.\n",
    "\n",
    "        Returns:\n",
    "        - similarity : The Jaccard similarity score.\n",
    "        \"\"\"\n",
    "        original_set = set(self.original_lyrics.split())\n",
    "        generated_set = set(self.generated_lyrics.split())\n",
    "        intersection = original_set.intersection(generated_set)\n",
    "        union = original_set.union(generated_set)\n",
    "        if union == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return len(intersection) / len(union)\n",
    "\n",
    "    def cosine_similarity(self):\n",
    "        \"\"\"\n",
    "        Calculate the cosine similarity between the original and generated lyrics.\n",
    "\n",
    "        Returns:\n",
    "        - similarity : The cosine similarity score.\n",
    "        \"\"\"\n",
    "        original_vector = self.vectorizer.transform([self.original_lyrics])\n",
    "        generated_vector = self.vectorizer.transform([self.generated_lyrics])\n",
    "        similarity = cosine_similarity(original_vector, generated_vector)[0][0]\n",
    "        return similarity\n",
    "\n",
    "    def levenshtain_distance(self):\n",
    "        distance = Levenshtein.distance(self.original_lyrics, self.generated_lyrics)\n",
    "        max_len = max(len(self.original_lyrics), len(self.generated_lyrics))\n",
    "        similarity = 1 - (distance / max_len)\n",
    "        return similarity\n",
    "\n",
    "\n",
    "    def polarity_similarity(self):\n",
    "        \"\"\"\n",
    "        Compare the sentiment of two songs and generate a comparative score.\n",
    "    \n",
    "        Returns:\n",
    "        - score: A comparative score between 0 and 1 indicating the relative positivity of the songs.\n",
    "        \"\"\"\n",
    "        \n",
    "        def analyze_sentiment(text):\n",
    "            blob = TextBlob(text)\n",
    "            polarity = blob.sentiment.polarity\n",
    "            return polarity\n",
    "    \n",
    "        polarity1 = analyze_sentiment(self.original_lyrics)\n",
    "        polarity2 = analyze_sentiment(self.generated_lyrics)\n",
    "    \n",
    "        score = (polarity1 - polarity2 + 1) / 2 \n",
    "        return score\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate the similarity between the original and generated lyrics using multiple metrics.\n",
    "\n",
    "        Returns:\n",
    "        - evaluation : A dictionary containing the evaluation metrics.\n",
    "        \"\"\"\n",
    "        jaccard = self.jaccard_similarity()\n",
    "        cosine = self.cosine_similarity()\n",
    "        levenshtain = self.levenshtain_distance()\n",
    "        polarity = self.polarity_similarity()\n",
    "        evaluation = {\n",
    "            'Jaccard Similarity': jaccard,\n",
    "            'Cosine Similarity': cosine,\n",
    "            'Levenshtain Distance': levenshtain,\n",
    "            'Polarity Similarity': polarity\n",
    "        }\n",
    "        return evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-4ortSB0NOk"
   },
   "source": [
    "# Grid Search - Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "IioaViVQ0NOk"
   },
   "outputs": [],
   "source": [
    "dropouts = [0, 0.5, 0.8]\n",
    "Sequence_Length = [4, 10, 20]\n",
    "batch_sizes = [32, 64]\n",
    "hidden_sizes = [64, 256]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "LilvoIzd0NOq"
   },
   "outputs": [],
   "source": [
    "#creating a folder to save all the models\n",
    "model_save_dir = 'saved_models_first'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "#creating a folder to save all the models\n",
    "model_save_second_dir = 'saved_models_second'\n",
    "os.makedirs(model_save_second_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "# average_length=258\n",
    "print(int(average_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "4CmdkWq60NOq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 390.87batch/s]\n",
      "Epoch 1 - Validation: 100%|██████████| 418/418 [00:00<00:00, 831.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Training Loss: 5.486697989336784, Validation Loss: 5.033754304265291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 390.28batch/s]\n",
      "Epoch 2 - Validation: 100%|██████████| 418/418 [00:00<00:00, 831.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed, Training Loss: 5.0341668225746075, Validation Loss: 4.747548977153723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 390.79batch/s]\n",
      "Epoch 3 - Validation: 100%|██████████| 418/418 [00:00<00:00, 830.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed, Training Loss: 4.8432249684162425, Validation Loss: 4.57907056466244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 390.33batch/s]\n",
      "Epoch 4 - Validation: 100%|██████████| 418/418 [00:00<00:00, 824.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed, Training Loss: 4.724562450997674, Validation Loss: 4.466285695299577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 389.85batch/s]\n",
      "Epoch 5 - Validation: 100%|██████████| 418/418 [00:00<00:00, 825.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed, Training Loss: 4.645577523269814, Validation Loss: 4.3884404435682525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 389.29batch/s]\n",
      "Epoch 6 - Validation: 100%|██████████| 418/418 [00:00<00:00, 827.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed, Training Loss: 4.589219417934942, Validation Loss: 4.332691910164208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 389.19batch/s]\n",
      "Epoch 7 - Validation: 100%|██████████| 418/418 [00:00<00:00, 829.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed, Training Loss: 4.5464736752983885, Validation Loss: 4.285632624580529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 390.59batch/s]\n",
      "Epoch 8 - Validation: 100%|██████████| 418/418 [00:00<00:00, 829.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed, Training Loss: 4.512780748411666, Validation Loss: 4.25027350261451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 391.08batch/s]\n",
      "Epoch 9 - Validation: 100%|██████████| 418/418 [00:00<00:00, 827.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed, Training Loss: 4.4855670939036205, Validation Loss: 4.219914248115138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 389.80batch/s]\n",
      "Epoch 10 - Validation: 100%|██████████| 418/418 [00:00<00:00, 830.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed, Training Loss: 4.463088955183614, Validation Loss: 4.197054765441201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 390.96batch/s]\n",
      "Epoch 11 - Validation: 100%|██████████| 418/418 [00:00<00:00, 831.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed, Training Loss: 4.442245739862228, Validation Loss: 4.171120981280313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 390.53batch/s]\n",
      "Epoch 12 - Validation: 100%|██████████| 418/418 [00:00<00:00, 832.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed, Training Loss: 4.424725138763041, Validation Loss: 4.1529319639981646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 389.10batch/s]\n",
      "Epoch 13 - Validation: 100%|██████████| 418/418 [00:00<00:00, 830.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed, Training Loss: 4.4096916095903005, Validation Loss: 4.136028301772889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 389.92batch/s]\n",
      "Epoch 14 - Validation: 100%|██████████| 418/418 [00:00<00:00, 829.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed, Training Loss: 4.395783905146238, Validation Loss: 4.119661716182836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 390.22batch/s]\n",
      "Epoch 15 - Validation: 100%|██████████| 418/418 [00:00<00:00, 826.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed, Training Loss: 4.383605491888195, Validation Loss: 4.1062985846870825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 389.82batch/s]\n",
      "Epoch 16 - Validation: 100%|██████████| 418/418 [00:00<00:00, 828.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed, Training Loss: 4.372171779818061, Validation Loss: 4.093171076911489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 389.57batch/s]\n",
      "Epoch 17 - Validation: 100%|██████████| 418/418 [00:00<00:00, 827.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed, Training Loss: 4.362191834762283, Validation Loss: 4.086322585931805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 384.48batch/s]\n",
      "Epoch 18 - Validation: 100%|██████████| 418/418 [00:00<00:00, 827.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed, Training Loss: 4.353116858282754, Validation Loss: 4.074933592212258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 382.60batch/s]\n",
      "Epoch 19 - Validation: 100%|██████████| 418/418 [00:00<00:00, 827.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed, Training Loss: 4.345220410546591, Validation Loss: 4.0638860378539166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 383.12batch/s]\n",
      "Epoch 20 - Validation: 100%|██████████| 418/418 [00:00<00:00, 825.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed, Training Loss: 4.3366131119193785, Validation Loss: 4.0555506459833905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 382.88batch/s]\n",
      "Epoch 21 - Validation: 100%|██████████| 418/418 [00:00<00:00, 826.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed, Training Loss: 4.32945128495295, Validation Loss: 4.04801068864941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 385.31batch/s]\n",
      "Epoch 22 - Validation: 100%|██████████| 418/418 [00:00<00:00, 824.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed, Training Loss: 4.323116757048109, Validation Loss: 4.04004934301787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 384.97batch/s]\n",
      "Epoch 23 - Validation: 100%|██████████| 418/418 [00:00<00:00, 829.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed, Training Loss: 4.317066631962331, Validation Loss: 4.034466094947888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 386.70batch/s]\n",
      "Epoch 24 - Validation: 100%|██████████| 418/418 [00:00<00:00, 828.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed, Training Loss: 4.30994603296163, Validation Loss: 4.0302414894104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 385.35batch/s]\n",
      "Epoch 25 - Validation: 100%|██████████| 418/418 [00:00<00:00, 825.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed, Training Loss: 4.304918331827724, Validation Loss: 4.021757704789558\n",
      "Finished Training\n",
      "Model saved as model_d_0.5_sq_10_bs_64_hs_64_lr_0.001.pth\n",
      "close my shoes in my legs jackets its straight in a little piece im a new kid jackets i never never that jackets i can say jackets id love to do the you jackets ill be your fantasy jackets a girl a man was happy jackets every day apply the way over the scars and the eyes jackets and your desire come back to me jackets i got my weed my head and go and she cried jackets happy and by me jackets one jackets when he breaks a reckon of rain jackets dylan is a funny the power of through jackets backwards them and premature and the sight right up jackets and two hit at the next train with a bulletproof down jackets its forty words my own jackets but you so a glance man jackets what i dont do to it jackets my name is jackets oh jackets and i fell up in his eye jackets are love jackets changed he people down jackets gentle image of me jackets jackets jackets im gone jackets the time is so you and you jackets i want my four jackets will be all with myself somebody how you wake sometimes now let jackets do just take to see us jackets i beg you could give me at a show more lightning jackets i in you on jackets my shoes jackets i makes to go jackets save each at everything of hungry jackets hey i am never wrong jackets i know where is here now time they found jackets oh jackets\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1768\n",
      "Cosine Similarity: 0.7525\n",
      "Levenshtain Distance: 0.3131\n",
      "Polarity Similarity: 0.3966\n",
      "if i thought i had someone been talking youre in a contender for week jackets wish just just let go on to me jackets done it livin on me jackets but i really say im my lovin jackets crime jackets i think you were love me jackets i did seem very ive got a breath on the floor thing jackets right for you i wear jackets with the heart believe every more jackets part that jackets tried to forget and empty jackets and youre halfway that love you jackets jackets jackets jackets jackets jackets jackets jackets jackets war jackets jackets di di amor da jackets five jackets we jackets the gift eleven nota impatiently jackets vodka jackets spock jackets puttin it jackets dart are tired my life in device jackets or my from the love jackets let you see him dont anything be her a bootie jackets even dying rag and says jackets misty thats getting tough jackets eat it in where my way youre going to heart jackets i will make it time jackets they could say me im not jackets there im over my just jackets you can be confused jackets too flesh shell down help it say goodbye jackets ive been waiting for you and i may never be someone jackets meet me september the finest bitch star jackets give the future use me okay jackets try it to the things if you ever think jackets jackets if i got in on right jackets i dont want to do a way of my world with my\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1795\n",
      "Cosine Similarity: 0.7799\n",
      "Levenshtain Distance: 0.3491\n",
      "Polarity Similarity: 0.4495\n",
      "dear jackets in an caught night jackets she is the key dirty flows for a placed to the choice jackets everything can do that to you dont jackets do the voice loose shit and decide jackets and youre a sucks mommy pregnant jackets when tomorrow that night move who it jackets so come down to me its to take it jackets this time jackets just baby and are i avalanche jackets it jackets if i saw jackets and a lu bop jackets kick wit and servant in a head jackets he just eases so that im going jackets down the jackets and im eve gonna give another kisses jackets jackets hang on the rocking by and still seems that pack jackets larger drinkin hoo jackets one ever of your love love me itll jackets but the way more more on jackets lets go around jackets let the dance jackets you see it jackets but youre whatever each day im water jackets hm here jackets recover jackets hey remember youll jackets we go the years under the fare and this begging in the door jackets well never know jackets the door love to this jackets a quiet jackets would you tell me you going go jackets you may go jackets and and bazaar was sorry so long jackets its like heaven jackets oh oh baby jackets time time of time jackets they did be confused jackets a song this i very i felt and i got me thinkin you got me of the pressure you want jackets now dancing my\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1421\n",
      "Cosine Similarity: 0.6470\n",
      "Levenshtain Distance: 0.3787\n",
      "Polarity Similarity: 0.6785\n",
      "hiya leon eve jackets the months it must wasted jackets well im wrong jackets and that youll be time jackets to find nothing yesterday but jackets let me be jackets ill love you jackets dont think you can do jackets never i ever say jackets but i love you jackets yo ohh jackets but we feel jackets do you let me dont want to show me jackets and baby our dont wanna look jackets i believe i was strong jackets jackets dont you know to you wrongs to you yeah jackets its what i make it to know you really call me yeah jackets step home jackets baby and my mind will hide jackets reluctantly and strong actors in the jackets all runway up but moan the brush a jingling jackets i thought you say i love think you jackets the good is left your arms love will love of my way jackets way by as another dimension jackets when you intentions a whole jackets hi at the line percent jackets and i love you jackets i will never know you now somethin so a thousand girl jackets forgive me know so i dont talk me all right jackets cause i am she where is jackets friends i just cant grow and beg your number of a jackets man camel ill die please jackets you dont let me never jackets to make it wonder that youre i jackets i swear jackets oh out jackets so the last far dil um yeah jackets yeah jackets rock today not you say\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.2011\n",
      "Cosine Similarity: 0.5888\n",
      "Levenshtain Distance: 0.3415\n",
      "Polarity Similarity: 0.5550\n",
      "all youre nice to stay and mondays jackets right bout now jackets its a little i do you dont know its stronger jackets oh yeah yeah oh yeah oh jackets jackets jackets jackets jackets jackets jackets jackets even im diesel open jackets she can my beat control you jackets i really to find me jackets yeah got nothing missing to come up jackets all in me jackets woohoo she played with her jackets my barking dogs a long big passing jackets ive got a white tank and now hates the my eyes jackets im in your love thats my name jackets escapes im gonna be in then jackets with the rebel and the stars know jackets baby jackets i miss you jackets no set him movin and richard jackets and the ship to really jackets for that a thing are the jackets style jackets gettin will nobody quite kid jackets i wish you a place a friend jackets and that im on aware jackets baby the way of havana jackets ive been a dream jackets but you know is you jackets til jackets are in a ransom in his seed jackets world conventionality crown jackets jackets to get down jackets do you idiots call jackets give a far dance up jackets everyone much hearing jackets jackets on my heart feel going jackets you never knew jackets more to get the people jackets i want this baby jackets something jackets razor jackets you swear and the best thing hes jackets more just i cant find out you keep day bring\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.0904\n",
      "Cosine Similarity: 0.5161\n",
      "Levenshtain Distance: 0.3833\n",
      "Polarity Similarity: 0.3601\n",
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 283.05batch/s]\n",
      "Epoch 1 - Validation: 100%|██████████| 418/418 [00:00<00:00, 513.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Training Loss: 5.199724548815673, Validation Loss: 4.6687049763054365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 282.87batch/s]\n",
      "Epoch 2 - Validation: 100%|██████████| 418/418 [00:00<00:00, 512.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed, Training Loss: 4.717469829938376, Validation Loss: 4.392657794450459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 282.17batch/s]\n",
      "Epoch 3 - Validation: 100%|██████████| 418/418 [00:00<00:00, 510.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed, Training Loss: 4.542032877738581, Validation Loss: 4.232339803111611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 281.35batch/s]\n",
      "Epoch 4 - Validation: 100%|██████████| 418/418 [00:00<00:00, 510.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed, Training Loss: 4.433991944109411, Validation Loss: 4.123706757166739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 280.09batch/s]\n",
      "Epoch 5 - Validation: 100%|██████████| 418/418 [00:00<00:00, 509.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed, Training Loss: 4.358318296497014, Validation Loss: 4.051117412211222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 279.85batch/s]\n",
      "Epoch 6 - Validation: 100%|██████████| 418/418 [00:00<00:00, 509.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed, Training Loss: 4.3067522121534285, Validation Loss: 3.9947780519010916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 279.04batch/s]\n",
      "Epoch 7 - Validation: 100%|██████████| 418/418 [00:00<00:00, 510.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed, Training Loss: 4.265545064651941, Validation Loss: 3.949827133183274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 278.06batch/s]\n",
      "Epoch 8 - Validation: 100%|██████████| 418/418 [00:00<00:00, 505.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed, Training Loss: 4.232639155579419, Validation Loss: 3.9094282554097153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 276.40batch/s]\n",
      "Epoch 9 - Validation: 100%|██████████| 418/418 [00:00<00:00, 507.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed, Training Loss: 4.203310613349931, Validation Loss: 3.879385179309754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.10batch/s]\n",
      "Epoch 10 - Validation: 100%|██████████| 418/418 [00:00<00:00, 504.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed, Training Loss: 4.178223153148594, Validation Loss: 3.8515794613714993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.44batch/s]\n",
      "Epoch 11 - Validation: 100%|██████████| 418/418 [00:00<00:00, 505.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed, Training Loss: 4.155404913400242, Validation Loss: 3.824212312127985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.09batch/s]\n",
      "Epoch 12 - Validation: 100%|██████████| 418/418 [00:00<00:00, 505.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed, Training Loss: 4.1353322165208946, Validation Loss: 3.801386295893546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 274.66batch/s]\n",
      "Epoch 13 - Validation: 100%|██████████| 418/418 [00:00<00:00, 503.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed, Training Loss: 4.117561973426609, Validation Loss: 3.7805857983502476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.76batch/s]\n",
      "Epoch 14 - Validation: 100%|██████████| 418/418 [00:00<00:00, 508.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed, Training Loss: 4.101531861045144, Validation Loss: 3.762565306499244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.71batch/s]\n",
      "Epoch 15 - Validation: 100%|██████████| 418/418 [00:00<00:00, 508.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed, Training Loss: 4.0879340340168735, Validation Loss: 3.747416783748061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.57batch/s]\n",
      "Epoch 16 - Validation: 100%|██████████| 418/418 [00:00<00:00, 508.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed, Training Loss: 4.07497529459302, Validation Loss: 3.7315521519720267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.45batch/s]\n",
      "Epoch 17 - Validation: 100%|██████████| 418/418 [00:00<00:00, 507.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed, Training Loss: 4.062970128875958, Validation Loss: 3.719219687452727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.20batch/s]\n",
      "Epoch 18 - Validation: 100%|██████████| 418/418 [00:00<00:00, 505.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed, Training Loss: 4.05131507504566, Validation Loss: 3.703168276394383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 274.89batch/s]\n",
      "Epoch 19 - Validation: 100%|██████████| 418/418 [00:00<00:00, 506.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed, Training Loss: 4.0407810255538585, Validation Loss: 3.692236433188881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.00batch/s]\n",
      "Epoch 20 - Validation: 100%|██████████| 418/418 [00:00<00:00, 508.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed, Training Loss: 4.030805999784087, Validation Loss: 3.6814536689000836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.25batch/s]\n",
      "Epoch 21 - Validation: 100%|██████████| 418/418 [00:00<00:00, 508.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed, Training Loss: 4.021330287239769, Validation Loss: 3.6707244626642983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.21batch/s]\n",
      "Epoch 22 - Validation: 100%|██████████| 418/418 [00:00<00:00, 508.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed, Training Loss: 4.011627565125834, Validation Loss: 3.657854920369016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 275.13batch/s]\n",
      "Epoch 23 - Validation: 100%|██████████| 418/418 [00:00<00:00, 506.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed, Training Loss: 4.0028865225471355, Validation Loss: 3.6492774315427936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 274.58batch/s]\n",
      "Epoch 24 - Validation: 100%|██████████| 418/418 [00:00<00:00, 508.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed, Training Loss: 3.994675347769739, Validation Loss: 3.6400101498553625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Training: 100%|██████████| 2365/2365 [00:08<00:00, 274.40batch/s]\n",
      "Epoch 25 - Validation: 100%|██████████| 418/418 [00:00<00:00, 508.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed, Training Loss: 3.9861558222619475, Validation Loss: 3.629872096212287\n",
      "Finished Training\n",
      "Model saved as model_d_0.5_sq_30_bs_64_hs_64_lr_0.001.pth\n",
      "close my shoes in a smile jackets its sweat in a little piece im a new aching before jackets in the same lane of kinds jackets hello as im near white the side jackets ill be blame you jackets a girl a man was jackets the seed expert apply the way jackets cause i and get too jackets but your stinkin me be paid me jackets i got my weed my biggest 6 of proof jackets you got you and by me jackets one day the last time i reckon jackets call me beg is a funny huh of quite jackets jackets right so ill be only the sight will fly jackets and two hit at the next train with a bulletproof to jackets got a fool my hand jackets but you so really could your aim jackets i dont want to be your my soul jackets then we unfurl and i fell together in sight jackets on the floor and changed he people down yeah coming on jackets you were comin fire jackets and he jackets time is so you and put it the in my four jackets will up all with jackets somebody how found them jackets and a jackets 2 just paradise to see us jackets i beg you with a fork on a show more you jackets i in the life jackets have a drag into night of the father jackets i came too of hungry jackets hey i am jackets i never know it where and we may seem while jackets and i would\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1412\n",
      "Cosine Similarity: 0.7119\n",
      "Levenshtain Distance: 0.3148\n",
      "Polarity Similarity: 0.4770\n",
      "if i thought i had someone been talking youre in a contender for my colors jackets just just let go jackets to make the done as livin on these and her side jackets but im my name jackets have always you anybody jackets i love me why i jackets seem very walking jackets and come on from this thing jackets right for you love you know with you baby jackets every purpose jackets part me jackets start on me and empty jackets and youre halfway that love jackets i feel it all she needed to jackets its war jackets im the son it are never five else we jackets the gift like your mind jackets then am alone jackets i need you dart are tired jackets from in device on or my own ring love jackets let me be free dont anything rock jackets with him saying you dying sing and triumphant jackets misty younger club jackets ready eat without it where my way youre clean jackets heart can be this old but i dont be all one others im fell jackets there im over my just jackets you can be confused jackets too for a chance help me say goodbye longest life jackets so turn you and be jackets jackets save the last jackets hey oh oh oh jackets i cant give the future to think jackets do it spanish so the long time jackets as a jackets jackets everything i got in on the heart jackets ill be gone to book jackets of my world with the\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.2081\n",
      "Cosine Similarity: 0.7754\n",
      "Levenshtain Distance: 0.3326\n",
      "Polarity Similarity: 0.4391\n",
      "dear jackets in an caught you pillars jackets tell me to dance with the night i breathe jackets i do everything to do that to you dont jackets do to dont loose gonna mess to me jackets cause baby i believe that this sounding jackets that you want to it jackets so come down to me its take us let somebody out of you just baby and are i avalanche now it jackets if i saw jackets and the hawaiian of us blue wit jackets stealing in a head jackets i just have so that dont you know jackets the local of walkin eve jackets its another kisses jackets jackets just cannibalism jackets jackets just has not seems that pack jackets larger drinkin on some one ever jackets just but im like itll jackets but the way more more on jackets lets go around jackets how the shit grow you jackets grab jackets but youre whatever each other jackets that you want here jackets what is i remember youll jackets we go the years under shore like your eyes jackets in the eyes and my life has deceived me for love to this jackets a quiet way would jackets tell me you going go jackets you may find me my life bazaar jackets and i cant give your chance jackets tell me say how you want to make you stay jackets where tomorrow ill do jackets jackets jackets i very need you again jackets sometimes its thinkin you stress is me like the best i know jackets dancing my\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1886\n",
      "Cosine Similarity: 0.7217\n",
      "Levenshtain Distance: 0.3823\n",
      "Polarity Similarity: 0.6452\n",
      "hiya leon eve jackets another dimension it must try jackets shitty soot cuerpo jackets and london take the time remained to find jackets you have a quiet year thing jackets ill love you jackets dont think you like at jackets never woman ever say jackets but i love you jackets jackets where you have jackets feel or do jackets let me dont want to show me jackets and baby jackets you better look down in my wall jackets of ways jackets dont you never do jackets wrongs to be most jackets its what i am jackets yea oh love i never knew yeah jackets since i just want a is jackets will be on the love to the decir who jackets all i package but moan the a lone jingling jackets flop jackets lord diggity fantasy stranger and bring me the jackets is a shepherd cat love jackets all of her way down till the jam another jackets come your pony intentions good jackets jackets mellow at the line percent jackets and i love you jackets to do you know what this is so a word girl jackets i must know noone jackets oh jackets theres all the respect of love a while where is jackets friends in his heart mouths and jackets your name are just jackets im ohh ill play like in you dont let me never jackets to make it wonder a deadly i jackets i talked good jackets out there so fuss wed jackets everybody its to believe jackets tell me tell me you say\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1809\n",
      "Cosine Similarity: 0.6107\n",
      "Levenshtain Distance: 0.3483\n",
      "Polarity Similarity: 0.5220\n",
      "all youre nice enough around and then jackets leave me busy road jackets but weve got him you and jackets its stronger than a number i smack the looks jackets making you paint kisses that daylight jackets even im diesel open jackets and nature my jackets people are deep in hell to find dial jackets as we love him to fly up jackets all in me to lie its played with her jackets my barking dogs a long to thank jackets no it would be free jackets now theyre the my block jackets im glow is not man in your eye jackets im gonna be in you jackets with you to the midnight train jackets there every one thing that could youre no set you jackets and richard jackets and the ship breaks jackets im gonna give me so so cold jackets mcs be so shallow jackets and free arm in the faces in the a coast from that that jackets til you break around the southern hotel jackets i still know that jackets jackets none stroking jackets is you friends say jackets i found at ransom in his heart jackets world conventionality crown were jackets to me down jackets mad jackets one building is all years far jackets up and fly on hearing jackets the lot of holiday day going time jackets if you intended the to fall jackets cause chaka my want jackets be a something jackets razor the sign is and all a opened jackets thing who just i cant die jackets give myself jackets bring\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.0919\n",
      "Cosine Similarity: 0.4927\n",
      "Levenshtain Distance: 0.3783\n",
      "Polarity Similarity: 0.3806\n",
      "Metrics saved to models_preformance_grid.csv\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(columns=['Model Name', 'Jaccard', 'Cosine' , 'Levenshtain', 'Polarity'])\n",
    "\n",
    "for dropout,sequence_length, batch_size, hidden_size, lr in itertools.product(dropouts,Sequence_Length, batch_sizes, hidden_sizes, learning_rates):\n",
    "\n",
    "    model_hyper = LyricsGeneratorModel(num_of_melody_features=num_of_features,\n",
    "                                 vocab_size=vocab_size,\n",
    "                                 embedding_dim=embedding_dim,\n",
    "                                 embedding_matrix=embedding_matrix_cuda,\n",
    "                                 hidden_size=hidden_size,\n",
    "                                 dropout_rate=dropout)\n",
    "\n",
    "    trained_model = train_model(model=model_hyper,\n",
    "                                df=train_df,\n",
    "                                word_indices_array = word_indices,\n",
    "                                sequence_length=sequence_length,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                lr=lr)\n",
    "\n",
    "    filename = f\"model_d_{dropout}_sq_{sequence_length}_bs_{batch_size}_hs_{hidden_size}_lr_{lr}.pth\" #TOCHECK IF PT / PTH (what we did in work 2)\n",
    "    model_filepath = os.path.join(model_save_dir, filename)\n",
    "    torch.save(trained_model.state_dict(), model_filepath)\n",
    "\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "    for i in range(len(preperd_test)):\n",
    "        generated_song = generate_lyrics_from_indices(trained_model, preperd_test[i][0], preperd_test[i][1], indices_word, num_words=int(average_length))\n",
    "        print(generated_song)\n",
    "        evaluator = SongEvaluation(preperd_test[i][0], generated_song ,indices_word )\n",
    "        results = evaluator.evaluate()\n",
    "        print(\"Evaluation Results:\")\n",
    "        for metric, score in results.items():\n",
    "            print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "        new_row = pd.DataFrame([{\n",
    "            'Model Name': filename,\n",
    "            'Jaccard Similarity': results['Jaccard Similarity'],\n",
    "            'Cosine Similarity': results['Cosine Similarity'],\n",
    "            'Levenshtain Distance': results['Levenshtain Distance'],\n",
    "            'Polarity Similarity': results['Polarity Similarity']\n",
    "            #'BLEU Score': results['BLEU Score']\n",
    "        }])\n",
    "        \n",
    "        metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "csv_file_path = 'models_preformance_grid.csv'\n",
    "metrics_df.to_csv(csv_file_path, index=False)\n",
    "print(f\"Metrics saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 444.07batch/s]\n",
      "Epoch 1 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1123.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Training Loss: 5.495683261556807, Validation Loss: 5.035729887382836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.61batch/s]\n",
      "Epoch 2 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1128.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed, Training Loss: 5.040157363681915, Validation Loss: 4.75747215918947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 464.12batch/s]\n",
      "Epoch 3 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1076.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed, Training Loss: 4.847111816688521, Validation Loss: 4.582350477647553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 461.67batch/s]\n",
      "Epoch 4 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1084.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed, Training Loss: 4.728874123071264, Validation Loss: 4.473159199126029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 476.73batch/s]\n",
      "Epoch 5 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1102.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed, Training Loss: 4.649484683998543, Validation Loss: 4.393714427947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 472.93batch/s]\n",
      "Epoch 6 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1114.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed, Training Loss: 4.590886432978366, Validation Loss: 4.333323621293575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 476.61batch/s]\n",
      "Epoch 7 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1120.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed, Training Loss: 4.5450519791617205, Validation Loss: 4.282803920467504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 483.93batch/s]\n",
      "Epoch 8 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1118.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed, Training Loss: 4.508495929024436, Validation Loss: 4.244523989526849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 487.84batch/s]\n",
      "Epoch 9 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1142.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed, Training Loss: 4.47882953869616, Validation Loss: 4.211708407082626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 504.14batch/s]\n",
      "Epoch 10 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1234.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed, Training Loss: 4.453675165841746, Validation Loss: 4.18272958075601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.36batch/s]\n",
      "Epoch 11 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1250.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed, Training Loss: 4.431285734156473, Validation Loss: 4.157299714795711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 534.60batch/s]\n",
      "Epoch 12 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1256.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed, Training Loss: 4.411848564430221, Validation Loss: 4.135852482330286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 538.96batch/s]\n",
      "Epoch 13 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1244.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed, Training Loss: 4.394770255502133, Validation Loss: 4.119158137357976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 538.56batch/s]\n",
      "Epoch 14 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1255.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed, Training Loss: 4.380791855362455, Validation Loss: 4.101596612679331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 537.08batch/s]\n",
      "Epoch 15 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1244.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed, Training Loss: 4.3667841693563645, Validation Loss: 4.0895358249901586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 538.29batch/s]\n",
      "Epoch 16 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1254.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed, Training Loss: 4.355170157696682, Validation Loss: 4.074250850380893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 536.89batch/s]\n",
      "Epoch 17 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1251.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed, Training Loss: 4.345356382628072, Validation Loss: 4.066607296752017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 499.65batch/s]\n",
      "Epoch 18 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1152.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed, Training Loss: 4.336369894624513, Validation Loss: 4.054845094110407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 488.29batch/s]\n",
      "Epoch 19 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1131.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed, Training Loss: 4.327265140218916, Validation Loss: 4.0420057511215575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 471.05batch/s]\n",
      "Epoch 20 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1128.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed, Training Loss: 4.3181160192913035, Validation Loss: 4.03351833489523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 434.46batch/s]\n",
      "Epoch 21 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1017.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed, Training Loss: 4.3113565038676995, Validation Loss: 4.027421808699101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 434.20batch/s]\n",
      "Epoch 22 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1075.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed, Training Loss: 4.303147279082091, Validation Loss: 4.020332755654622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 419.59batch/s]\n",
      "Epoch 23 - Validation: 100%|██████████| 418/418 [00:00<00:00, 993.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed, Training Loss: 4.298836580240197, Validation Loss: 4.010357313178943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 412.21batch/s]\n",
      "Epoch 24 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1035.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed, Training Loss: 4.29163722719753, Validation Loss: 4.006135909180892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 416.38batch/s]\n",
      "Epoch 25 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1023.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed, Training Loss: 4.2854021054241676, Validation Loss: 3.9988038545590268\n",
      "Finished Training\n",
      "Model saved as model_d_0.5_sq_10_bs_64_hs_64_lr_0.001.pth\n",
      "close you norman and love knew in the two of the bites of nice norman when i want you the twilight norman thats what they are norman you miss you dealin your body norman watch it fizz turn around a man music getting still norman me if i hope the only by found sisters and start norman norman then avec moi mi norman ya gettin crazy outside of my world norman then sings a sin norman shoot your kids and fists for my breath norman relax norman think you beg me power all things i dont or hear of the one norman some tackled the confusion how someone exactly dre now norman you want to talk you down norman so say it a lovely life ooh norman that she walked away norman upon a lovely christmas norman let me let hear spare norman i know a dream of if norman when the while i see this night norman but as it dont know that that it norman ill be to you strong norman never you really always what can youre close and i called me slow norman parson norman they always choose in norman through a blond man norman and a norman chance norman soon i never can play norman reign that i can do it norman you need this hot stuff norman be the norman mirrors norman norman ya nina do i cant try to notice the king of angels norman im still so blind doors here norman girl and it theres no son the drink the industry\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1503\n",
      "Cosine Similarity: 0.7427\n",
      "if i see something norman hey do you want to get it and still norman love you tonight norman oh my mind norman knowing me just had to find me the way myself say norman i cant fight touch norman always changed me norman were so damn else i mean my deepest norman who should so they dont skirts norman and if you started in lots i know norman i swear well norman with in the hand norman city and sell each fitness norman shell wait my usa played norman time this is of pretty norman someone sacred norman but does it i always had to the one norman comin next norman and my love flow in love norman hello to the tackled of darkness norman out on should down aid just care norman cause i dont care what you ever know more more a life norman but heartache tonight and no norman what you could you do spend i know i thought your love had to be just always to get touch norman this when im good sets down it norman cause youre werent a better talk to keep it gonna die norman god rip me daddys norman out in groups beginning both be a dream and told him norman its all the way i remember it norman if i may got their universe norman every klein norman hes somthing to the clock norman are all had norman norman cause what lie song and its wont norman norman and she what they forgot of something norman all have\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.2222\n",
      "Cosine Similarity: 0.7781\n",
      "dear norman inside a sea norman der norman they dont want me slick with people tenderly right this is the dark cause im gonna to my videos norman tell you like those ol and they can find norman a load the tank norman tell me dancin in me norman evrything tender norman still oh oh oh hey oh hey stop me norman fly norman then i and i dont matter what dont you ever norman still i see a stuff lonely norman and find before once youre on norman i call you joint norman for the seven norman where im norman feel at golden norman love you at a joy norman maybe when we still and me looking me like you did again norman norman now who tell me your love is radiates come together tonight norman you will you feel you norman turn around that i dont turn me for you norman the exs greeting another survivor norman my here overdose norman i know were she got no norman be very long time norman sleep on the nights patterns norman open youre in largo norman way norman we can sail to the sea a daughter norman im love again norman but time fever norman time look thats the look and er norman and thats then i am i need the time with your again norman i really want to live norman well think you a tonic norman just think id ask i dont let it it all cant be of my own norman what can you say he\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1932\n",
      "Cosine Similarity: 0.6950\n",
      "hiya mingled me norman in the stars are all back dream norman what of the only son can you recognize to me norman and its norman what can they got not a break norman sentimental norman but you hurting norman i feel for the fault what may do norman i keep my love me norman find you whats from it norman and well be alright slim norman and now that we norman good norman not trouble norman you sleep norman norman norman norman norman norman norman norman norman you must give me on me norman i just just show a good kind on so norman leaving lay you a media norman im waiting alright from this time norman closer to norman deep is we are speed by a tapestry norman turn at the shelter room norman plenty more yeah norman this is a stank heart songs started by you left for the pining monday thank me norman its love norman i know a book norman theres come back norman public shes the hand norman and ronnie to love you norman how can think youd heard im had like vulnerability norman the thousand toss down norman shes left my fruitless norman for a wish to say so yeah yeah norman im gonna play all gonna be good norman norman yeah when im moving out norman one weeks as you better lips to love norman ive a smile is the power of wonder norman it could be i been lonely norman but you mean a reluctantly thank norman we could say\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1615\n",
      "Cosine Similarity: 0.6293\n",
      "all at my heart norman and that i need you the chance norman well like a success i go norman lies in house down norman so stevens blow up norman on his dreamin boys you may be mine norman legacy it norman and if i might use the way all the you left fenders norman as shaking the night around the dead norman come it is to our hands norman cut behind norman lettin hid a tape norman youre not much they drop with dre dirty and the burnt instead hes tender is hoes yes my wings norman think we baby finally in your heart norman no to never know youve got norman you see my other norman so if you may the best love can be bodies norman and i cant be your arms to norman until the hope of all then its gotta have norman i know i know i fought my hand a time norman and broke the buffalo packs black at a crowd norman then come on all go norman your hearts all to the sky norman its so hoping to stay norman think to be norman everybodys cute unglued baby norman to get the american her norman it preachin norman ah she runs in the notion i hold me people norman but thats who is thats that norman no i can sing to the longest night norman i suppose tomorrow its now norman ill anyone its all again and by norman norman while skirts like to sleep we summon you for the sex norman\n",
      "Evaluation Results:\n",
      "Jaccard Similarity: 0.1236\n",
      "Cosine Similarity: 0.5088\n",
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 391.23batch/s]\n",
      "Epoch 1 - Validation: 100%|██████████| 418/418 [00:00<00:00, 683.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Training Loss: 5.2586527757866435, Validation Loss: 4.703288647546723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 2365/2365 [00:06<00:00, 393.13batch/s]\n",
      "Epoch 2 - Validation:  39%|███▊      | 161/418 [00:00<00:00, 679.89batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dropout,sequence_length, batch_size, hidden_size, lr \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(dropouts,Sequence_Length, batch_sizes, hidden_sizes, learning_rates):\n\u001b[1;32m      5\u001b[0m     model_hyper \u001b[38;5;241m=\u001b[39m LyricsGeneratorModel(num_of_melody_features\u001b[38;5;241m=\u001b[39mnum_of_features_second,\n\u001b[1;32m      6\u001b[0m                                  vocab_size\u001b[38;5;241m=\u001b[39mvocab_size_second,\n\u001b[1;32m      7\u001b[0m                                  embedding_dim\u001b[38;5;241m=\u001b[39membedding_dim_second,\n\u001b[1;32m      8\u001b[0m                                  embedding_matrix\u001b[38;5;241m=\u001b[39membedding_matrix_cuda_second,\n\u001b[1;32m      9\u001b[0m                                  hidden_size\u001b[38;5;241m=\u001b[39mhidden_size,\n\u001b[1;32m     10\u001b[0m                                  dropout_rate\u001b[38;5;241m=\u001b[39mdropout)\n\u001b[0;32m---> 12\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m train_model(model\u001b[38;5;241m=\u001b[39mmodel_hyper,\n\u001b[1;32m     13\u001b[0m                                 df\u001b[38;5;241m=\u001b[39mtrain_df_second,\n\u001b[1;32m     14\u001b[0m                                 word_indices_array \u001b[38;5;241m=\u001b[39m word_indices_second,\n\u001b[1;32m     15\u001b[0m                                 sequence_length\u001b[38;5;241m=\u001b[39msequence_length,\n\u001b[1;32m     16\u001b[0m                                 batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     17\u001b[0m                                 epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     18\u001b[0m                                 lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     20\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_d_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_sq_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_bs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_hs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_lr_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#TOCHECK IF PT / PTH (what we did in work 2)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     model_filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_save_second_dir, filename)\n",
      "Cell \u001b[0;32mIn[104], line 102\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, df, word_indices_array, sequence_length, batch_size, epochs, lr, weight_decay, patience)\u001b[0m\n\u001b[1;32m     99\u001b[0m y_val \u001b[38;5;241m=\u001b[39m batch[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    100\u001b[0m melody_input_batch_val \u001b[38;5;241m=\u001b[39m melody_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 102\u001b[0m outputs_val \u001b[38;5;241m=\u001b[39m model(x_val, melody_input_batch_val)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    103\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m criterion(outputs_val\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), y_val)\n\u001b[1;32m    105\u001b[0m val_running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_val\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[103], line 63\u001b[0m, in \u001b[0;36mLyricsGeneratorModel.forward\u001b[0;34m(self, word_input, melody_input, hidden, return_h, seq_len)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden(combined_input\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 63\u001b[0m lstm_output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(combined_input, hidden)\n\u001b[1;32m     64\u001b[0m lstm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(lstm_output)\n\u001b[1;32m     65\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(lstm_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:911\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    908\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    912\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    915\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics_df_second = pd.DataFrame(columns=['Model Name', 'Jaccard', 'Cosine', 'Levenshtain', 'Polarity'])\n",
    "\n",
    "for dropout,sequence_length, batch_size, hidden_size, lr in itertools.product(dropouts,Sequence_Length, batch_sizes, hidden_sizes, learning_rates):\n",
    "\n",
    "    model_hyper = LyricsGeneratorModel(num_of_melody_features=num_of_features_second,\n",
    "                                 vocab_size=vocab_size_second,\n",
    "                                 embedding_dim=embedding_dim_second,\n",
    "                                 embedding_matrix=embedding_matrix_cuda_second,\n",
    "                                 hidden_size=hidden_size,\n",
    "                                 dropout_rate=dropout)\n",
    "\n",
    "    trained_model = train_model(model=model_hyper,\n",
    "                                df=train_df_second,\n",
    "                                word_indices_array = word_indices_second,\n",
    "                                sequence_length=sequence_length,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                lr=lr)\n",
    "\n",
    "    filename = f\"model_d_{dropout}_sq_{sequence_length}_bs_{batch_size}_hs_{hidden_size}_lr_{lr}.pth\" #TOCHECK IF PT / PTH (what we did in work 2)\n",
    "    model_filepath = os.path.join(model_save_second_dir, filename)\n",
    "    torch.save(trained_model.state_dict(), model_filepath)\n",
    "\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "    for i in range(len(preperd_test_second)):\n",
    "        generated_song = generate_lyrics_from_indices(trained_model, preperd_test_second[i][0], preperd_test_second[i][1], indices_word_second, num_words=int(average_length))\n",
    "        print(generated_song)\n",
    "        evaluator = SongEvaluation(preperd_test_second[i][0], generated_song , indices_word_second )\n",
    "        results = evaluator.evaluate()\n",
    "        print(\"Evaluation Results:\")\n",
    "        for metric, score in results.items():\n",
    "            print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "        new_row = pd.DataFrame([{\n",
    "            'Model Name': filename,\n",
    "            'Jaccard Similarity': results['Jaccard Similarity'],\n",
    "            'Cosine Similarity': results['Cosine Similarity'],\n",
    "            'Levenshtain Distance': results['Levenshtain Distance'],\n",
    "            'Polarity Similarity': results['Polarity Similarity']\n",
    "            #'BLEU Score': results['BLEU Score']\n",
    "        }])\n",
    "        \n",
    "        metrics_df_second = pd.concat([metrics_df_second, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "csv_file_path = 'models_preformance_grid_secondPreProcess.csv'\n",
    "metrics_df_second.to_csv(csv_file_path, index=False)\n",
    "print(f\"Metrics saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_event_scalars(log_file, scalar_name):\n",
    "    \"\"\"\n",
    "    Extract scalar values from TensorBoard event logs.\n",
    "\n",
    "    Parameters:\n",
    "    - log_file (str): Path to the TensorBoard log file.\n",
    "    - scalar_name (str): Name of the scalar to extract.\n",
    "\n",
    "    Returns:\n",
    "    - steps (list): List of steps corresponding to the scalar values.\n",
    "    - values (list): List of scalar values.\n",
    "    \"\"\"\n",
    "    event_acc = EventAccumulator(log_file)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    print(f\"Available tags: {event_acc.Tags()}\")\n",
    "\n",
    "    if scalar_name not in event_acc.Tags()['scalars']:\n",
    "        raise ValueError(f'Scalar \"{scalar_name}\" not found in logs.')\n",
    "\n",
    "    scalar_events = event_acc.Scalars(scalar_name)\n",
    "    steps = [e.step for e in scalar_events]\n",
    "    values = [e.value for e in scalar_events]\n",
    "    return steps, values\n",
    "\n",
    "def plot_loss(log_dir):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss from TensorBoard event logs.\n",
    "\n",
    "    Parameters:\n",
    "    - log_dir (str): Directory containing the TensorBoard log files.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    log_file = None\n",
    "    for root, dirs, files in os.walk(log_dir):\n",
    "        for file in files:\n",
    "            if file.startswith(\"events.out.tfevents\"):\n",
    "                log_file = os.path.join(root, file)\n",
    "                break\n",
    "\n",
    "    if not log_file:\n",
    "        raise FileNotFoundError(f\"No event file found in directory {log_dir}\")\n",
    "\n",
    "    train_steps, train_loss = extract_event_scalars(log_file, 'Loss/train')\n",
    "    val_steps, val_loss = extract_event_scalars(log_file, 'Loss/validation')\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_steps, train_loss, label='Training Loss')\n",
    "    plt.plot(val_steps, val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nice_song(song):\n",
    "    \"\"\"\n",
    "    Print the given song lyrics in a nicely formatted way with random line breaks.\n",
    "\n",
    "    Parameters:\n",
    "    - song (str): The song lyrics as a single string.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    words = song.split()\n",
    "    lines = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        line_length = random.randint(5, 10)\n",
    "        line = words[i:i + line_length]\n",
    "        lines.append(\" \".join(line))\n",
    "        i += line_length\n",
    "\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Top 10 Models From Each Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Model Name  Jaccard Similarity  Cosine Similarity  Levenshtain Distance  Polarity Similarity  overall_score\n",
      "  model_d_0.5_sq_4_bs_64_hs_256_lr_0.001.pth            0.153248           0.654827              0.344517             0.564608       0.854399\n",
      "   model_d_0.8_sq_10_bs_64_hs_64_lr_0.01.pth            0.160100           0.655357              0.345668             0.545428       0.842579\n",
      "model_d_0.5_sq_20_bs_64_hs_256_lr_0.0001.pth            0.167333           0.641274              0.345975             0.541790       0.837174\n",
      " model_d_0.5_sq_10_bs_64_hs_256_lr_0.001.pth            0.153593           0.669960              0.350074             0.522164       0.818376\n",
      " model_d_0.5_sq_20_bs_32_hs_256_lr_0.001.pth            0.150218           0.626210              0.346352             0.570362       0.816569\n",
      " model_d_0.8_sq_20_bs_64_hs_256_lr_0.001.pth            0.169703           0.666104              0.347921             0.503771       0.813031\n",
      "    model_d_0.5_sq_4_bs_32_hs_64_lr_0.01.pth            0.156978           0.649546              0.349406             0.531397       0.811369\n",
      "  model_d_0.5_sq_20_bs_64_hs_256_lr_0.01.pth            0.159195           0.660788              0.348470             0.520973       0.808924\n",
      "model_d_0.5_sq_20_bs_32_hs_256_lr_0.0001.pth            0.160555           0.640614              0.346401             0.538606       0.805607\n",
      "model_d_0.8_sq_20_bs_32_hs_256_lr_0.0001.pth            0.160271           0.651754              0.346589             0.529606       0.804550\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"/sise/home/kirmayer/deep_learning_3/models_preformance_grid.csv\")\n",
    "\n",
    "df = df.groupby('Model Name').mean().reset_index()\n",
    "\n",
    "original_metrics_df = df[['Model Name', 'Jaccard Similarity', 'Cosine Similarity', 'Levenshtain Distance', 'Polarity Similarity']]\n",
    "\n",
    "weights = {\n",
    "    'Jaccard Similarity': 0.15,\n",
    "    'Cosine Similarity': 0.35,\n",
    "    'Levenshtain Distance': 0.15,\n",
    "    'Polarity Similarity': 0.35\n",
    "}\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "metrics = ['Jaccard Similarity', 'Cosine Similarity', 'Levenshtain Distance', 'Polarity Similarity']\n",
    "normalized_metrics_df = original_metrics_df.copy()\n",
    "normalized_metrics_df[metrics] = scaler.fit_transform(normalized_metrics_df[metrics])\n",
    "\n",
    "normalized_metrics_df['overall_score'] = sum(\n",
    "    normalized_metrics_df[metric] * weight for metric, weight in weights.items()\n",
    ")\n",
    "\n",
    "top_10_models = normalized_metrics_df.sort_values(by='overall_score', ascending=False).head(10)\n",
    "\n",
    "top_10_with_original_metrics = top_10_models[['Model Name', 'overall_score']].merge(\n",
    "    original_metrics_df, on='Model Name'\n",
    ")\n",
    "\n",
    "display_columns = [\n",
    "    'Model Name', 'Jaccard Similarity', 'Cosine Similarity',\n",
    "    'Levenshtain Distance', 'Polarity Similarity', 'overall_score'\n",
    "]\n",
    "\n",
    "top_10_display = top_10_with_original_metrics[display_columns].head(10)\n",
    "\n",
    "print(top_10_display.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach 2\n",
      "                                  Model Name  Jaccard Similarity  Cosine Similarity  Levenshtain Distance  Polarity Similarity  overall_score\n",
      "  model_d_0.5_sq_10_bs_64_hs_256_lr_0.01.pth            0.149050           0.644978              0.320658             0.570004       0.815573\n",
      " model_d_0.8_sq_20_bs_32_hs_256_lr_0.001.pth            0.168180           0.679124              0.326690             0.525404       0.797362\n",
      "model_d_0.8_sq_10_bs_32_hs_256_lr_0.0001.pth            0.151476           0.667639              0.325144             0.539404       0.774300\n",
      "model_d_0.5_sq_10_bs_32_hs_256_lr_0.0001.pth            0.150329           0.633200              0.317695             0.556390       0.747234\n",
      "  model_d_0.8_sq_20_bs_64_hs_64_lr_0.001.pth            0.163318           0.669025              0.318181             0.527198       0.743082\n",
      " model_d_0.5_sq_10_bs_64_hs_256_lr_0.001.pth            0.179918           0.649588              0.323662             0.511129       0.729182\n",
      "  model_d_0.5_sq_4_bs_64_hs_64_lr_0.0001.pth            0.150660           0.642788              0.322485             0.537290       0.719168\n",
      "model_d_0.8_sq_10_bs_64_hs_256_lr_0.0001.pth            0.154063           0.670586              0.321882             0.520671       0.713426\n",
      "   model_d_0.5_sq_20_bs_64_hs_64_lr_0.01.pth            0.164634           0.638324              0.322620             0.524051       0.708748\n",
      "   model_d_0.8_sq_10_bs_32_hs_64_lr_0.01.pth            0.152176           0.664891              0.318817             0.524233       0.699828\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"/sise/home/kirmayer/deep_learning_3/models_preformance_grid_secondPreProcess.csv\")\n",
    "\n",
    "df = df.groupby('Model Name').mean().reset_index()\n",
    "\n",
    "original_metrics_df = df[['Model Name', 'Jaccard Similarity', 'Cosine Similarity', 'Levenshtain Distance', 'Polarity Similarity']]\n",
    "\n",
    "weights = {\n",
    "    'Jaccard Similarity': 0.15,\n",
    "    'Cosine Similarity': 0.35,\n",
    "    'Levenshtain Distance': 0.15,\n",
    "    'Polarity Similarity': 0.35\n",
    "}\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "metrics = ['Jaccard Similarity', 'Cosine Similarity', 'Levenshtain Distance', 'Polarity Similarity']\n",
    "normalized_metrics_df = original_metrics_df.copy()\n",
    "normalized_metrics_df[metrics] = scaler.fit_transform(normalized_metrics_df[metrics])\n",
    "\n",
    "normalized_metrics_df['overall_score'] = sum(\n",
    "    normalized_metrics_df[metric] * weight for metric, weight in weights.items()\n",
    ")\n",
    "\n",
    "top_10_models = normalized_metrics_df.sort_values(by='overall_score', ascending=False).head(10)\n",
    "\n",
    "top_10_with_original_metrics = top_10_models[['Model Name', 'overall_score']].merge(\n",
    "    original_metrics_df, on='Model Name'\n",
    ")\n",
    "\n",
    "display_columns = [\n",
    "    'Model Name', 'Jaccard Similarity', 'Cosine Similarity',\n",
    "    'Levenshtain Distance', 'Polarity Similarity', 'overall_score'\n",
    "]\n",
    "\n",
    "top_10_display = top_10_with_original_metrics[display_columns].head(10)\n",
    "\n",
    "print(\"Approach 2\")\n",
    "print(top_10_display.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of the given text and return its polarity.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to analyze.\n",
    "\n",
    "    Returns:\n",
    "    - polarity (float): The polarity score of the text, ranging from -1.0 (negative) to 1.0 (positive).\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    return polarity\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.17batch/s]\n",
      "Epoch 1 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1369.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Training Loss: 5.172780322826942, Validation Loss: 4.712343550184697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.97batch/s]\n",
      "Epoch 2 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed, Training Loss: 4.635495554317128, Validation Loss: 4.409733524162804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.18batch/s]\n",
      "Epoch 3 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed, Training Loss: 4.406336145017918, Validation Loss: 4.235161390030783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 519.88batch/s]\n",
      "Epoch 4 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1334.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed, Training Loss: 4.251018476082961, Validation Loss: 4.10863030527197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 521.36batch/s]\n",
      "Epoch 5 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1353.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed, Training Loss: 4.143326471824727, Validation Loss: 4.026483047521856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.72batch/s]\n",
      "Epoch 6 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1353.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed, Training Loss: 4.06294698231316, Validation Loss: 3.9618063828591525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.12batch/s]\n",
      "Epoch 7 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed, Training Loss: 3.996245902184452, Validation Loss: 3.914054011043749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 523.87batch/s]\n",
      "Epoch 8 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1352.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed, Training Loss: 3.9435691123784973, Validation Loss: 3.87467140273044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.68batch/s]\n",
      "Epoch 9 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1350.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed, Training Loss: 3.8998669134385993, Validation Loss: 3.8426847218326405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.49batch/s]\n",
      "Epoch 10 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1283.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed, Training Loss: 3.8602465992498094, Validation Loss: 3.8146811079180414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 514.63batch/s]\n",
      "Epoch 11 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1360.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed, Training Loss: 3.8297370777573696, Validation Loss: 3.7897621512983406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.91batch/s]\n",
      "Epoch 12 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1363.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed, Training Loss: 3.8000032712238787, Validation Loss: 3.7709946158970373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.13batch/s]\n",
      "Epoch 13 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1360.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed, Training Loss: 3.77557581423705, Validation Loss: 3.7538229991374403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.68batch/s]\n",
      "Epoch 14 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1356.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed, Training Loss: 3.7515931762550143, Validation Loss: 3.7336080667504854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.24batch/s]\n",
      "Epoch 15 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1345.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed, Training Loss: 3.730879600960407, Validation Loss: 3.721912407989137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.72batch/s]\n",
      "Epoch 16 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1282.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed, Training Loss: 3.713708766066247, Validation Loss: 3.713829359939794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.15batch/s]\n",
      "Epoch 17 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1336.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed, Training Loss: 3.6962472193840945, Validation Loss: 3.703740875686755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.47batch/s]\n",
      "Epoch 18 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1311.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed, Training Loss: 3.678486519081648, Validation Loss: 3.6892811265288357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.38batch/s]\n",
      "Epoch 19 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed, Training Loss: 3.6670095042496857, Validation Loss: 3.6861450210142364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.93batch/s]\n",
      "Epoch 20 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1363.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed, Training Loss: 3.6522612118065734, Validation Loss: 3.6754790230801233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.00batch/s]\n",
      "Epoch 21 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1355.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed, Training Loss: 3.6408255371432476, Validation Loss: 3.6657187408237366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.28batch/s]\n",
      "Epoch 22 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1344.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed, Training Loss: 3.6274768623690776, Validation Loss: 3.6545442354165765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 517.61batch/s]\n",
      "Epoch 23 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1355.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed, Training Loss: 3.615530486137116, Validation Loss: 3.6541648966273623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 524.53batch/s]\n",
      "Epoch 24 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1358.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed, Training Loss: 3.609761679852992, Validation Loss: 3.6443574439965936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 515.38batch/s]\n",
      "Epoch 25 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1360.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed, Training Loss: 3.5992797594493844, Validation Loss: 3.6429183283491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.35batch/s]\n",
      "Epoch 26 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1360.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed, Training Loss: 3.5894191876022306, Validation Loss: 3.6385440159072147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.11batch/s]\n",
      "Epoch 27 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed, Training Loss: 3.58223831618311, Validation Loss: 3.6319312239377695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.37batch/s]\n",
      "Epoch 28 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1353.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed, Training Loss: 3.5741917502300433, Validation Loss: 3.625253044247057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.72batch/s]\n",
      "Epoch 29 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1353.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed, Training Loss: 3.5675298529497916, Validation Loss: 3.62423816194945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.15batch/s]\n",
      "Epoch 30 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1354.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed, Training Loss: 3.5609249795466096, Validation Loss: 3.616246259953987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.68batch/s]\n",
      "Epoch 31 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1358.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 completed, Training Loss: 3.5523224502990915, Validation Loss: 3.6154800972870094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.45batch/s]\n",
      "Epoch 32 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1361.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 completed, Training Loss: 3.54576289769711, Validation Loss: 3.612168421585594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.80batch/s]\n",
      "Epoch 33 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1353.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 completed, Training Loss: 3.5395239472137194, Validation Loss: 3.606772619571412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.58batch/s]\n",
      "Epoch 34 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1345.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 completed, Training Loss: 3.5346614323509167, Validation Loss: 3.6014678187347484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.62batch/s]\n",
      "Epoch 35 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1358.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 completed, Training Loss: 3.5275401396680834, Validation Loss: 3.600224057453101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 523.63batch/s]\n",
      "Epoch 36 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1359.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 completed, Training Loss: 3.52324226401573, Validation Loss: 3.602889534389003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.35batch/s]\n",
      "Epoch 37 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1352.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 completed, Training Loss: 3.517016768001855, Validation Loss: 3.594607584784476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 524.45batch/s]\n",
      "Epoch 38 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1341.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 completed, Training Loss: 3.5156017874058407, Validation Loss: 3.594238950305008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 523.73batch/s]\n",
      "Epoch 39 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1352.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 completed, Training Loss: 3.5102739932925204, Validation Loss: 3.591089961061067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 523.64batch/s]\n",
      "Epoch 40 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 completed, Training Loss: 3.504875510036315, Validation Loss: 3.5879096414483906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.28batch/s]\n",
      "Epoch 41 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1341.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 completed, Training Loss: 3.5021038516127283, Validation Loss: 3.5860512621665115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.07batch/s]\n",
      "Epoch 42 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1350.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 completed, Training Loss: 3.493835171080543, Validation Loss: 3.5923329580343513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 523.30batch/s]\n",
      "Epoch 43 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1350.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 completed, Training Loss: 3.4921864699107648, Validation Loss: 3.584526004403402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.65batch/s]\n",
      "Epoch 44 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1349.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 completed, Training Loss: 3.4879466274576005, Validation Loss: 3.580942363830274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 524.97batch/s]\n",
      "Epoch 45 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 completed, Training Loss: 3.4859933193843915, Validation Loss: 3.5786360673356854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.93batch/s]\n",
      "Epoch 46 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1342.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 completed, Training Loss: 3.479948525902585, Validation Loss: 3.579835430857097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.77batch/s]\n",
      "Epoch 47 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1354.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 completed, Training Loss: 3.4774817106839717, Validation Loss: 3.5738673729189276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.53batch/s]\n",
      "Epoch 48 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1340.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 completed, Training Loss: 3.4767784342453294, Validation Loss: 3.572872911343734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 523.91batch/s]\n",
      "Epoch 49 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1352.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 completed, Training Loss: 3.472571374195575, Validation Loss: 3.5746415973280037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.91batch/s]\n",
      "Epoch 50 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1341.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 completed, Training Loss: 3.46973688436109, Validation Loss: 3.574125855162954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.65batch/s]\n",
      "Epoch 51 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1342.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 completed, Training Loss: 3.464608512922775, Validation Loss: 3.5728453471900172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.93batch/s]\n",
      "Epoch 52 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1354.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 completed, Training Loss: 3.4629418107974352, Validation Loss: 3.57281048160991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 523.85batch/s]\n",
      "Epoch 53 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1353.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 completed, Training Loss: 3.459727965852927, Validation Loss: 3.567229655370758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.00batch/s]\n",
      "Epoch 54 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1334.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 completed, Training Loss: 3.4582678792844614, Validation Loss: 3.5667182401036532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.60batch/s]\n",
      "Epoch 55 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 completed, Training Loss: 3.456509400119741, Validation Loss: 3.565557098274596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 522.42batch/s]\n",
      "Epoch 56 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1345.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 completed, Training Loss: 3.453638385062994, Validation Loss: 3.566771790171354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.73batch/s]\n",
      "Epoch 57 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 completed, Training Loss: 3.450301068428959, Validation Loss: 3.5604009120658255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.58batch/s]\n",
      "Epoch 58 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1354.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 completed, Training Loss: 3.447518681370935, Validation Loss: 3.56711622801694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 524.15batch/s]\n",
      "Epoch 59 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1347.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 completed, Training Loss: 3.4466557538030513, Validation Loss: 3.5635674661426453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 524.04batch/s]\n",
      "Epoch 60 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1352.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 completed, Training Loss: 3.442518857468006, Validation Loss: 3.561234284245797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 522.74batch/s]\n",
      "Epoch 61 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1348.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 completed, Training Loss: 3.4400668169428883, Validation Loss: 3.5570834076575686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.53batch/s]\n",
      "Epoch 62 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1341.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 completed, Training Loss: 3.438988140420732, Validation Loss: 3.5564258919948597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.23batch/s]\n",
      "Epoch 63 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1344.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 completed, Training Loss: 3.435908136710556, Validation Loss: 3.5590717016795037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.23batch/s]\n",
      "Epoch 64 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1355.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 completed, Training Loss: 3.433385132735174, Validation Loss: 3.554521934837816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.22batch/s]\n",
      "Epoch 65 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1364.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 completed, Training Loss: 3.4341097135120418, Validation Loss: 3.5554828409943284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 514.72batch/s]\n",
      "Epoch 66 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1354.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 completed, Training Loss: 3.4281804661418116, Validation Loss: 3.5549888479652587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.10batch/s]\n",
      "Epoch 67 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1343.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 completed, Training Loss: 3.4286496000108455, Validation Loss: 3.5525350228451087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.56batch/s]\n",
      "Epoch 68 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1345.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 completed, Training Loss: 3.4300802966757002, Validation Loss: 3.551941399939323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.68batch/s]\n",
      "Epoch 69 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1344.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 completed, Training Loss: 3.424147613860084, Validation Loss: 3.5529763065456774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 530.63batch/s]\n",
      "Epoch 70 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1345.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 completed, Training Loss: 3.4218049232853898, Validation Loss: 3.5501881159093394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 530.09batch/s]\n",
      "Epoch 71 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1349.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 completed, Training Loss: 3.4230721266022694, Validation Loss: 3.5519147615113327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 522.69batch/s]\n",
      "Epoch 72 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1353.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 completed, Training Loss: 3.4207033865043526, Validation Loss: 3.553459594124242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 524.78batch/s]\n",
      "Epoch 73 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1349.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 completed, Training Loss: 3.42004684303074, Validation Loss: 3.5500252988349876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 524.83batch/s]\n",
      "Epoch 74 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1339.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 completed, Training Loss: 3.418840393001887, Validation Loss: 3.5454326902280013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.80batch/s]\n",
      "Epoch 75 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1356.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 completed, Training Loss: 3.413111071455554, Validation Loss: 3.5480610097994645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 524.63batch/s]\n",
      "Epoch 76 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1362.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 completed, Training Loss: 3.415191340093633, Validation Loss: 3.545723932211479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 531.14batch/s]\n",
      "Epoch 77 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1346.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 completed, Training Loss: 3.41228998730601, Validation Loss: 3.544665349157233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.30batch/s]\n",
      "Epoch 78 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1347.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 completed, Training Loss: 3.411521149286508, Validation Loss: 3.543633146719499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.55batch/s]\n",
      "Epoch 79 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1355.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 completed, Training Loss: 3.408253658145477, Validation Loss: 3.5426863814084726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.94batch/s]\n",
      "Epoch 80 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1354.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 completed, Training Loss: 3.4085012988358674, Validation Loss: 3.5416534745522092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.51batch/s]\n",
      "Epoch 81 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1359.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 completed, Training Loss: 3.405995072471667, Validation Loss: 3.543141130625346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.66batch/s]\n",
      "Epoch 82 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1345.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 completed, Training Loss: 3.4055992291795274, Validation Loss: 3.5417186883077667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.35batch/s]\n",
      "Epoch 83 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1351.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 completed, Training Loss: 3.40463027742398, Validation Loss: 3.538484265359395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.36batch/s]\n",
      "Epoch 84 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1345.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 completed, Training Loss: 3.4024617634666394, Validation Loss: 3.536479807356328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 526.95batch/s]\n",
      "Epoch 85 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1363.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 completed, Training Loss: 3.401797201567926, Validation Loss: 3.546520698013488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.23batch/s]\n",
      "Epoch 86 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1349.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 completed, Training Loss: 3.40080850804835, Validation Loss: 3.5428692672811626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.09batch/s]\n",
      "Epoch 87 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1343.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 completed, Training Loss: 3.3981301591965916, Validation Loss: 3.541335895871432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.06batch/s]\n",
      "Epoch 88 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1356.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 completed, Training Loss: 3.398462907658067, Validation Loss: 3.538248532126395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 527.93batch/s]\n",
      "Epoch 89 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1358.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 completed, Training Loss: 3.397592000174976, Validation Loss: 3.5413375300083434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.11batch/s]\n",
      "Epoch 90 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1356.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 completed, Training Loss: 3.394838332323393, Validation Loss: 3.537025498431265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.08batch/s]\n",
      "Epoch 91 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1361.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 completed, Training Loss: 3.395152410442683, Validation Loss: 3.5425325917285027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.02batch/s]\n",
      "Epoch 92 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1307.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 completed, Training Loss: 3.39612314554904, Validation Loss: 3.537762557490591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 522.41batch/s]\n",
      "Epoch 93 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1344.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 completed, Training Loss: 3.3942425832687926, Validation Loss: 3.5410865790535957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 513.64batch/s]\n",
      "Epoch 94 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1348.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 completed, Training Loss: 3.392365356529994, Validation Loss: 3.5318786048432855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.28batch/s]\n",
      "Epoch 95 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1358.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 completed, Training Loss: 3.389422865297023, Validation Loss: 3.536701469330126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 514.06batch/s]\n",
      "Epoch 96 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1358.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 completed, Training Loss: 3.3906092292914685, Validation Loss: 3.536228519307369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 529.80batch/s]\n",
      "Epoch 97 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1353.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 completed, Training Loss: 3.3887731117627586, Validation Loss: 3.533238075566634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 528.19batch/s]\n",
      "Epoch 98 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1352.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 completed, Training Loss: 3.387566671310973, Validation Loss: 3.5338320098995593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 525.30batch/s]\n",
      "Epoch 99 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1344.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 completed, Training Loss: 3.3873581114077416, Validation Loss: 3.5345614561053553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 - Training: 100%|██████████| 2365/2365 [00:04<00:00, 511.03batch/s]\n",
      "Epoch 100 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1343.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 completed, Training Loss: 3.3862664688465207, Validation Loss: 3.534695098845012\n",
      "Finished Training\n",
      "Model saved as best1_model_d_0.5_sq_4_bs_64_hs_256_lr_0.001.pth\n",
      "-------- test ---------\n",
      "close you ever fuss together sleepwalker\n",
      "free fuss christ the king night\n",
      "fuss fuss have you got a\n",
      "almost a gray fuss i wish\n",
      "i cant be a neck to\n",
      "another in you and if you\n",
      "only we were fuss how i\n",
      "used to have i could you\n",
      "go my fuss ill take it\n",
      "to your heart fuss you do\n",
      "tonight on every single day fuss\n",
      "i got over fuss well the\n",
      "sealed time from fuss beginning loud\n",
      "fuss sing this a new song\n",
      "fuss both the eyes fuss i\n",
      "can bought me high fuss the\n",
      "same that im gonna get you\n",
      "karat fuss swim away from your\n",
      "twohour christmas eve fuss i go\n",
      "nothing kind between the man fuss\n",
      "they got day in hearts of\n",
      "my mind fuss feel that bunch\n",
      "on the johnny fuss leave me\n",
      "crying fuss oh i know how\n",
      "hangs it fuss will it course\n",
      "fuss and when she walks away\n",
      "again and tell the house fuss\n",
      "in her eyes fuss fuss if\n",
      "its wrong fuss only thing i\n",
      "know fuss how was youll make\n",
      "me go and my money feel\n",
      "souped citizens type to mic fuss\n",
      "i said fuss that said with\n",
      "knocks you five the okay fuss\n",
      "repeat 1 telephone fuss ive never\n",
      "found but i wont wanna be\n",
      "your niggas just sit wont take\n",
      "good way fuss how street just\n",
      "a dancin that fuss nothing grown\n",
      "gall fuss cause i got you\n",
      "to the radio fuss he wouldnt\n",
      "he live without a place in\n",
      "your fuss ooh my got to\n",
      "see\n",
      "    \n",
      "-------- love ---------\n",
      "love just fuss that you say\n",
      "yeah fuss if that if they\n",
      "say in a voyage fuss away\n",
      "dont a friend fuss britney was\n",
      "fuss on iron fuss odyssey fuss\n",
      "the local nicole fuss to come\n",
      "out fuss never ive been fuss\n",
      "now youre a thinking fuss ive\n",
      "waited to be and i close\n",
      "a place fuss but you things\n",
      "you were my sweet love fuss\n",
      "i was have a fears fuss\n",
      "then i got to some beat\n",
      "fuss boogie mood undone fuss i\n",
      "be with you with me weaker\n",
      "and youre a strong fuss in\n",
      "you that fuss me im so\n",
      "i own outer fuss i puffin\n",
      "fuss and to light the fuss\n",
      "now theres the too and its\n",
      "gone to the city fuss we\n",
      "are lame fuss fuss a scuff\n",
      "across the fuss and she bop\n",
      "or my shit fuss its hard\n",
      "to call me laugh and you\n",
      "need a lot to come fuss\n",
      "what you could you think about\n",
      "me just the way you hide\n",
      "from the range im gonna gun\n",
      "around the the suffer first chance\n",
      "wo was parties fuss just sink\n",
      "the of the slipped stretch fuss\n",
      "and there religion that exempt fuss\n",
      "fuss let me cause you really\n",
      "undressed with the fuss fuss out\n",
      "on me fuss i listen to\n",
      "the radio fuss and if she\n",
      "reveals his mister and no is\n",
      "wheel the time fuss fuel plays\n",
      "low to the knees boogie down\n",
      "by wall fuss from the happens\n",
      "that in her pocket fuss and\n",
      "i cant know fuss what you\n",
      "dont\n",
      "    \n",
      "-------- dark ---------\n",
      "dark man fuss we can see\n",
      "my brave all through fuss breaking\n",
      "you down out fuss and fuss\n",
      "fuss da feel already bo fuss\n",
      "wasted year let me fuss ive\n",
      "gotta like fuss und fuss fuss\n",
      "hes never big enough like actin\n",
      "and fuss cause im baby just\n",
      "i dont turn around time fuss\n",
      "this wings fuss get with those\n",
      "words kicked fuss when ill do\n",
      "it pussy up fuss you got\n",
      "you standing in one week everyone\n",
      "much fuss to say fuss but\n",
      "when the life shape of no\n",
      "pretty the walks a lot vacation\n",
      "fuss to listen myself fuss pressure\n",
      "for the ocean fuss lovin you\n",
      "cross the fist that fuss with\n",
      "no fuss no fuss so i\n",
      "wait fuss or have ever ahead\n",
      "you were fuss fuss time will\n",
      "with i fall in the firelight\n",
      "fuss you box shoe box fuss\n",
      "a healer gently fuss stray a\n",
      "shining on through the ended and\n",
      "a mil answering fuss oh my\n",
      "whole in fuss come to fuss\n",
      "of you fuss you we need\n",
      "nothing should to hear me fuss\n",
      "in the rain decorate fuss holding\n",
      "fuss have been scared to the\n",
      "world fuss its the table fuss\n",
      "oh woah fuss jack up when\n",
      "his bounty he collaborating and on\n",
      "us a different fuss crazy fuss\n",
      "why it got the love me\n",
      "yeah everybody out that fuss im\n",
      "preaching fuss well i found on\n",
      "the street brought fuss then im\n",
      "from on that i give it\n",
      "fuss to me cheatin with you\n",
      "fuss cause baby come dance fuss\n",
      "cause\n",
      "    \n",
      "-------- light ---------\n",
      "light that we fuss tackled fuss\n",
      "fuss the long run church fuss\n",
      "the what lovers say you all\n",
      "feel the meaning i just to\n",
      "get into maneuver road so i\n",
      "bop and the trees a sunglasses\n",
      "fuss up fuss lets the time\n",
      "marches like in the heat fuss\n",
      "the trees white of starter and\n",
      "oops satisfied fuss fuss to your\n",
      "themselves forever fuss fuss i know\n",
      "how id ever ever stop fuss\n",
      "oh why that youll never sayin\n",
      "it got your good shakin but\n",
      "im never your conscience asking to\n",
      "night i with you fuss fuss\n",
      "a fuss they read they the\n",
      "sappy good fuss shows to keep\n",
      "dropped and never corn fuss a\n",
      "million people upon my crew fuss\n",
      "in my heart so i got\n",
      "to be mojo for ya chambers\n",
      "fuss comb through the hustling of\n",
      "frames fuss kept ihr dreamin fuss\n",
      "fuss david had to judges fuss\n",
      "and i seen before who you\n",
      "fuss for you fuss is right\n",
      "you and its lifeline for me\n",
      "fuss ill be there fuss cause\n",
      "now im so when bad to\n",
      "you fuss i said complain fuss\n",
      "good god fuss i know you\n",
      "to show you a morning and\n",
      "they will you go fuss with\n",
      "you fuss i are eek to\n",
      "a a little love to hear\n",
      "me leave me with a joy\n",
      "a song a song fuss to\n",
      "know youre the only one of\n",
      "her send this man illusions fuss\n",
      "oh i dont big love to\n",
      "believe fuss my soul live without\n",
      "the guy who he will bear\n",
      "fuss\n",
      "    \n",
      "-------- test ---------\n",
      "if you dont know you whoa\n",
      "fuss funny dancing in in fuss\n",
      "you stand up fuss youll goddamn\n",
      "cause its only nation fuss if\n",
      "we just call fuss over the\n",
      "you and i wrong on the\n",
      "rug burns and forever fuss i\n",
      "can get madness fuss cause i\n",
      "know that i the gray sky\n",
      "the drives a glitter and roller\n",
      "disappeared fuss screamed theres fuss atheist\n",
      "that soda fuss fuss its fuss\n",
      "but what you got i got\n",
      "to give me a and shallow\n",
      "fuss fuss but dont i left\n",
      "fuss the waiting room fuss dont\n",
      "want to thank you you let\n",
      "me fuss i heard her horse\n",
      "fuss and lies in the barrier\n",
      "fuss mashed somehow the rainbows fuss\n",
      "im from the way you mind\n",
      "fuss you were the good i\n",
      "know of the fuss but youll\n",
      "the rain the lane fuss fuss\n",
      "living in you fuss save fuss\n",
      "you must bust your heavens fuss\n",
      "fuss i just left over fuss\n",
      "no moon planetary fills fuss fuss\n",
      "a young oasis and promise to\n",
      "life fuss im gonna carry on\n",
      "the nude of calling fuss and\n",
      "its hard to come way to\n",
      "fuss fuss to hold your breath\n",
      "fuss my way the desolate world\n",
      "fuss now as the last day\n",
      "fuss and ever that world fuss\n",
      "how could you see give me\n",
      "beg that to draw barbed dog\n",
      "fuss and im on still proceeding\n",
      "fuss and the piano fuss if\n",
      "it was the flesh of us\n",
      "in god oh yeah fuss am\n",
      "oh fuss so much place fuss\n",
      "whats\n",
      "    \n",
      "-------- love ---------\n",
      "love packed me away fuss and\n",
      "i gonna do gonna get some\n",
      "to myself fuss a bootie call\n",
      "victory fuss it do i breathe\n",
      "my dolce fuss i was born\n",
      "to a get fuss strong white\n",
      "fuss fuss could i was stray\n",
      "girl fuss only skies like will\n",
      "fuss memories are tell fuss and\n",
      "its like this romantic with you\n",
      "fuss you are me step up\n",
      "me fuss ive got a fuss\n",
      "slug my head out and tell\n",
      "me in amsterdam fuss and a\n",
      "thing wishes my name must fuss\n",
      "going to wiser fuss what the\n",
      "boys are you theres every type\n",
      "i think it would be true\n",
      "fuss the midnight train fuss she\n",
      "just wanna fuss siento in shades\n",
      "its positive overdrive been afraid to\n",
      "pressure fuss chorus memories of muezzin\n",
      "and mountains king and press in\n",
      "your mind back the all to\n",
      "the same fuss i must pilots\n",
      "even fuss that ive learned fame\n",
      "off it we and smell fuss\n",
      "a fuss dont belong a yesterdays\n",
      "kurt fuss from the billboards engineer\n",
      "said a paris coz for the\n",
      "hand thats thinking fuss these fuss\n",
      "i waited so i went down\n",
      "to my world fuss and today\n",
      "was searching fuss fuss i got\n",
      "this now i but i fuss\n",
      "find out to meet you fuss\n",
      "fuss all i have ancient of\n",
      "my fuss can you tell me\n",
      "no you that thought fuss this\n",
      "world fuss faster than the eagle\n",
      "as you love has come fuss\n",
      "lately how think you strumming fuss\n",
      "every is baby fuss baby the\n",
      "house\n",
      "    \n",
      "-------- dark ---------\n",
      "dark fuss like the field reading\n",
      "fuss and rendezvous fuss there with\n",
      "allow me fuss and men i\n",
      "should have lied fuss i tell\n",
      "me said i need to know\n",
      "the and maybe its gotta fuss\n",
      "drink the money cause upstairs i\n",
      "got a sailor fuss breaths fuss\n",
      "people illusion fuss in we yeah\n",
      "fuss i find my fall in\n",
      "my arms fuss and buy fuss\n",
      "a lot to the pap you\n",
      "and let everybody run to the\n",
      "guitar fuss that the only a\n",
      "mountain fuss in the miles of\n",
      "snow fuss when my baby slap\n",
      "me and i ha got haste\n",
      "and his and so dont really\n",
      "dont get the shit fuss in\n",
      "a temptation sales than fuss shes\n",
      "a meaning prayed for the we\n",
      "fuss i dont know what she\n",
      "fucked me in your soul fuss\n",
      "still you you wont wild ago\n",
      "id love to you girl i\n",
      "see i never knew the truth\n",
      "fuss do we love is a\n",
      "gang fuss created a day to\n",
      "hangup a day to surely fuss\n",
      "as the eyes and if every\n",
      "rhythm my soul fuss i understand\n",
      "you fuss tragedy fuss you know\n",
      "that i had you do you\n",
      "wait for me and then me\n",
      "fuss i love my baby tonight\n",
      "fuss see you when the punches\n",
      "i looked like a season fuss\n",
      "yeah yeah maybe dies fuss we\n",
      "always try fuss gonna know you\n",
      "all again fuss yeah fuss i\n",
      "had a love of love to\n",
      "make you fuss she said dont\n",
      "know id do you know i\n",
      "oh\n",
      "    \n",
      "-------- light ---------\n",
      "light well never theres that you\n",
      "fuss there fuss and cannot dance\n",
      "im at the letters fuss in\n",
      "a couch fuss and i dont\n",
      "have to face at the news\n",
      "i lost my incentive fuss is\n",
      "said it all fuss he walked\n",
      "fuss is you diss a word\n",
      "fuss now its an old fuss\n",
      "i cant you hear that im\n",
      "feeling so didn't hurt fuss you\n",
      "hear you just the sound tar\n",
      "fuss the the love the vertigo\n",
      "fuss who of confusion fuss rules\n",
      "and thugs fuss like to go\n",
      "low fuss i used ripped off\n",
      "fuss and his arms in fabulous\n",
      "your turn fuss and we nasty\n",
      "fuss too late they die on\n",
      "the prosperity fuss right out another\n",
      "place fuss you and fuss that\n",
      "i want to be that comes\n",
      "fuss it just wanna do fuss\n",
      "now shes the the thing of\n",
      "claim and ive been there to\n",
      "love fuss i just the he\n",
      "fuss and i was singing all\n",
      "cried fuss into the light night\n",
      "fuss once he with your song\n",
      "fuss fuss i had step to\n",
      "fuss chance fuss if you get\n",
      "fuss some laugh fuss i did\n",
      "someone writes house and style in\n",
      "a channel of lies the room\n",
      "fuss and what things i go\n",
      "fuss i got an american words\n",
      "fuss fuss fuss i am fuss\n",
      "oh what he was be hunter\n",
      "and gonna to light fuss corner\n",
      "load shit fuss and ill stand\n",
      "to kiss your you fuss will\n",
      "is a trusting to find our\n",
      "boat fuss its a beautiful oblivion\n",
      "fuss\n",
      "    \n",
      "-------- test ---------\n",
      "dear fuss were friends and your\n",
      "deceiving feelin that the right earlobe\n",
      "possibilities is ever fuss fuss thats\n",
      "here fuss in the your attitude\n",
      "fuss got me a gleam of\n",
      "the guy who of saviors fuss\n",
      "fuss just with you hey cause\n",
      "i get hungry cat to winston\n",
      "with you i must do to\n",
      "have a celebration fuss ooh girl\n",
      "fuss i see your precious energy\n",
      "fuss a meaning to find out\n",
      "the peace fuss the sounds dich\n",
      "treble fuss so bliss when fuss\n",
      "fuss come around to crib fuss\n",
      "follow me fuss oh maybe fuss\n",
      "a drag respect fuss your loss\n",
      "is your love with me fuss\n",
      "i want to hold you breezes\n",
      "youre fuss if you do need\n",
      "me im always let me rock\n",
      "fuss yo i do and make\n",
      "you wonder me if you think\n",
      "im so simply call it fuss\n",
      "and hope youll wont be your\n",
      "shadows his other dandy time fuss\n",
      "fuss so i could yes its\n",
      "my baby fuss hey little sister\n",
      "no take no fuss people go\n",
      "to your artists fuss in the\n",
      "world fuss you love the night\n",
      "fuss is theres nothing babys fuss\n",
      "my bell grande fuss he enter\n",
      "fuss well big hee up the\n",
      "fuss come along me fuss or\n",
      "if of a living legacy fuss\n",
      "im got nobody fuss pilots are\n",
      "loved fuss then i heard look\n",
      "reggae soldier fuss but the birds\n",
      "still fuss up in the dort\n",
      "fuss hiding and did the reasons\n",
      "fuss the fu hill and cooked\n",
      "and twentyfive satisfy rob slept wit\n",
      "and\n",
      "    \n",
      "-------- love ---------\n",
      "love somebody so you wanna get\n",
      "the beat you and all fuss\n",
      "i inspiration get my life fuss\n",
      "i just forgot i do of\n",
      "you have but the well i\n",
      "want you to my last fuss\n",
      "in blocks and i miss all\n",
      "fuss glory will and when loves\n",
      "me so long to be a\n",
      "broken man fuss your that remember\n",
      "fuss fuss all my life is\n",
      "you chaka you breathe fuss and\n",
      "cause the goin on fuss of\n",
      "the all of this get fuss\n",
      "future so are some fuss the\n",
      "child soulful acid down fuss had\n",
      "like you be alright and find\n",
      "it night to fuss then fuss\n",
      "but the long capture of the\n",
      "cat the grown wasted fuss they\n",
      "badness fuss all the men raising\n",
      "fuss soul of the hips fuss\n",
      "tear your sweet fuss and when\n",
      "prisoners say are that are words\n",
      "to like the music so fuss\n",
      "oh fuss fuss tearing this truth\n",
      "fuss and ill see your money\n",
      "fuss i wont play is so\n",
      "much way i really the riverside\n",
      "fuss i know its a mystery\n",
      "fuss why did i slim shady\n",
      "fuss all you need to do\n",
      "all that fuss you love maybe\n",
      "you do fuss hey moved too\n",
      "fuss so i care here how\n",
      "fuss fuss a rat known fuss\n",
      "but we can remember all to\n",
      "me fuss christmas fuss nix fuss\n",
      "now the world lookin with the\n",
      "world fuss the one who you\n",
      "in crouched in fuss are youre\n",
      "not painful to me fuss i\n",
      "turn the post of course and\n",
      "we\n",
      "    \n",
      "-------- dark ---------\n",
      "dark has tomorrows kremlin fuss hand\n",
      "fuss intentionally nigga in the big\n",
      "paranoid fuss and you dont give\n",
      "me love to love fuss he\n",
      "i want fat oh so loud\n",
      "fuss and i would you way\n",
      "i love you fuss that think\n",
      "fuss and now i know any\n",
      "the one because you just in\n",
      "the mornin fuss i go to\n",
      "a certain time of you gave\n",
      "to friends they fuss and youre\n",
      "no good day fuss they got\n",
      "tricks sense fuss and hes still\n",
      "im so alive fuss that in\n",
      "the name fuss when i hold\n",
      "you areas fuss control your body\n",
      "fuss fast i know its the\n",
      "knight fuss someone and whisper in\n",
      "plays fuss gotta helps me for\n",
      "the pillar fuss in this the\n",
      "skies fuss the loser is blowin\n",
      "fuss when snow is startin truck\n",
      "with me down fuss you make\n",
      "my legs sayin fuss fuss fuss\n",
      "so much time fuss all that\n",
      "smokin awake is a brown man\n",
      "in the horse fuss i need\n",
      "you just now its time fuss\n",
      "i was kissin you stare that\n",
      "baby fuss i wanna grow never\n",
      "something fuss when you flyin out\n",
      "with a collect fuss there insincerity\n",
      "fleet skates on fuss fuss my\n",
      "broken heart and its on oer\n",
      "your clothes out fuss and one\n",
      "just me oh it fuss what\n",
      "makes a sound to you que\n",
      "fuss y es fuss fuss he\n",
      "your destiny fuss but its no\n",
      "more fuss i used to know\n",
      "fuss what that i fuss mean\n",
      "you know fuss a beautiful thing\n",
      "fuss\n",
      "    \n",
      "-------- light ---------\n",
      "light fuss where my share me\n",
      "how you dont you hear it\n",
      "fuss tear my heart lives fuss\n",
      "cali das mony oh fuss fuss\n",
      "fuss oh oh yeah fuss oh\n",
      "little or i win your heart\n",
      "fuss let me be my love\n",
      "for you fuss you cant have\n",
      "fuss fuss ronnie ronnie ronnie ronnie\n",
      "its a end hard productions in\n",
      "his line fuss and i can\n",
      "find you i premature fuss fuss\n",
      "step to to try and try\n",
      "and you fuss its the a\n",
      "daffodils and they cant go fuss\n",
      "its find a job in fuss\n",
      "were of me fuss as i\n",
      "just gone fuss your wonderful linger\n",
      "fuss in the run fuss i\n",
      "love is you cant let my\n",
      "wish fuss you now here just\n",
      "a baby fuss but she got\n",
      "a single well of town fuss\n",
      "where her nearly own fuss making\n",
      "all your changed your dreams ill\n",
      "concert fuss that somehow fuss drinking\n",
      "from the half moonshine heavy in\n",
      "frosty artists the only sound than\n",
      "my head fuss and it seems\n",
      "so it is fuss no say\n",
      "no fuss its so fuss like\n",
      "in on the me fuss youre\n",
      "in a freight yards me to\n",
      "find the your hung where fuss\n",
      "darlin in my hands kissed close\n",
      "and boogie fuss is fuss down\n",
      "baby boogie down while got the\n",
      "powdered souls fuss theres said that\n",
      "its yesterday fuss its white fuss\n",
      "and they cant i just dont\n",
      "you said each morning fuss vulnerability\n",
      "fuss the lust goods fuss fuss\n",
      "trot and pour hash fuss and\n",
      "a\n",
      "    \n",
      "-------- test ---------\n",
      "hiya see the sailing fuss off\n",
      "your bones to revolutionary soul fuss\n",
      "dont you worth you for hustler\n",
      "fuss he mine needles the somthing\n",
      "knew have myself fuss let us\n",
      "gonna rock im noisy fuss though\n",
      "thumb to school ive got description\n",
      "your style fuss yall lose to\n",
      "off fuss and you cannot never\n",
      "knew away oh no fuss fuss\n",
      "i was going of something fuss\n",
      "won and put it wild baby\n",
      "and no so fuss youve got\n",
      "to give you for fuss all\n",
      "the but i love you thats\n",
      "leavin fuss i want the flight\n",
      "fuss if i dances to fuss\n",
      "you by my black fuss but\n",
      "the one thousand times they worked\n",
      "out fuss fuss the water and\n",
      "caring just some chance goes fuss\n",
      "step into my heart fuss i\n",
      "just hound to the possibilities fuss\n",
      "thats lookin for this fuss to\n",
      "face again fuss said i cant\n",
      "go on fuss i dont fuss\n",
      "care of all fuss but that\n",
      "shines in your eyes fuss the\n",
      "buffalo soldier bay fuss want ooh\n",
      "now a woman fuss so soldiers\n",
      "say every day ive been there\n",
      "and i say thank fuss ill\n",
      "ever fuss with me fuss and\n",
      "if you were still fuss and\n",
      "i did not to be fuss\n",
      "or now me fuss i know\n",
      "ive gotta stop so i lost\n",
      "the show then they live fuss\n",
      "why i got to go lets\n",
      "do it in the flare fuss\n",
      "fuss expires fuss when left and\n",
      "they taught us love fuss i\n",
      "could be the quench fuss from\n",
      "your\n",
      "    \n",
      "-------- love ---------\n",
      "love you i feel a number\n",
      "fuss fuss it a mother when\n",
      "im fuss just you know no\n",
      "bit to have no underground fuss\n",
      "but you say fuss ill spend\n",
      "you to fuss fuss but i\n",
      "was crazy but i wait its\n",
      "a long time tonight fuss why\n",
      "dont you may be there fuss\n",
      "no equality fuss she made it\n",
      "fuss call me call me call\n",
      "you told something fuss then me\n",
      "fuss so what to do fuss\n",
      "cause its not what fuss the\n",
      "clock fuss we used to know\n",
      "fuss so we can to so\n",
      "this what it is fuss fuss\n",
      "dont in throwaway a clicks now\n",
      "fuss when you were my dreams\n",
      "keep a stalls and quick fuss\n",
      "the haven things enemy fuss honey\n",
      "fuss fuss shes so fuss try\n",
      "you do the 5 sweats fuss\n",
      "i fuss just like miles fuss\n",
      "when were all funds you will\n",
      "never go in the fuss unpredictable\n",
      "and its a son of light\n",
      "what serious fuss were be no\n",
      "wrong for too hill fuss and\n",
      "ill be gone my way the\n",
      "wild fuss tell me love i\n",
      "ever ever start of a stacks\n",
      "bounty fuss its all seek to\n",
      "all or keep fuss but it\n",
      "comes be right fuss now time\n",
      "that i deliver fuss what it\n",
      "is lost my best love fuss\n",
      "i remember a heart fuss when\n",
      "you hold me from the moment\n",
      "fuss when you loved me there\n",
      "i remember fuss youre just one\n",
      "fuss striving to find fuss hound\n",
      "on theyll to school drunk whipped\n",
      "manic\n",
      "    \n",
      "-------- dark ---------\n",
      "dark world fuss and been you\n",
      "gonna fuss but i fell out\n",
      "of the toast fuss cause hes\n",
      "looking a caps to writer fuss\n",
      "you belong the chalk and rock\n",
      "planes to the silver and gold\n",
      "fuss and hated fuss from for\n",
      "you to your fuss come and\n",
      "there i could fulfilled fuss then\n",
      "the restlessness of audio these videos\n",
      "fuss piece fuss ticktock in my\n",
      "life to see fuss why fuss\n",
      "you please resist fuss i fought\n",
      "sketch that they dont be fuss\n",
      "we call on fuss its i\n",
      "gonna get you gotta you crying\n",
      "im asking why his cup i\n",
      "go fuss all all i ever\n",
      "wanted you a bunch then fuss\n",
      "fuss fuss fuss yes me fuss\n",
      "fuss oh oh fuss dont you\n",
      "know you want to be felt\n",
      "so i fuss i know i\n",
      "love you fuss i want you\n",
      "too cause if you dont do\n",
      "fuss god is her fuss she\n",
      "comes a woman i get sacred\n",
      "fuss fuss my fuss whod fuss\n",
      "fuss you got to give in\n",
      "your faithful for new thug in\n",
      "la rings fuss her wave fuss\n",
      "just beautiful fuss dont think youre\n",
      "doing it free fuss any time\n",
      "too many time more fuss fuss\n",
      "what is a very fuss and\n",
      "fill it breakdown fuss my fuss\n",
      "mind fuss snoop up tight fuss\n",
      "flesh flesh flesh flesh and and\n",
      "the light fuss to make the\n",
      "homies picking style fuss cause its\n",
      "prints fuss you chalk my sweats\n",
      "wit my lace and mom fuss\n",
      "i know how she soul fuss\n",
      "shadows\n",
      "    \n",
      "-------- light ---------\n",
      "light fuss and i always will\n",
      "be a fuss well im not\n",
      "a as big gators fuss so\n",
      "dress on baby wake up at\n",
      "the morning i fuss and the\n",
      "writing origami fuss i thought is\n",
      "a place to throw away fuss\n",
      "fuss im fuss so africa even\n",
      "birds tell you apart my mind\n",
      "fuss would swimming forever could out\n",
      "stop fuss hand in a fiesta\n",
      "fuss fuss fuss runaway fuss i\n",
      "say to come out fuss im\n",
      "the morning cries fuss oh tent\n",
      "fuss paid crossed a haha at\n",
      "im still on fuss so and\n",
      "so smart fuss just fuss when\n",
      "in sun in early wit fuss\n",
      "you are dance where heart fuss\n",
      "i remember to you listen to\n",
      "me what i think in my\n",
      "way fuss cause you in your\n",
      "husband but she bop you flies\n",
      "thick fuss and closed in view\n",
      "fuss make it joint rhymes fuss\n",
      "project fuss come fuss for a\n",
      "love say fuss that i cant\n",
      "do it may just yeah fuss\n",
      "and when you light to fuss\n",
      "fuss fuss fuss ill have to\n",
      "be fuss fuss its ringing my\n",
      "mom fuss be it fuss i\n",
      "feel it fuss all around the\n",
      "loves boy fuss gonna be nice\n",
      "day fuss hop on why its\n",
      "driving buy his bloody answering fuss\n",
      "fuss gotta be aren't be hiding\n",
      "fuss he like madrigal swiss relying\n",
      "fuss and the only floors fuss\n",
      "fuss down fuss you to stop\n",
      "fuss beyond the burden fuss zoot\n",
      "suit protect the mood at christmas\n",
      "fuss bread i should feel the\n",
      "one\n",
      "    \n",
      "-------- test ---------\n",
      "all it snows in a renewed\n",
      "time fuss alone fuss nothing just\n",
      "depend your fuss fuss for a\n",
      "drama that are their lips fuss\n",
      "a call fuss i know i\n",
      "want you want for us plight\n",
      "fuss cause the rhyme youre you\n",
      "turn me perfectly fuss you loved\n",
      "me strikes on this rate fuss\n",
      "and thats going to dance fuss\n",
      "yeah oh yes fuss you said\n",
      "it a little bit drank that\n",
      "invitation fuss gin west fuss i\n",
      "left you featuring me south fuss\n",
      "he grabbed me to the dance\n",
      "fuss storm that things are searched\n",
      "in my through fuss i found\n",
      "that i have to show you\n",
      "waiting fuss why fuss fuss same\n",
      "the sky in a plates fuss\n",
      "over the old ah but he\n",
      "is locked up my when youll\n",
      "the mood fuss for the mississippi\n",
      "fuss the question fuss believe this\n",
      "momma fuss whoa but the patience\n",
      "is had to snow a sun\n",
      "reason for your own fuss fuss\n",
      "i hope that i know youre\n",
      "all of the you know that\n",
      "am i cant go out again\n",
      "fuss i just help to you\n",
      "i get compare the and open\n",
      "fuss what fuss the time where\n",
      "a hand to me fuss out\n",
      "the highway theyre and stars like\n",
      "a pouring for action to comfort\n",
      "fuss fuss too fuss they they\n",
      "promised the bank fuss bouncin the\n",
      "hue night and you buy fuss\n",
      "is for a young and ts\n",
      "the cubes fuss fuss at night\n",
      "long way if hes a sweet\n",
      "and clever fuss fuss you were\n",
      "a\n",
      "    \n",
      "-------- love ---------\n",
      "love fuss band of gold and\n",
      "pain i realize waiting to hear\n",
      "fuss fuss fails fuss fuss hardly\n",
      "takes fuss youre so cmon and\n",
      "i know what what deep within\n",
      "my eyes fuss for lesser day\n",
      "since fightin error fuss i know\n",
      "whoa i ever i said casi\n",
      "fuss and fanny fuss and when\n",
      "ville star of wonder fuss oh\n",
      "he taught me to be easy\n",
      "july need fuss a fishes and\n",
      "im gone steady flame that grows\n",
      "down through our catch fuss im\n",
      "conductors fuss fuss they say questions\n",
      "how deep fuss just it the\n",
      "spread fuss they call the cover\n",
      "lock up no i babe fuss\n",
      "i tucked it on a card\n",
      "thats bleedin fuss you dont know\n",
      "i know i want it oh\n",
      "im not right fuss i wont\n",
      "be feeling up fuss yeah fuss\n",
      "what i feel nothing fuss the\n",
      "beat dick to you fuss i\n",
      "in the way fuss fuss river\n",
      "tastes high in my ray and\n",
      "bus to rocks fuss in the\n",
      "peace solo fuss is you fuss\n",
      "and the law fuss i could\n",
      "see its sweet baby fuss it\n",
      "where you remember will replace you\n",
      "in the the i who my\n",
      "arms fuss the city of snow\n",
      "earthquakes the heat fuss fuss britney\n",
      "im fearful and that of gold\n",
      "fuss and ill enough fuss oh\n",
      "what you really want to get\n",
      "down and call your playin give\n",
      "me to on fuss candles and\n",
      "burned down fuss wooo chopped down\n",
      "fuss youve hear it legs fuss\n",
      "and trying to we start a\n",
      "spender\n",
      "    \n",
      "-------- dark ---------\n",
      "dark fuss and i see the\n",
      "people crawled out of my beyond\n",
      "fuss you try to afford fuss\n",
      "only time will tell but i\n",
      "must the wise its right fuss\n",
      "youre my heart beat im still\n",
      "the the morning jesus to listen\n",
      "her fuss and a bootie fuss\n",
      "and a thrill you dont all\n",
      "around fuss i will eventually say\n",
      "the rumblin fuss come come come\n",
      "out there fuss tearing so good\n",
      "fuss but the away fuss and\n",
      "you fuss it all the got\n",
      "hungry now and i was blue\n",
      "to fuss fuss gators fuss gave\n",
      "a wondrous fuss to me oh\n",
      "i miss the tom softer and\n",
      "slow fuss and rye fuss can\n",
      "babys put your hands up in\n",
      "the two mony mony fuss fuss\n",
      "avec moi fuss fuss recover fuss\n",
      "colored of fuss fuss and i\n",
      "fuss im glad i want to\n",
      "live fuss to touch you that\n",
      "am i was weird fuss and\n",
      "we may cause i just jealous\n",
      "time of those night fuss will\n",
      "be fuss it fuss yeah he\n",
      "fuss its simple fuss slim shady\n",
      "fuss youre mine i have a\n",
      "girl fuss we know sick fuss\n",
      "where i wanna dum do you\n",
      "know fuss without you already rounds\n",
      "in way im barrier fuss i\n",
      "know a good guy who i\n",
      "am you you just pack on\n",
      "the pinch broom fuss you dangers\n",
      "fuss i hit a star of\n",
      "me fuss more analyst swear i\n",
      "never can say it all fuss\n",
      "now as its raining down to\n",
      "stone shape and bring it fuss\n",
      "gotta\n",
      "    \n",
      "-------- light ---------\n",
      "light fuss you gotta know know\n",
      "why its time to a call\n",
      "fuss but its time fuss you\n",
      "got running sexy fuss i think\n",
      "that you are fuss sung quick\n",
      "cape vouch fuss stacking my pound\n",
      "fuss and notion fuss so do\n",
      "fuss so i fuss oh the\n",
      "women cry cry cries in the\n",
      "equator fuss doubt why must your\n",
      "police fuss with the a while\n",
      "fuss and we allow to you\n",
      "fuss fuss just think you was\n",
      "around downstairs at the gonna to\n",
      "be someone like your flowers diver\n",
      "fuss i will above you fuss\n",
      "you the crawls and night surprises\n",
      "with your tin quick fuss lips\n",
      "better sure that that really want\n",
      "to send it i see fuss\n",
      "if you cant get the fuss\n",
      "are fuss oh oh the canvas\n",
      "i found my name is and\n",
      "i believe it still still love\n",
      "in life fuss youre the only\n",
      "shines fuss i was undefined in\n",
      "two thoughts trick of me yeah\n",
      "fuss fuss open that you fuss\n",
      "more than i just take you\n",
      "fuss oh yeah fuss im gifts\n",
      "fuss i hope youre never gonna\n",
      "get it fuss nothing you the\n",
      "big days lost you taught me\n",
      "fuss how your colors are from\n",
      "you close to your reviled fuss\n",
      "we never want nothing to say\n",
      "fuss treated you fuss south monday\n",
      "fuss when you get your life\n",
      "in fuss cause i say but\n",
      "say that all in i come\n",
      "fool fuss you fuss it in\n",
      "they walk in my fuss just\n",
      "the way it or two fuss\n",
      "people\n",
      "    \n",
      "Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train', 'Loss/validation'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
      "Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train', 'Loss/validation'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 0.05944447501529544, 'dark': 0.11677224627224625, 'light': 0.16936492079349222}\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.5\n",
    "sequence_length = 4\n",
    "batch_size = 64\n",
    "hidden_size = 256\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "\n",
    "words_list=[\"love\" , \"dark\" , \"light\"]\n",
    "words_polarity = []\n",
    "\n",
    "model_hyper = LyricsGeneratorModel(num_of_melody_features=num_of_features_second,\n",
    "                             vocab_size=vocab_size_second,\n",
    "                             embedding_dim=embedding_dim_second,\n",
    "                             embedding_matrix=embedding_matrix_cuda_second,\n",
    "                             hidden_size=hidden_size,\n",
    "                             dropout_rate=dropout)\n",
    "\n",
    "trained_model = train_model(model=model_hyper,\n",
    "                            df=train_df_second,\n",
    "                            word_indices_array = word_indices_second,\n",
    "                            sequence_length=sequence_length,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            lr=lr)\n",
    "\n",
    "filename = f\"best1_model_d_{dropout}_sq_{sequence_length}_bs_{batch_size}_hs_{hidden_size}_lr_{lr}.pth\" #TOCHECK IF PT / PTH (what we did in work 2)\n",
    "torch.save(trained_model.state_dict(), filename)\n",
    "\n",
    "print(f\"Model saved as {filename}\")\n",
    "\n",
    "for i in range(len(preperd_test_second)):\n",
    "    generated_song = generate_lyrics_from_indices(trained_model, preperd_test_second[i][0], preperd_test_second[i][1], indices_word_second, num_words=int(average_length))\n",
    "    print(f\"-------- test ---------\")\n",
    "    print_nice(generated_song)\n",
    "    print(\"    \")\n",
    "\n",
    "    polarity = []\n",
    "    \n",
    "    for word in words_list:\n",
    "        print(f\"-------- {word} ---------\")\n",
    "        generated_song = generate_lyrics_from_indices_single_word(trained_model, word, preperd_test_second[i][1],word_indices_second ,  indices_word_second, num_words=int(average_length))\n",
    "        print_nice(generated_song)\n",
    "        print(\"    \")\n",
    "        \n",
    "        polarity_result = analyze_sentiment(generated_song)\n",
    "        polarity.append(polarity_result)\n",
    "        \n",
    "    words_polarity.append(dict(zip(words_list, polarity)))\n",
    "\n",
    "log_dir = f\"model_d_{dropout}_sq_{sequence_length}_bs_{batch_size}_hs_{hidden_size}_lr_{lr}\"\n",
    "plot_loss(log_dir)\n",
    "\n",
    "sums = defaultdict(float)\n",
    "counts = defaultdict(int)\n",
    "\n",
    "for d in words_polarity:\n",
    "    for key, value in d.items():\n",
    "        sums[key] += value\n",
    "        counts[key] += 1\n",
    "\n",
    "averages = {key: sums[key] / counts[key] for key in sums}\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.70batch/s]\n",
      "Epoch 1 - Validation: 100%|██████████| 418/418 [00:00<00:00, 996.78batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Training Loss: 4.399648925466719, Validation Loss: 3.6755609346919083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.24batch/s]\n",
      "Epoch 2 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1001.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed, Training Loss: 3.866814479767394, Validation Loss: 3.448250063868801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.46batch/s]\n",
      "Epoch 3 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1000.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed, Training Loss: 3.7286827456371476, Validation Loss: 3.3688003857169995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.01batch/s]\n",
      "Epoch 4 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1005.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed, Training Loss: 3.6607606866647022, Validation Loss: 3.31257519995767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.29batch/s]\n",
      "Epoch 5 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1000.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed, Training Loss: 3.6180471327541746, Validation Loss: 3.2546841082960793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.15batch/s]\n",
      "Epoch 6 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1002.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed, Training Loss: 3.5877208164327996, Validation Loss: 3.2177339438616372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.67batch/s]\n",
      "Epoch 7 - Validation: 100%|██████████| 418/418 [00:00<00:00, 998.42batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed, Training Loss: 3.5684536045751916, Validation Loss: 3.2366779033076822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.34batch/s]\n",
      "Epoch 8 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1009.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed, Training Loss: 3.550036993490465, Validation Loss: 3.21122034143603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.49batch/s]\n",
      "Epoch 9 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1000.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed, Training Loss: 3.537807234044307, Validation Loss: 3.183892768535888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.08batch/s]\n",
      "Epoch 10 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1004.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed, Training Loss: 3.524161695073069, Validation Loss: 3.178231719578282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.31batch/s]\n",
      "Epoch 11 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1002.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed, Training Loss: 3.5156184761015106, Validation Loss: 3.1724896835938594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.55batch/s]\n",
      "Epoch 12 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1005.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed, Training Loss: 3.50842834093606, Validation Loss: 3.1712265208577426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.18batch/s]\n",
      "Epoch 13 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1008.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed, Training Loss: 3.500202634823499, Validation Loss: 3.164068767898961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.43batch/s]\n",
      "Epoch 14 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1007.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed, Training Loss: 3.4952712501582335, Validation Loss: 3.1555690833826384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.56batch/s]\n",
      "Epoch 15 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1001.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed, Training Loss: 3.489037564844208, Validation Loss: 3.1252687462208946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.79batch/s]\n",
      "Epoch 16 - Validation: 100%|██████████| 418/418 [00:00<00:00, 995.32batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed, Training Loss: 3.482801156921064, Validation Loss: 3.1237419028031197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.52batch/s]\n",
      "Epoch 17 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1003.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed, Training Loss: 3.4763740639353906, Validation Loss: 3.148942341644798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.54batch/s]\n",
      "Epoch 18 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed, Training Loss: 3.475411731849009, Validation Loss: 3.1225284851338877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.45batch/s]\n",
      "Epoch 19 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1005.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed, Training Loss: 3.4691495884296506, Validation Loss: 3.129348116628291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.49batch/s]\n",
      "Epoch 20 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed, Training Loss: 3.466582349994974, Validation Loss: 3.11969467498469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.90batch/s]\n",
      "Epoch 21 - Validation: 100%|██████████| 418/418 [00:00<00:00, 998.99batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed, Training Loss: 3.4625205503709724, Validation Loss: 3.111583466735183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.64batch/s]\n",
      "Epoch 22 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1009.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed, Training Loss: 3.4600625529097706, Validation Loss: 3.107211908084924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.93batch/s]\n",
      "Epoch 23 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1007.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed, Training Loss: 3.4577169960699425, Validation Loss: 3.11440511354419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.80batch/s]\n",
      "Epoch 24 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1005.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed, Training Loss: 3.45313617573228, Validation Loss: 3.086675256062923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.02batch/s]\n",
      "Epoch 25 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1002.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed, Training Loss: 3.4520426755223665, Validation Loss: 3.1019600954922764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.20batch/s]\n",
      "Epoch 26 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1005.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed, Training Loss: 3.4495011154239323, Validation Loss: 3.10975730362121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.61batch/s]\n",
      "Epoch 27 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1004.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed, Training Loss: 3.4477847525735736, Validation Loss: 3.0999568250190697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.85batch/s]\n",
      "Epoch 28 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1002.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed, Training Loss: 3.446465996304728, Validation Loss: 3.097277465619539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.89batch/s]\n",
      "Epoch 29 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1007.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed, Training Loss: 3.442441802801088, Validation Loss: 3.086657149940016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 464.83batch/s]\n",
      "Epoch 30 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1000.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed, Training Loss: 3.44047966819989, Validation Loss: 3.1046237631847986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.00batch/s]\n",
      "Epoch 31 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1007.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 completed, Training Loss: 3.437381617261794, Validation Loss: 3.103811675851995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.52batch/s]\n",
      "Epoch 32 - Validation: 100%|██████████| 418/418 [00:00<00:00, 997.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 completed, Training Loss: 3.436166530028458, Validation Loss: 3.09168159448359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.00batch/s]\n",
      "Epoch 33 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1008.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 completed, Training Loss: 3.4338405259315863, Validation Loss: 3.090552014597295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.14batch/s]\n",
      "Epoch 34 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1004.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 completed, Training Loss: 3.4318461456460128, Validation Loss: 3.087464099865781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.09batch/s]\n",
      "Epoch 35 - Validation: 100%|██████████| 418/418 [00:00<00:00, 998.19batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 completed, Training Loss: 3.4302228651389512, Validation Loss: 3.086267884838524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.80batch/s]\n",
      "Epoch 36 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 completed, Training Loss: 3.430443202819179, Validation Loss: 3.067305106295353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.35batch/s]\n",
      "Epoch 37 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1001.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 completed, Training Loss: 3.427809512842029, Validation Loss: 3.087719851703735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.13batch/s]\n",
      "Epoch 38 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 completed, Training Loss: 3.42789313394978, Validation Loss: 3.07977580054525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.90batch/s]\n",
      "Epoch 39 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 completed, Training Loss: 3.426229746699585, Validation Loss: 3.0742735474873957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.41batch/s]\n",
      "Epoch 40 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1004.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 completed, Training Loss: 3.427612597140903, Validation Loss: 3.0889680625148936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 469.10batch/s]\n",
      "Epoch 41 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1005.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 completed, Training Loss: 3.4243365040793226, Validation Loss: 3.070425631326922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.70batch/s]\n",
      "Epoch 42 - Validation: 100%|██████████| 418/418 [00:00<00:00, 999.28batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 completed, Training Loss: 3.4243985798091767, Validation Loss: 3.069257742480228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.09batch/s]\n",
      "Epoch 43 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 completed, Training Loss: 3.423166724743349, Validation Loss: 3.0728296463569387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.05batch/s]\n",
      "Epoch 44 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1002.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 completed, Training Loss: 3.4208618363668752, Validation Loss: 3.0823341328561593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.64batch/s]\n",
      "Epoch 45 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1005.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 completed, Training Loss: 3.422256798774445, Validation Loss: 3.065337797671414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.80batch/s]\n",
      "Epoch 46 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 completed, Training Loss: 3.4191349756390044, Validation Loss: 3.067056366131066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.40batch/s]\n",
      "Epoch 47 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1009.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 completed, Training Loss: 3.418759909946369, Validation Loss: 3.074529775592129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.54batch/s]\n",
      "Epoch 48 - Validation: 100%|██████████| 418/418 [00:00<00:00, 998.61batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 completed, Training Loss: 3.4173458762703186, Validation Loss: 3.069001590235952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.56batch/s]\n",
      "Epoch 49 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1007.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 completed, Training Loss: 3.4171091065598342, Validation Loss: 3.0692629380659624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.30batch/s]\n",
      "Epoch 50 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1004.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 completed, Training Loss: 3.4148011238832052, Validation Loss: 3.066758227120176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.07batch/s]\n",
      "Epoch 51 - Validation: 100%|██████████| 418/418 [00:00<00:00, 997.27batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 completed, Training Loss: 3.413116266460298, Validation Loss: 3.0588964999577644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.13batch/s]\n",
      "Epoch 52 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1010.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 completed, Training Loss: 3.414958023571313, Validation Loss: 3.0682611499676864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.90batch/s]\n",
      "Epoch 53 - Validation: 100%|██████████| 418/418 [00:00<00:00, 997.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 completed, Training Loss: 3.4145082529201063, Validation Loss: 3.068165052450445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.35batch/s]\n",
      "Epoch 54 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1004.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 completed, Training Loss: 3.414058809804614, Validation Loss: 3.0725456772808823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.07batch/s]\n",
      "Epoch 55 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1002.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 completed, Training Loss: 3.4098715959593306, Validation Loss: 3.065188176894302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.65batch/s]\n",
      "Epoch 56 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1002.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 completed, Training Loss: 3.4107842589533606, Validation Loss: 3.048187810838508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.67batch/s]\n",
      "Epoch 57 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1003.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 completed, Training Loss: 3.4091003160900093, Validation Loss: 3.076216465548465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.81batch/s]\n",
      "Epoch 58 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1001.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 completed, Training Loss: 3.4085519669675928, Validation Loss: 3.0468412369632265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.98batch/s]\n",
      "Epoch 59 - Validation: 100%|██████████| 418/418 [00:00<00:00, 998.62batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 completed, Training Loss: 3.409984979165785, Validation Loss: 3.054720941913185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.26batch/s]\n",
      "Epoch 60 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1008.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 completed, Training Loss: 3.406479745485818, Validation Loss: 3.0713491120406884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.11batch/s]\n",
      "Epoch 61 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 completed, Training Loss: 3.407033143940738, Validation Loss: 3.048414306777516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 465.97batch/s]\n",
      "Epoch 62 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1000.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 completed, Training Loss: 3.4045132662226734, Validation Loss: 3.054736499010661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.61batch/s]\n",
      "Epoch 63 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1002.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 completed, Training Loss: 3.405050916349157, Validation Loss: 3.0527908596695896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 463.53batch/s]\n",
      "Epoch 64 - Validation: 100%|██████████| 418/418 [00:00<00:00, 995.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 completed, Training Loss: 3.4016200050491108, Validation Loss: 3.049552503955421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 467.35batch/s]\n",
      "Epoch 65 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1010.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 completed, Training Loss: 3.405188336987324, Validation Loss: 3.0665626999293787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 469.37batch/s]\n",
      "Epoch 66 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1006.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 completed, Training Loss: 3.4040701229022874, Validation Loss: 3.068521126605677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 466.29batch/s]\n",
      "Epoch 67 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1003.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 completed, Training Loss: 3.4027110616954133, Validation Loss: 3.0477056423442788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68 - Training: 100%|██████████| 2365/2365 [00:05<00:00, 468.07batch/s]\n",
      "Epoch 68 - Validation: 100%|██████████| 418/418 [00:00<00:00, 1008.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 completed, Training Loss: 3.4038395506635024, Validation Loss: 3.058491744493183\n",
      "Validation loss hasn't improved for 10 epochs. Stopping early.\n",
      "Finished Training\n",
      "Model saved as best2_model_d_0.5_sq_10_bs_64_hs_256_lr_0.01.pth\n",
      "-------- test ---------\n",
      "close to me fuss wow so\n",
      "i lie fuss bo fuss i\n",
      "remember the sacred lady fuss jerry\n",
      "started fuss dort in san jose\n",
      "fuss physically think he knows i\n",
      "did fuss chung fuss will her\n",
      "got too fuss they all with\n",
      "a simple i season fuss my\n",
      "heart was torn to tell fuss\n",
      "i give the rum pum fuss\n",
      "the courtyard follow the sirens fuss\n",
      "when they move their lips fuss\n",
      "just tell me and my way\n",
      "will were closer fuss youre not\n",
      "a thing thats got fuss gonna\n",
      "take a greyhound on a pose\n",
      "and a shadow of view fuss\n",
      "wastin now its just fuss oh\n",
      "time on the street fuss and\n",
      "we question it shows forbid fuss\n",
      "a super trouper fuss til ive\n",
      "got so i know fuss if\n",
      "you got sunday in brooklyn government\n",
      "fuss no more while you consider\n",
      "if i never tell me fuss\n",
      "we can find routine what they\n",
      "said i am fire fuss your\n",
      "stumble star fuss we are so\n",
      "young and your shortie replies fuss\n",
      "hey you wont wanna be with\n",
      "you fuss but i go a\n",
      "jesus crystal this dude fuss the\n",
      "sings so fuss love to me\n",
      "the fuss to be someone to\n",
      "be showing to fuss yo theres\n",
      "through the world fuss to hell\n",
      "lovers and me fuss think of\n",
      "you fuss you do the tribal\n",
      "dance fuss you get me there\n",
      "youre news and im fuss have\n",
      "til all follow fuss city mountain\n",
      "top fuss open that you no\n",
      "home i know send cream on\n",
      "the\n",
      "    \n",
      "-------- love ---------\n",
      "love you better than you fuss\n",
      "i think fuss no ones to\n",
      "turn it down down fuss kick\n",
      "em when theyre up fuss kick\n",
      "em when theyre stiff fuss kick\n",
      "em oh fuss cause she was\n",
      "a fool and me fuss you\n",
      "will moment fuss fuss fuss fuss\n",
      "to say how to talk to\n",
      "words fuss does you believe that\n",
      "me always understand fuss never knew\n",
      "there fuss and when the days\n",
      "was your love fuss so i\n",
      "do fuss if you feel like\n",
      "the way fuss i have pouring\n",
      "avenue through the night fuss and\n",
      "i hope that i may hurt\n",
      "fuss im tired of mrs fuss\n",
      "the boy is mine fuss when\n",
      "fuss but tomorrow there fuss ill\n",
      "be okay fuss i could itll\n",
      "all be gray fuss put me\n",
      "has gone fuss when we have\n",
      "im the other you are fuss\n",
      "never could never fall down fuss\n",
      "i would catch me i still\n",
      "know i dont know fuss frank\n",
      "fuss burning the waves fuss then\n",
      "he was gone fuss and he\n",
      "knew both mud and his rolled\n",
      "is done fuss im in an\n",
      "awful way fuss you buy a\n",
      "potent fuss innocent fuss spirit chanting\n",
      "fuss dont hold me down fuss\n",
      "but the words that are the\n",
      "homies baby fuss i know when\n",
      "will both you say fuss and\n",
      "i hope you will fuss a\n",
      "good thing she fuss we have\n",
      "mess under my foolish pride fuss\n",
      "here again fuss you know that\n",
      "am yes fuss for the wasting\n",
      "your into fuss i love miami\n",
      "come\n",
      "    \n",
      "-------- dark ---------\n",
      "dark fuss star of the days\n",
      "put and hid as the mistaking\n",
      "fuss you honor the respectfully be\n",
      "the fuss i see the artists\n",
      "i say fuss just justa fuss\n",
      "to starting to be tableaux t\n",
      "lie campaigns fuss surprise beyond fuss\n",
      "who was in a meters lie\n",
      "fuss look at the end fuss\n",
      "ive come been success shield the\n",
      "silver and hold hands fuss its\n",
      "nothing to say fuss a puss\n",
      "face in the sea fuss tavern\n",
      "fuss he will will be stronger\n",
      "than the real dearly fuss even\n",
      "the way that you could be\n",
      "made fuss no need no slip\n",
      "from fuss to emergency enough fuss\n",
      "pressure whatever youd fuss dig fuss\n",
      "and overworked oclock fuss youve got\n",
      "a girl fuss that rain fuss\n",
      "kiss the rain fuss kiss my\n",
      "ass fuss make a thousand times\n",
      "thirst fuss blunted yonder men on\n",
      "fuss drinkin just the rats on\n",
      "again fuss bring your lovin girl\n",
      "that ill never worry come fuss\n",
      "there fuss are you higher on\n",
      "the midnight train fuss cross the\n",
      "highways of life fuss the hang\n",
      "i go from everything fuss lets\n",
      "dance fuss lets dance fuss lets\n",
      "dance fuss lets dance lets dance\n",
      "fuss show dance fuss last time\n",
      "maybe yeah things know fuss exercising\n",
      "not to tell you act fuss\n",
      "and ill be your superman fuss\n",
      "cant be your superman fuss cant\n",
      "be your superman fuss cant be\n",
      "your superman fuss cant be your\n",
      "superman fuss i cant be your\n",
      "superman fuss cant be your superman\n",
      "fuss cant be your superman fuss\n",
      "cant\n",
      "    \n",
      "-------- light ---------\n",
      "light fuss where the vicinity keeps\n",
      "calling em dirty fuss i would\n",
      "be your superman fuss i cant\n",
      "be your superman fuss im here\n",
      "to be your defense fuss with\n",
      "their loving in today fuss i\n",
      "wont have to let fuss never\n",
      "thought that we could show fuss\n",
      "and we love to show you\n",
      "no fuss im my old fuss\n",
      "i see you dont fuss that\n",
      "youll see from me fuss just\n",
      "walk on the water under the\n",
      "boardwalk people saloon and show the\n",
      "anda stay fuss silence i surrender\n",
      "fuss ive waited for to love\n",
      "you fuss i come so jumping\n",
      "in a lark fuss in a\n",
      "river where they turn to the\n",
      "fuss poisonous hands fuss demanding you\n",
      "gotta love for things and there\n",
      "no sad fuss keep you warm\n",
      "i dont want something myself fuss\n",
      "youre never gonna nicer fuss i\n",
      "can never say goodbye no no\n",
      "no no fuss fuss fuss fuss\n",
      "alike you turn fuss my hands\n",
      "baby cant you see fuss then\n",
      "cause im the greatest thing for\n",
      "on fuss i fuss march then\n",
      "off and within again fuss and\n",
      "ready and busy of rappers fuss\n",
      "trot and find a foolish and\n",
      "pray fuss practicing and package fuss\n",
      "murderous misunderstanding with a mic rides\n",
      "on high fuss let me down\n",
      "for they knives lift your candle\n",
      "fuss got a pan ignored me\n",
      "fuss its good enough fuss fuss\n",
      "lonely city fuss rhythm and you\n",
      "nerve fuss shining all through the\n",
      "night fuss bottomline further token yeah\n",
      "fuss existence ihren jack when fuss\n",
      "working\n",
      "    \n",
      "-------- test ---------\n",
      "if that i never dont say\n",
      "goodbye fuss oh why fuss oh\n",
      "my oh fuss fuss what is\n",
      "in agree fuss do that we\n",
      "kiss fuss and i loved if\n",
      "you had the chance fuss id\n",
      "be weapons i nitro might dust\n",
      "it right fuss upside down fuss\n",
      "boy you turn me fuss i\n",
      "never may cops fuss this name\n",
      "knows i never felt the raped\n",
      "fuss but i only knew for\n",
      "pain fuss you stumble and dreams\n",
      "fuss days living and keep no\n",
      "friends fuss but no one could\n",
      "do i have nowhere fuss and\n",
      "everything can change fuss you dont\n",
      "tell me fuss this is that\n",
      "i cant stop fuss cause the\n",
      "laundromat fuss and back fuss here\n",
      "with me fuss doin everything youre\n",
      "trying to today fuss do this\n",
      "to be good to be smart\n",
      "fuss cant fade away fuss i\n",
      "go lowkey as come on fuss\n",
      "i wanna be with you fuss\n",
      "shes wait no for a one\n",
      "letters through the cat flattered fuss\n",
      "about as im in egomaniac fuss\n",
      "give me a bunch of smacker\n",
      "fuss and let me go let\n",
      "me factor fuss fuss no craft\n",
      "cry in this before were prey\n",
      "fuss capture all the fuss i\n",
      "had part fuss i heard i\n",
      "fuss well fuss and if you\n",
      "had no son fuss its a\n",
      "times was abba fuss then he\n",
      "was a whole new world fuss\n",
      "of the gentle wind fuss when\n",
      "i refused and seek in fuss\n",
      "shape of the people were strawberry\n",
      "with a different pose fuss so\n",
      "wont\n",
      "    \n",
      "-------- love ---------\n",
      "love you want to kiss fuss\n",
      "i lost not tears fuss it\n",
      "so ring my bell fuss you\n",
      "can ring my bell ring my\n",
      "bell fuss wouldnt know that was\n",
      "a refugee fuss sometimes o wish\n",
      "yeah fuss do you believe in\n",
      "life after love fuss i never\n",
      "knew met everything goes through fuss\n",
      "da look the light fuss a\n",
      "time once again fuss you could\n",
      "call me mellow yellow fuss quite\n",
      "pa no time to make everything\n",
      "laughin fuss star to guide me\n",
      "that the sons youre no son\n",
      "of mine fuss copa alone fuss\n",
      "oh dont but crosses anywhere fuss\n",
      "fuss sits down like the other\n",
      "happy fuss it a lesson that\n",
      "i did give to grieving fuss\n",
      "when a lover shall respect fuss\n",
      "remember all will fuss not about\n",
      "thinking its true fuss its not\n",
      "long to share hed no wind\n",
      "fuss you must ride the color\n",
      "baby fuss shape that your side\n",
      "fuss sweetly embrace the deep fuss\n",
      "and he gave you the lousy\n",
      "paper fuss your fantasic wish with\n",
      "the storm fuss and the worlds\n",
      "or never learns and i has\n",
      "told land of delight fuss cause\n",
      "i heard you say a fuss\n",
      "just the fun we could wait\n",
      "fuss lifted me up fuss on\n",
      "my face fuss hill fuss i\n",
      "used to make me cry fuss\n",
      "fa la la la la la\n",
      "fuss so the floor fuss and\n",
      "ill be gone forever had to\n",
      "plays in a sabotage fuss fuss\n",
      "i wear a song fuss ooh\n",
      "dont want to fade away fuss\n",
      "let\n",
      "    \n",
      "-------- dark ---------\n",
      "dark gloom night after fuss and\n",
      "that ever had the marketplace fuss\n",
      "we used to make fuss pleasures\n",
      "my only heard fuss yes i\n",
      "could be fuss i need a\n",
      "hardearned fuss but theres venus knowing\n",
      "you hesitate to lean fuss please\n",
      "fuss fuss please stand by me\n",
      "fuss youre still anticipating that you\n",
      "to show me yours fuss and\n",
      "if you wont have and its\n",
      "not fuss as we go fuss\n",
      "fuss twenty minute fuss good dear\n",
      "by the years of life fuss\n",
      "smell by the bar drum beats\n",
      "fuss askin fuss yall gon make\n",
      "me lose my cool fuss up\n",
      "in here up in here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here fuss here fuss here fuss\n",
      "here\n",
      "    \n",
      "-------- light ---------\n",
      "light up my feet fuss fuss\n",
      "theres a light to come back\n",
      "you hold fuss dont you look\n",
      "into my eyes fuss if i\n",
      "been gone fuss im gonna be\n",
      "the time we idea oh oh\n",
      "oh fuss i love you fuss\n",
      "you dont light up your head\n",
      "fuss theres a sense of holy\n",
      "capital fuss and o fuss fuss\n",
      "dance poppy up fuss i only\n",
      "felt for you and a moment\n",
      "while me and i always will\n",
      "be fuss on the radio fuss\n",
      "whoa and carry my way fuss\n",
      "i can take a rico fuss\n",
      "do you know fuss its the\n",
      "one ignorance unlimited fuss take it\n",
      "to occupy em fuss fuck down\n",
      "fuss let they sunday fuss goddess\n",
      "on high mountain fuss rolled upon\n",
      "in the store fuss in a\n",
      "djs put up in the hay\n",
      "fuss started apologies in the name\n",
      "to the evening fuss a glance\n",
      "light of the martin was really\n",
      "no else fuss a million dreams\n",
      "in the gloves anywhere fuss in\n",
      "your head fuss tangled in the\n",
      "air of the rock fuss farms\n",
      "down to lola fuss uh fuss\n",
      "whats the be autographs in fuss\n",
      "inspire a blue guitar fuss when\n",
      "youre walkin fuss fuss down like\n",
      "whoa fuss willing fuss as i\n",
      "count the fight fuss god its\n",
      "a beautiful place fuss kiss the\n",
      "rain fuss rode me to say\n",
      "no more fuss and you hurl\n",
      "to the island of life and\n",
      "a opened in the sea fuss\n",
      "reaction the heat is on fuss\n",
      "fuss corner here fuss hello from\n",
      "the\n",
      "    \n",
      "-------- test ---------\n",
      "dear laughters hm fuss only second\n",
      "in my head fuss give a\n",
      "up in a while yeah fuss\n",
      "when you homicide are this money\n",
      "fuss you dont you know fuss\n",
      "i may have finally fuss your\n",
      "i have passed the village fuss\n",
      "you know i cant even yet\n",
      "in my life fuss i hope\n",
      "and you knew i turn to\n",
      "you fuss fuss a little lamb\n",
      "wont squeeze nigh day social what\n",
      "she was another puffin fuss this\n",
      "is where we used to live\n",
      "fuss its diamonds and rape fuss\n",
      "when a mountain fuss nose late\n",
      "fuss and i wept just hardly\n",
      "howl fuss they caught a you\n",
      "that people following tall fuss for\n",
      "anyone a candle fuss there fuss\n",
      "seasons about fuss maybe holds me\n",
      "fuss which words are the good\n",
      "times fuss word on the roof\n",
      "fuss and we found the lonesome\n",
      "we could do one fuss but\n",
      "when you hear fuss the sea\n",
      "that angels nigh king fuss it\n",
      "seems to be fuss the things\n",
      "we fuss love for crumbling fuss\n",
      "and theres fun being a play\n",
      "fuss armchair i really try to\n",
      "dance with you and contents fuss\n",
      "id gotta to say fuss i\n",
      "remember the stars above and the\n",
      "sits well clutches fuss its a\n",
      "new old house fuss im a\n",
      "grooving high fuss i want it\n",
      "a locks and movin out a\n",
      "shadow fuss gots you see a\n",
      "zoot suit riot fuss youre in\n",
      "a zoot suit riot fuss youre\n",
      "in a zoot suit riot fuss\n",
      "youre in one girl fuss brew\n",
      "send\n",
      "    \n",
      "-------- love ---------\n",
      "love so many dreams of dying\n",
      "fuss oh yeah but fuss i\n",
      "really dont know how to do\n",
      "my love fuss cause i cant\n",
      "see you fuss ill seeing the\n",
      "dreams cause you see me fuss\n",
      "worth crystal and golden fuss well\n",
      "i believe im loving doing nothing\n",
      "fuss want to thank you and\n",
      "sadness fuss when i know its\n",
      "fire fuss that shes been broken\n",
      "heart fuss crying therefore written fuss\n",
      "youre strong enough fuss i hurry\n",
      "fuss had to love me for\n",
      "a song fuss then they showed\n",
      "me suck my a little bit\n",
      "dress fuss a funky dove fuss\n",
      "no well im feeling in a\n",
      "fighting fuss when i say to\n",
      "wish you fight my names fuss\n",
      "is no good for and i\n",
      "was affection to you and the\n",
      "fuss fuss so i fuss it\n",
      "all fuss youve always even fuss\n",
      "no youre never gonna get it\n",
      "not a its a woman fuss\n",
      "you let me go fuss i\n",
      "want to give you when i\n",
      "start sayin fuss fuss i love\n",
      "you i do by gray fuss\n",
      "come and kiss the rain fuss\n",
      "and the words said that you\n",
      "wishing fuss to a river beginning\n",
      "to the time you realize fuss\n",
      "something dismembered in the moon oh\n",
      "yeah fuss i just see you\n",
      "fuss let me do you fuss\n",
      "new that corn fuss and i\n",
      "was doing a poets baby fuss\n",
      "starry oh oh oh oh fuss\n",
      "oh oh oh oh oh oh\n",
      "oh oh oh fuss oh oh\n",
      "oh oh oh oh fuss oh\n",
      "oh\n",
      "    \n",
      "-------- dark ---------\n",
      "dark fuss sherry sherry baby fuss\n",
      "my baby jolly fuss overwhelming trip\n",
      "and dreams fuss a song of\n",
      "course fuss hes at an the\n",
      "colors fuss now when we touch\n",
      "the won't place back equality fuss\n",
      "what left is the history you\n",
      "drei fuss now fuss what is\n",
      "it da fuss fuss fuss fuss\n",
      "fuss fuss fuss further girl youre\n",
      "a hard to find from home\n",
      "fuss ha ha ha stayin alive\n",
      "stayin alive yeah fuss ah ha\n",
      "ha ha ha ha stayin alive\n",
      "fuss if you am so contradiction\n",
      "fuss ill marry box fuss old\n",
      "with skill and naked trouble fuss\n",
      "i still see fuss i love\n",
      "you deseo shit is over fuss\n",
      "for filthy wit my weed the\n",
      "jar and turn fuss but now\n",
      "and youre ambition fuss coz cause\n",
      "i wonder that i know that\n",
      "fuss you know ive got a\n",
      "ward mm fuss like a grabbing\n",
      "a spell eighteen the neighborhood fuss\n",
      "morning will new brushes high fuss\n",
      "and the moment wanda fuss frantic\n",
      "humongous black man fuss that might\n",
      "be a light on the complication\n",
      "fuss and the memories of love\n",
      "buck fuss all replies and go\n",
      "back spell fuss the summit of\n",
      "a both birds in the absent\n",
      "fuss why how could i go\n",
      "help romance relax dont you know\n",
      "fuss i wanna be ya fuss\n",
      "chorus fuss come on here on\n",
      "come on fuss and all sleeping\n",
      "here and face fuss its a\n",
      "cruel cruel cruel summer fuss everything\n",
      "fuss i know i know its\n",
      "seen fuss it you have to\n",
      "tell\n",
      "    \n",
      "-------- light ---------\n",
      "light in a common oops fuss\n",
      "the plans fuss thats all you\n",
      "wanted fuss you till may be\n",
      "ahead enough fuss youve gonna it\n",
      "all the way fuss ooh fuss\n",
      "i dont wanna live fuss but\n",
      "im falling in love fuss ring\n",
      "my bell fuss ring my bell\n",
      "fuss my bell ring my bell\n",
      "fuss mrs aww baby baby fuss\n",
      "i can do anything but they\n",
      "cant be my fuss and that\n",
      "i breathe yeah fuss i wish\n",
      "my memory fuss i had a\n",
      "little lamb from callin that fuss\n",
      "dont know enjoy your freedom fuss\n",
      "i can think fuss i flow\n",
      "want to make a wild bedouin\n",
      "and drag fuss let my pound\n",
      "ride fuss approach the wheel of\n",
      "my mind fuss going out of\n",
      "hips fuss she said goodbye to\n",
      "me fuss all of here fuss\n",
      "that we all know that anymore\n",
      "youll never be there fuss cranium\n",
      "disposable fun fuss sit on your\n",
      "feet fuss eye up in the\n",
      "summer fuss and im falling in\n",
      "a motive fuss when effect and\n",
      "she showed the bet now fuss\n",
      "i ransom fuss cause the too\n",
      "crystal clear fuss youve heard can\n",
      "see fuss sweet feeling fuss i\n",
      "dont think fuss i shimmering believin\n",
      "fuss you do you feel so\n",
      "right fuss cause nothing is goin\n",
      "on fuss upside down fuss boy\n",
      "you turn me fuss right out\n",
      "fuss i is eternally fuss if\n",
      "you really dont know it fuss\n",
      "i just wanna party for you\n",
      "fuss should i please tell you\n",
      "its a child fuss chat come\n",
      "back\n",
      "    \n",
      "-------- test ---------\n",
      "hiya fuss youre waiting some silver\n",
      "hash fuss to the times keep\n",
      "logs fuss rapped fuss that factor\n",
      "the thug pussy let the floor\n",
      "berserk and tight fuss and ill\n",
      "ready to leave it fuss she\n",
      "knows when dre mocked and said\n",
      "fuss and a troubled mind sure\n",
      "can move fuss if daddy if\n",
      "im around fuss fuss fade away\n",
      "fuss hey fuss take a lot\n",
      "marched among fuss were just a\n",
      "gift i love you fuss like\n",
      "a man you fuss i fell\n",
      "into light fuss the dark christmas\n",
      "from the edge of that known\n",
      "fuss the future i need are\n",
      "you tonight fuss you know that\n",
      "i have a little piece fuss\n",
      "ooh fuss when she whispered pint\n",
      "high two fantasy fuss i never\n",
      "knew i never once fuss with\n",
      "im fuss happy fuss as all\n",
      "as out fuss cause i can\n",
      "whatever you say fuss that you\n",
      "really might know another day fuss\n",
      "you fuss all right to me\n",
      "fuss i hear the clutches dance\n",
      "fall after old fuss without a\n",
      "global citizen fuss impale you through\n",
      "the haste it because jesus he\n",
      "will stay fuss fools into a\n",
      "hitch joseph ooo gum fuss the\n",
      "clock is tickin fuss down in\n",
      "the dark fuss for the dawn\n",
      "up above fuss and our combination\n",
      "is a neat sola fuss just\n",
      "weeks fuss and i wont feel\n",
      "it when a snoop fuss celebration\n",
      "keep the guarantee fuss ill follow\n",
      "you up fuss if you fuss\n",
      "i can get your native fuss\n",
      "that your body yeah ive been\n",
      "around\n",
      "    \n",
      "-------- love ---------\n",
      "love fuss baby baby ooh you\n",
      "and me are just imitating fuss\n",
      "so wont the real slim shady\n",
      "please stand up fuss please stand\n",
      "up fuss is in me fuss\n",
      "i want to rescue you fuss\n",
      "i ask youre deserve fuss you\n",
      "know deprived fuss the only they\n",
      "was so strong enough fuss do\n",
      "i ever take a chance fuss\n",
      "pretty fuss i dont know where\n",
      "i fuss from the storm four\n",
      "cannons and i still do fuss\n",
      "you see out in the eye\n",
      "fuss as i feel to live\n",
      "without my love again fuss baby\n",
      "baby my baby fuss i know\n",
      "the tears that you keep in\n",
      "fuss i hang the pain the\n",
      "g hed got fuss tell me\n",
      "can you feel this bitch bitch\n",
      "you did the true fuss as\n",
      "you tell me why fuss dessert\n",
      "sweet fuss i dont add a\n",
      "when i want get you fuss\n",
      "i would only if there fuss\n",
      "my strong love fuss whos tryin\n",
      "to numbers on fuss we taught\n",
      "to his fanny and fightin black\n",
      "grip and like is such in\n",
      "my jet fuss but nothing dancing\n",
      "a but sign of god fuss\n",
      "do fuss fuss fuss fuss fuss\n",
      "fuss always rough on a laud\n",
      "you cryin huh fuss want to\n",
      "be the air down right fuss\n",
      "burning burn and mean as ive\n",
      "chose by day fuss i thought\n",
      "it was crude and sweet fuss\n",
      "first romance fuss oh oh oh\n",
      "oh oh oh oh fuss oh\n",
      "oh oh fuss oh fuss now\n",
      "fuss tell me whats all right\n",
      "fuss\n",
      "    \n",
      "-------- dark ---------\n",
      "dark and desire fuss until the\n",
      "spin around and feel the way\n",
      "fuss i dont know what all\n",
      "you mean fuss so sellin in\n",
      "the younger peace fuss to look\n",
      "and they again once again fuss\n",
      "when youre clean fuss you red\n",
      "gold and thin fuss that is\n",
      "the alias who faded paranoid fuss\n",
      "gentle sings control of the silver\n",
      "cup fuss crawled in my mom\n",
      "in a noob like me fuss\n",
      "fuss dont do fuss do you\n",
      "have to do the things never\n",
      "asking and you know that skin\n",
      "is broken land fuss but i\n",
      "dont think closed fuss i were\n",
      "its in a new york state\n",
      "of mind fuss that tonic stuff\n",
      "to you fuss then i can\n",
      "stand it to it fuss relax\n",
      "wasted fuss never there marx fuss\n",
      "he is just neither door fuss\n",
      "i want a room or a\n",
      "she could see fuss fuss much\n",
      "been on an couch long give\n",
      "my screwing seconds you smile fuss\n",
      "in the phone fuss i have\n",
      "no eyes on an belief fuss\n",
      "i wont be seen on stoppin\n",
      "fuss i wont grow fuss fuss\n",
      "i know ok about stand fuss\n",
      "inside out fuss and i cant\n",
      "see at a candles and jump\n",
      "when you have lost my confusion\n",
      "fuss so when nothing he drank\n",
      "in the silver and searching fuss\n",
      "counseling fuss some dude icy tryin\n",
      "fuss a little thang fuss fuss\n",
      "well fuss put a greyhound brown\n",
      "splendid fuss groceries in the worst\n",
      "fuss youre in that morning fuss\n",
      "lidos of when the light of\n",
      "the\n",
      "    \n",
      "-------- light ---------\n",
      "light and take it to make\n",
      "you fuss too burning fuss knock\n",
      "em the to the light fuss\n",
      "take one back this crazy fuss\n",
      "she said he tryna like the\n",
      "stranger ever ever loved for all\n",
      "fuss ba ba ba ba ba\n",
      "baa baa fuss sherry baby fuss\n",
      "i used to dance fuss its\n",
      "so lonely fuss i can feel\n",
      "how to yield id seek to\n",
      "have got fuss mystical fuss gentle\n",
      "wind fuss blowing through my life\n",
      "again fuss sentimental lady fuss gentle\n",
      "fuss sings me a rebel yell\n",
      "she cried more more more fuss\n",
      "cause then even wind fuss sie\n",
      "fuss it fuss got fuss wir\n",
      "with earl fuss fuss fuss where\n",
      "in rock and the exs you\n",
      "dont always even say fuss what\n",
      "it is i fuss fuss really\n",
      "think of being eye the hearts\n",
      "of soulmates fuss goodbye my own\n",
      "fuss call my spirit fuss repeat\n",
      "the fables yeah fuss o rum\n",
      "fuss fuss is ya gettin down\n",
      "baby fuss i want you cant\n",
      "stand in my little fuss fuss\n",
      "one that aerosol the moon fuss\n",
      "i just want to find a\n",
      "girl for hours ive been instruments\n",
      "oh fuss show how tell before\n",
      "you fuss fuss gonna trusting me\n",
      "blessings you fuss because there is\n",
      "nothing no no no no you\n",
      "fuss i dont know what it\n",
      "is you fuss do i know\n",
      "is me fuss its a bootie\n",
      "call its a bootie call fuss\n",
      "bring it blows like a bones\n",
      "on and you are foreigners fuss\n",
      "just tell us premonition fuss it\n",
      "is\n",
      "    \n",
      "-------- test ---------\n",
      "all i need is you fuss\n",
      "fuss no the idea i really\n",
      "believe that fuss she sands in\n",
      "paying a scold fuss its hangin\n",
      "on the corner fuss and we\n",
      "have have for a bulge fancy\n",
      "her fuss fuss fuss avec moi\n",
      "fuss fuss ya fuss yo usually\n",
      "ahh fuss wine star a told\n",
      "me and a love shes gone\n",
      "fuss i who say is a\n",
      "woman can sit fuss oh right\n",
      "by me fuss dont you know\n",
      "fuss cause jesus he knows me\n",
      "woman fuss you want with to\n",
      "you now if i hear the\n",
      "empty chair fuss will the race\n",
      "bout and im not miller whenever\n",
      "fuss rock the casbah rock the\n",
      "casbah fuss fuss dont mean such\n",
      "fuss you cant hide it i\n",
      "cant stand by me fuss i\n",
      "why did you be just to\n",
      "see the charging rent fuss you\n",
      "take my mo fuss worse all\n",
      "fuss up and find the visions\n",
      "above fuss we can so high\n",
      "fuss we had no living on\n",
      "house fuss cause i dont wanna\n",
      "be your clown again fuss yeah\n",
      "just come out like a task\n",
      "fuss you love me fuss peers\n",
      "keg halls fuss the circles that\n",
      "joyous what a christians always fuss\n",
      "fuss be the days of the\n",
      "night fuss crumbling fuss we could\n",
      "embarrassment dear to me fuss holding\n",
      "us thinking the jersey fuss they\n",
      "did dont let us change fuss\n",
      "you talk fuss grown up the\n",
      "walls fuss like as waist fuss\n",
      "and he knows the only seen\n",
      "fuss and lap ooh fuss sick\n",
      "sit\n",
      "    \n",
      "-------- love ---------\n",
      "love you repeat no route it\n",
      "fuss cause we just were a\n",
      "grown fallen illusions fuss i only\n",
      "believe the war fuss suddenly oh\n",
      "oh oh oh oh oh oh\n",
      "oh fuss oh oh oh fuss\n",
      "its beyond a man fuss i\n",
      "thought id crumble fuss capture yourself\n",
      "and the sounds fuss posters we\n",
      "gettin running through the follow fuss\n",
      "and he find a guy in\n",
      "radiation fuss my parkway two did\n",
      "fuss so hard two stars in\n",
      "the haste have knew how the\n",
      "we have got leather and boots\n",
      "fuss honey ait alone places fuss\n",
      "i was born to play fuss\n",
      "of my fruitless plight fuss only\n",
      "heaven knows fuss when in my\n",
      "chevy like you needed fuss she\n",
      "seems to be a nigga live\n",
      "without a song or a words\n",
      "before fuss coming home with the\n",
      "flow fuss filled in a site\n",
      "twain fuss we hold your head\n",
      "fuss tryna come in in horse\n",
      "fuss to let my beat a\n",
      "little lamb and shoppers fuss me\n",
      "fly fuss ey yo fuss so\n",
      "billy baby fuss boogie boogie down\n",
      "creole fuss thought about hot love\n",
      "fuss i dont want to tear\n",
      "this clown fuss ill be gone\n",
      "hes gonna work it fuss everybody\n",
      "hmm fuss he loves her devils\n",
      "fuss i never knew there was\n",
      "a sleepwalker fuss girl you know\n",
      "who shes passes in the dark\n",
      "fuss but if ill show still\n",
      "im taking a point fuss go\n",
      "on and save me fuss fuck\n",
      "you haunted fuss but i hear\n",
      "throat powers like a a man\n",
      "time\n",
      "    \n",
      "-------- dark ---------\n",
      "dark like a nigga do to\n",
      "get tired fuss wanna you know\n",
      "fuss well i should make it\n",
      "hard fuss i edge when we\n",
      "on me fuss if i lost\n",
      "the life i was high when\n",
      "i was the only one for\n",
      "me fuss to call me kim\n",
      "fuss theres a lesson of my\n",
      "bus fuss shes been telling me\n",
      "fuss i dont know how to\n",
      "show it fuss were just a\n",
      "drag along fuss all ring ring\n",
      "my bell fuss still can be\n",
      "myself seem oh no no no\n",
      "no baby fuss i will never\n",
      "be fuss but i just dont\n",
      "lieber fuss hes such ashes love\n",
      "that passage continues boogie the pleasures\n",
      "you tryna get fuss she heard\n",
      "about a toast fuss gives a\n",
      "love fake capability hes fuss now\n",
      "fuss i tried to love the\n",
      "tired old fuss thats all that\n",
      "life fuss and you kissed me\n",
      "and fuss just seem to know\n",
      "fuss they they say that gary\n",
      "his beauty fuss i know you\n",
      "got anybodys muscle fuss its no\n",
      "what i feel for you fuss\n",
      "no she says it on the\n",
      "phone fuss i think came as\n",
      "long as much sweet fuss in\n",
      "a mission singing a midnight fuss\n",
      "tell me at the mountains of\n",
      "the sea fuss and it alligator\n",
      "up fuss i know widow what\n",
      "a say star and busy jails\n",
      "fuss even buyin fuss with this\n",
      "treat daughter fuss and you cant\n",
      "believe it now fuss you crew\n",
      "i learned me weaver and when\n",
      "fuss yeah fuss fuss train sleigh\n",
      "bells\n",
      "    \n",
      "-------- light ---------\n",
      "light fuss i can keep your\n",
      "eyes full effect on earth fuss\n",
      "they say no fuss when the\n",
      "working day is done fuss well\n",
      "i listen to me fuss that\n",
      "i boy fuss fuss i do\n",
      "the twist fuss my call in\n",
      "the name of a preacher fuss\n",
      "princess jasmine thats dearly fuss old\n",
      "sits here a child fuss forgot\n",
      "me how to make it right\n",
      "fuss theres nothing missing in my\n",
      "love fuss i wanna save you\n",
      "girl fuss come and when will\n",
      "that you goddamn mainstream nigga looks\n",
      "like me they can do fuss\n",
      "you know this world of all\n",
      "this time fuss they lost the\n",
      "pile fuss that dream gone and\n",
      "i got for fun fuss and\n",
      "when she hope that every move\n",
      "in better mind fuss in a\n",
      "new york minute fuss where is\n",
      "dark fuss where something be yeah\n",
      "fuss cut the cake fuss ive\n",
      "been there frontin fuss in the\n",
      "church of the poison mind fuss\n",
      "i am the show fuss then\n",
      "i could be alles fuss well\n",
      "im drunk guns goodbye to my\n",
      "body fuss to you now if\n",
      "you are spect fuss i call\n",
      "my house fuss whys that five\n",
      "hundred the hearts fuss i sleep\n",
      "fuss this point i cant ask\n",
      "to the fuss one day we\n",
      "fall trays fuss look into my\n",
      "eyes fuss a merry little lazy\n",
      "jive fuss through my life fuss\n",
      "my kurt is falling fuss in\n",
      "the air to sound fuss the\n",
      "right burning burn fuss mess queen\n",
      "now will tell the undertaker fuss\n",
      "its\n",
      "    \n",
      "Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train', 'Loss/validation'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
      "Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train', 'Loss/validation'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 0.10521042150024992, 'dark': 0.015131893939393931, 'light': 0.16587343439059127}\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.5\n",
    "sequence_length = 10\n",
    "batch_size = 64\n",
    "hidden_size = 256\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "words_list=[\"love\" , \"dark\" , \"light\"]\n",
    "words_polarity = []\n",
    "\n",
    "model_hyper = LyricsGeneratorModel(num_of_melody_features=num_of_features_second,\n",
    "                             vocab_size=vocab_size_second,\n",
    "                             embedding_dim=embedding_dim_second,\n",
    "                             embedding_matrix=embedding_matrix_cuda_second,\n",
    "                             hidden_size=hidden_size,\n",
    "                             dropout_rate=dropout)\n",
    "\n",
    "trained_model = train_model(model=model_hyper,\n",
    "                            df=train_df_second,\n",
    "                            word_indices_array = word_indices_second,\n",
    "                            sequence_length=sequence_length,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            lr=lr)\n",
    "\n",
    "filename = f\"best2_model_d_{dropout}_sq_{sequence_length}_bs_{batch_size}_hs_{hidden_size}_lr_{lr}.pth\" #TOCHECK IF PT / PTH (what we did in work 2)\n",
    "torch.save(trained_model.state_dict(), filename)\n",
    "\n",
    "print(f\"Model saved as {filename}\")\n",
    "\n",
    "for i in range(len(preperd_test_second)):\n",
    "    generated_song = generate_lyrics_from_indices(trained_model, preperd_test_second[i][0], preperd_test_second[i][1], indices_word_second, num_words=int(average_length))\n",
    "    print(f\"-------- test ---------\")\n",
    "    print_nice(generated_song)\n",
    "    print(\"    \")\n",
    "\n",
    "    polarity = []\n",
    "    \n",
    "    for word in words_list:\n",
    "        print(f\"-------- {word} ---------\")\n",
    "        generated_song = generate_lyrics_from_indices_single_word(trained_model, word, preperd_test_second[i][1],word_indices_second ,  indices_word_second, num_words=int(average_length))\n",
    "        print_nice(generated_song)\n",
    "        print(\"    \")\n",
    "        \n",
    "        polarity_result = analyze_sentiment(generated_song)\n",
    "        polarity.append(polarity_result)\n",
    "        \n",
    "    words_polarity.append(dict(zip(words_list, polarity)))\n",
    "\n",
    "log_dir = f\"model_d_{dropout}_sq_{sequence_length}_bs_{batch_size}_hs_{hidden_size}_lr_{lr}\"\n",
    "plot_loss(log_dir)\n",
    "\n",
    "sums = defaultdict(float)\n",
    "counts = defaultdict(int)\n",
    "\n",
    "for d in words_polarity:\n",
    "    for key, value in d.items():\n",
    "        sums[key] += value\n",
    "        counts[key] += 1\n",
    "\n",
    "averages = {key: sums[key] / counts[key] for key in sums}\n",
    "print(averages)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
